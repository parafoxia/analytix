{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#_1","title":"Home","text":"A simple yet powerful SDK for the YouTube Analytics API."},{"location":"#features","title":"Features","text":"<ul> <li>Pythonic syntax lets you feel right at home</li> <li>Dynamic error handling saves hours of troubleshooting and makes sure only valid requests count toward your API quota</li> <li>A clever interface allows you to make multiple requests across multiple sessions without reauthorising</li> <li>Extra support enables you to export reports in a variety of filetypes and to a number of DataFrame formats</li> <li>Easy enough for beginners, but powerful enough for advanced users</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#installing-analytix","title":"Installing analytix","text":"<p>To install the latest stable version of analytix, use the following command:</p> <pre><code>pip install analytix\n</code></pre> <p>You can also install the latest development version using the following command:</p> <pre><code>pip install git+https://github.com/parafoxia/analytix\n</code></pre> <p>You may need to prefix these commands with a call to the Python interpreter depending on your OS and Python configuration.</p>"},{"location":"#dependencies","title":"Dependencies","text":"<p>Below is a list of analytix's dependencies. Note that the minimum version assumes you're using CPython 3.8. The latest versions of each library are always supported.</p> Name Min. version Required? Usage <code>urllib3</code> 2.2.0 Yes Making HTTP requests <code>jwt</code> 1.2.0 No Decoding JWT ID tokens (from v5.1) <code>openpyxl</code> 3.0.0 No Exporting report data to Excel spreadsheets <code>pandas</code> ~1.3.0 No Exporting report data to pandas DataFrames <code>polars</code> 0.15.17 No Exporting report data to Polars DataFrames <code>pyarrow</code> ~5.0.0 No Exporting report data to Apache Arrow tables and file formats"},{"location":"#oauth-authentication","title":"OAuth authentication","text":"<p>All requests to the YouTube Analytics API need to be authorised through OAuth 2. In order to do this, you will need a Google Developers project with the YouTube Analytics API enabled. You can find instructions on how to do that in the API setup guide.</p> <p>Once a project is set up, analytix handles authorisation \u2014 including token refreshing \u2014 for you.</p> <p>More details regarding how and when refresh tokens expire can be found on the Google Identity documentation.</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#retrieving-reports","title":"Retrieving reports","text":"<p>The following example creates a CSV file containing basic info for the 10 most viewed videos, from most to least viewed, in the US in 2022:</p> <pre><code>from datetime import date\n\nfrom analytix import Client\n\nclient = Client(\"secrets.json\")\nreport = client.fetch_report(\n    dimensions=(\"video\",),\n    filters={\"country\": \"US\"},\n    metrics=(\"estimatedMinutesWatched\", \"views\", \"likes\", \"comments\"),\n    sort_options=(\"-estimatedMinutesWatched\",),\n    start_date=date(2022, 1, 1),\n    end_date=date(2022, 12, 31),\n    max_results=10,\n)\nreport.to_csv(\"analytics.csv\")\n</code></pre> <p>If you want to analyse this data using additional tools such as pandas, you can directly export the report as a DataFrame or table using the <code>to_pandas()</code>, <code>to_arrow()</code>, and <code>to_polars()</code> methods of the report instance. You can also save the report as a <code>.tsv</code>, <code>.json</code>, <code>.xlsx</code>, <code>.parquet</code>, or <code>.feather</code> file.</p> <p>There are more examples in the GitHub repository.</p>"},{"location":"#fetching-group-information","title":"Fetching group information","text":"<p>You can also fetch groups and group items:</p> <pre><code>from analytix import Client\n\n# You can also use the client as context manager!\nwith Client(\"secrets.json\") as client:\n    groups = client.fetch_groups()\n    group_items = client.fetch_group_items(groups[0].id)\n</code></pre>"},{"location":"#logging","title":"Logging","text":"<p>If you want to see what analytix is doing, you can enable the packaged logger:</p> <pre><code>import analytix\n\nanalytix.enable_logging()\n</code></pre> <p>This defaults to showing all log messages of level INFO and above. To show more (or less) messages, pass a logging level as an argument.</p>"},{"location":"#compatibility","title":"Compatibility","text":"<p>CPython versions 3.8 through 3.12 and PyPy versions 3.9 and 3.10 are officially supported*. CPython 3.13-dev is provisionally supported*. Windows, MacOS, and Linux are all supported.</p> <p>*For base analytix functionality; support cannot be guaranteed for functionality requiring external libraries.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are very much welcome! To get started:</p> <ul> <li>Familiarise yourself with the code of conduct</li> <li>Have a look at the contributing guide</li> </ul>"},{"location":"#license","title":"License","text":"<p>The analytix module for Python is licensed under the BSD 3-Clause License.</p>"},{"location":"guides/dimensions/","title":"What are dimensions?","text":""},{"location":"guides/dimensions/#overview","title":"Overview","text":"<p>Dimensions provide a means to split data into smaller parts. This is useful when you wish to see how your channel is performing over time or compare the statistics for one attribute against those for another. Most report types require at least one dimension to be provided, and some report types can accept more.</p>"},{"location":"guides/dimensions/#using-a-single-dimension","title":"Using a single dimension","text":"<p>Here is some example data:</p> views likes comments 1 1 000 000 100 000 20 000 <p>This data contains four columns (the ID column, and three metrics), and one row. This row represents the cumulative data over the course of 12 months. While this is useful if you want to know the totals, there is not a lot we can take from it. To remedy this, we can use the \"month\" dimension. After doing so, the data looks like this:</p> month views likes comments 1 2021-01 92 961 12 460 1 232 2 2021-02 32 947 7 434 2 124 3 2021-03 25 949 4 006 217 4 2021-04 196 356 14 541 2 169 5 2021-05 89 804 3 145 1 467 6 2021-06 66 140 10 087 2 509 7 2021-07 43 045 13 448 1 156 8 2021-08 156 670 10 972 2 480 9 2021-09 52 414 3 035 2 240 10 2021-10 142 657 11 400 1 716 11 2021-11 93 453 8 334 2 602 12 2021-12 7 604 1 138 88 <p>As you can see, doing this has added an extra column (month), as well as split the original row into 12 separate ones. Using this, we can see that our channel performed the best in April and the worst in December. It might be worth seeing what sort of content was put out in April (as well as August and November) and trying to do more of that going forward.</p>"},{"location":"guides/dimensions/#using-multiple-dimensions","title":"Using multiple dimensions","text":"<p>For report types that allow it, we can even split the data further; lets add \u201csubscribedStatus\u201d as a dimension (the below data has been truncated for brevity):</p> month subscribedStatus views likes comments 1 2021-01 SUBSCRIBED 32 725 5 768 35 2 2021-01 UNSUBSCRIBED 60 236 6 692 1 197 3 2021-02 SUBSCRIBED 7 601 1 274 633 4 2021-02 UNSUBSCRIBED 25 346 6 160 1 491 5 2021-03 SUBSCRIBED 6 360 343 95 6 2021-03 UNSUBSCRIBED 19 509 3 663 122 ... ... ... ... ... ... <p>Each month now has two rows, and the metrics for subscribed and unsubscribed viewers are now viewable. This data shows that our channel is being viewed by more unsubscribed viewers than subscribed ones, which is to be expected with any channel with at least a few thousand subscribers. January received a lot more likes from subscribed viewers than other months, so it might be worth looking at why that was.</p>"},{"location":"guides/dimensions/#valid-dimensions","title":"Valid dimensions","text":"<ul> <li>adType</li> <li>ageGroup <sup>1</sup></li> <li>audienceType</li> <li>channel <sup>1</sup> <sup>2</sup></li> <li>claimedStatus <sup>2</sup></li> <li>city</li> <li>country <sup>1</sup></li> <li>creatorContentType</li> <li>day <sup>1</sup></li> <li>deviceType</li> <li>elapsedVideoTimeRatio</li> <li>gender <sup>1</sup></li> <li>insightPlaybackLocationDetail</li> <li>insightPlaybackLocationType</li> <li>insightTrafficSourceDetail</li> <li>insightTrafficSourceType</li> <li>liveOrOnDemand</li> <li>month <sup>1</sup></li> <li>operatingSystem</li> <li>playlist</li> <li>province</li> <li>sharingService <sup>1</sup></li> <li>subscribedStatus</li> <li>uploaderType <sup>1</sup> <sup>2</sup></li> <li>video <sup>1</sup></li> <li>youtubeProduct</li> </ul> <ol> <li> <p>Core dimension (subject to YouTube\u2019s deprecation policy)\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Only supported in content owner reports\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"guides/filters/","title":"What are filters?","text":""},{"location":"guides/filters/#overview","title":"Overview","text":"<p>Filters allow for unwanted data to be omitted, leaving only the relevant data. This is useful when you only want data for a specific demographic, or in some cases, when setting what type of information you want. The vast majority of report types do not require you to provide a filter, though many report types can accept multiple filters.</p>"},{"location":"guides/filters/#retrieving-playlist-information","title":"Retrieving playlist information","text":"<p>Whether to retrieve video or playlist information is controlled through filters. In order to retrieve playlist information, you must passed the \"isCurated\" filter with value \"1\", like so:</p> <pre><code>filters={\"isCurated\": \"1\"}\n</code></pre> <p>Other filters can be additionally supplied as normal, provided they are supported by playlist report types.</p> <p>Warning</p> <p>This functionality is deprecated and will not work beyond 30 Jun 2024. See the guide on new playlist reports for more information.</p>"},{"location":"guides/filters/#other-special-cases","title":"Other special cases","text":"<p>There are a few other special cases worth keeping in mind:</p> <ul> <li>The \"country\" filter must be set to \"US\" when \"province\" is passed as a dimension</li> <li>The \"insightPlaybackLocationType\" filter must be set to \"EMBEDDED\" when \"insightPlaybackLocationDetail\" is passed as a dimension</li> <li>The \"insightTrafficSourceType\" filter must be set to one of the following when \"insightTrafficSourceDetail\" is passed as a dimension:<ul> <li>ADVERTISING</li> <li>CAMPAIGN_CARD</li> <li>END_SCREEN</li> <li>EXT_URL</li> <li>NOTIFICATION</li> <li>RELATED_VIDEO</li> <li>SUBSCRIBER</li> <li>YT_CHANNEL</li> <li>YT_OTHER_PAGE</li> <li>YT_SEARCH</li> </ul> </li> <li>The \"video\" filter cannot accept a comma-separated list of video IDs when \"elapsedVideoTimeRatio\" is passed as a dimension</li> </ul>"},{"location":"guides/filters/#valid-filters","title":"Valid filters","text":"<p>Click on a box to view the filter's possible values.</p> adType <ul> <li>auctionBumperInstream</li> <li>auctionDisplay</li> <li>auctionInstream</li> <li>auctionTrueviewInslate</li> <li>auctionTrueviewInstream</li> <li>auctionUnknown</li> <li>reservedBumperInstream</li> <li>reservedClickToPlay</li> <li>reservedDisplay</li> <li>reservedInstream</li> <li>reservedInstreamSelect</li> <li>reservedMasthead</li> <li>reservedUnknown</li> <li>unknown</li> </ul> ageGroup <ul> <li>age13-17</li> <li>age18-24</li> <li>age25-34</li> <li>age35-44</li> <li>age45-54</li> <li>age55-64</li> <li>age65-</li> </ul> audienceType <ul> <li>ORGANIC</li> <li>AD_INSTREAM</li> <li>AD_INDISPLAY</li> </ul> channel     Any channel ID.  claimedStatus <ul> <li>claimed</li> </ul> continent <ul> <li>002</li> <li>019</li> <li>142</li> <li>150</li> <li>009</li> </ul> country     Any ISO 3166-1 alpha-3 country code.  day     Any day in YYYY-MM-DD format.  deviceType <ul> <li>DESKTOP</li> <li>GAME_CONSOLE</li> <li>MOBILE</li> <li>TABLET</li> <li>TV</li> <li>UNKNOWN_PLATFORM</li> </ul> elapsedVideoTimeRatio     Any value (to a maximum of two significant figures) between 0.01 and 1 inclusive.  gender <ul> <li>female</li> <li>male</li> <li>user_specified</li> </ul> group     Any group ID.  insightPlaybackLocationType <ul> <li>BROWSE</li> <li>CHANNEL</li> <li>EMBEDDED</li> <li>EXTERNAL_APP</li> <li>MOBILE</li> <li>SEARCH</li> <li>WATCH</li> <li>YT_OTHER</li> </ul> insightPlaybackLocationDetail Not specified. insightTrafficSourceDetail <ul> <li>ADVERTISING</li> <li>CAMPAIGN_CARD</li> <li>END_SCREEN</li> <li>EXT_URL</li> <li>NOTIFICATION</li> <li>RELATED_VIDEO</li> <li>SUBSCRIBER</li> <li>YT_CHANNEL</li> <li>YT_OTHER_PAGE</li> <li>YT_SEARCH</li> </ul> insightTrafficSourceType <ul> <li>ADVERTISING</li> <li>ANNOTATION</li> <li>CAMPAIGN_CARD</li> <li>END_SCREEN</li> <li>EXT_URL</li> <li>NO_LINK_EMBEDDED</li> <li>NO_LINK_OTHER</li> <li>NOTIFICATION</li> <li>PLAYLIST</li> <li>PROMOTED</li> <li>RELATED_VIDEO</li> <li>SHORTS</li> <li>SUBSCRIBER</li> <li>YT_CHANNEL</li> <li>YT_OTHER_PAGE</li> <li>YT_PLAYLIST_PAGE</li> <li>YT_SEARCH</li> </ul> isCurated <ul> <li>1</li> </ul>     WARNING: This is deprecated and will be removed on 30 Jun 2024.  liveOrOnDemand <ul> <li>LIVE</li> <li>ON_DEMAND</li> </ul> month     Any day in YYYY-MM format.  operatingSystem <ul> <li>ANDROID</li> <li>BADA</li> <li>BLACKBERRY</li> <li>CHROMECAST</li> <li>DOCOMO</li> <li>FIREFOX</li> <li>HIPTOP</li> <li>IOS</li> <li>KAIOS</li> <li>LINUX</li> <li>MACINTOSH</li> <li>MEEGO</li> <li>NINTENDO_3DS</li> <li>OTHER</li> <li>PLAYSTATION</li> <li>PLAYSTATION_VITA</li> <li>REALMEDIA</li> <li>SMART_TV</li> <li>SYMBIAN</li> <li>TIZEN</li> <li>WEBOS</li> <li>WII</li> <li>WINDOWS</li> <li>WINDOWS_MOBILE</li> <li>XBOX</li> </ul> playlist     Any playlist ID.  province     Any ISO 3166-2 alpha-3 subdivision code.  sharingService <ul> <li>AMEBA</li> <li>ANDROID_EMAIL</li> <li>ANDROID_MESSENGER</li> <li>ANDROID_MMS</li> <li>BBM</li> <li>BLOGGER</li> <li>COPY_PASTE</li> <li>CYWORLD</li> <li>DIGG</li> <li>DROPBOX</li> <li>EMBED</li> <li>MAIL</li> <li>FACEBOOK</li> <li>FACEBOOK_MESSENGER</li> <li>FACEBOOK_PAGES</li> <li>FOTKA</li> <li>GMAIL</li> <li>GOO</li> <li>GOOGLEPLUS</li> <li>GO_SMS</li> <li>GROUPME</li> <li>HANGOUTS</li> <li>HI5</li> <li>HTC_MMS</li> <li>INBOX</li> <li>IOS_SYSTEM_ACTIVITY_DIALOG</li> <li>KAKAO_STORY</li> <li>KAKAO</li> <li>KIK</li> <li>LGE_EMAIL</li> <li>LINE</li> <li>LINKEDIN</li> <li>LIVEJOURNAL</li> <li>MENEAME</li> <li>MIXI</li> <li>MOTOROLA_MESSAGING</li> <li>MYSPACE</li> <li>NAVER</li> <li>NEARBY_SHARE</li> <li>NUJIJ</li> <li>ODNOKLASSNIKI</li> <li>OTHER</li> <li>PINTEREST</li> <li>RAKUTEN</li> <li>REDDIT</li> <li>SKYPE</li> <li>SKYBLOG</li> <li>SONY_CONVERSATIONS</li> <li>STUMBLEUPON</li> <li>TELEGRAM</li> <li>TEXT_MESSAGE</li> <li>TUENTI</li> <li>TUMBLR</li> <li>TWITTER</li> <li>UNKNOWN</li> <li>VERIZON_MMS</li> <li>VIBER</li> <li>VKONTATKE</li> <li>WECHAT</li> <li>WEIBO</li> <li>WHATS_APP</li> <li>WYKOP</li> <li>YAHOO</li> <li>YOUTUBE_GAMING</li> <li>YOUTUBE_KIDS</li> <li>YOUTUBE_MUSIC</li> <li>YOUTUBE_TV</li> </ul> subContinent <ul> <li>014</li> <li>017</li> <li>015</li> <li>018</li> <li>011</li> <li>029</li> <li>013</li> <li>021</li> <li>005</li> <li>143</li> <li>030</li> <li>034</li> <li>035</li> <li>145</li> <li>151</li> <li>154</li> <li>039</li> <li>155</li> <li>053</li> <li>054</li> <li>057</li> <li>061</li> </ul> subscribedStatus <ul> <li>SUBSCRIBED</li> <li>UNSUBSCRIBED</li> </ul> uploaderType <ul> <li>self</li> <li>thirdParty</li> </ul> video     Any video ID.  youtubeProduct <ul> <li>CORE</li> <li>GAMING</li> <li>KIDS</li> <li>UNKNOWN</li> </ul>"},{"location":"guides/metrics/","title":"What are metrics?","text":""},{"location":"guides/metrics/#overview","title":"Overview","text":"<p>Metrics define the information you wish to retrieve, and every provided metric is a column in the report (always to the right of all dimensions). This is useful when you want to fine-tune exactly what information you retrieve.</p> <p>All metric data is numeric.</p>"},{"location":"guides/metrics/#selecting-metrics","title":"Selecting metrics","text":"<p>The YouTube Analytics API defines many report types (for which there is a separate guide), and each defines a different set of valid metrics. It can be difficult to tell exactly which metrics are valid for each report, but if you're not sure, you may not have to worry. If you do not provide any metrics when retrieving reports, analytix will automatically include every metric the report type supports in the report. This means you only ever need to supply a series of metrics if you want your report to focus on very specific information.</p>"},{"location":"guides/metrics/#valid-metrics","title":"Valid metrics","text":"<ul> <li>views <sup>1</sup></li> <li>redViews</li> <li>comments <sup>1</sup></li> <li>likes <sup>1</sup></li> <li>dislikes <sup>1</sup></li> <li>videosAddedToPlaylists</li> <li>videosRemovedFromPlaylists</li> <li>shares <sup>1</sup></li> <li>estimatedMinutesWatched <sup>1</sup></li> <li>estimatedRedMinutesWatched</li> <li>averageViewDuration <sup>1</sup></li> <li>averageViewPercentage</li> <li>annotationClickThroughRate <sup>1</sup></li> <li>annotationCloseRate <sup>1</sup></li> <li>annotationImpressions</li> <li>annotationClickableImpressions</li> <li>annotationClosableImpressions</li> <li>annotationClicks</li> <li>annotationCloses</li> <li>cardClickRate</li> <li>cardTeaserClickRate</li> <li>cardImpressions</li> <li>cardTeaserImpressions</li> <li>cardClicks</li> <li>cardTeaserClicks</li> <li>subscribersGained <sup>1</sup></li> <li>subscribersLost <sup>1</sup></li> <li>estimatedRevenue <sup>1</sup></li> <li>estimatedAdRevenue</li> <li>grossRevenue</li> <li>estimatedRedPartnerRevenue</li> <li>monetizedPlaybacks</li> <li>playbackBasedCpm</li> <li>adImpressions</li> <li>cpm</li> <li>viewerPercentage <sup>1</sup></li> <li>audienceWatchRatio</li> <li>relativeRetentionPerformance</li> <li>averageTimeInPlaylist</li> <li>playlistAverageViewDuration</li> <li>playlistEstimatedMinutesWatched</li> <li>playlistSaves</li> <li>playlistStarts</li> <li>playlistViews</li> <li>viewsPerPlaylistStart</li> </ul> <ol> <li> <p>Core metric (subject to YouTube\u2019s deprecation policy)\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"guides/new-playlist-reports/","title":"Migrating to new playlist reports","text":"<p>See Also</p> <p>You can read about the API changes in full on the YouTube Analytics API documentation.</p>"},{"location":"guides/new-playlist-reports/#overview","title":"Overview","text":"<p>The \"isCurated\" filter was deprecated by YouTube and ceased to work on 30 Jun 2024. As a result, legacy playlist reports will no longer work.</p> <p>From v5.3, only new playlist reports are supported (though v5.2 supported both new and legacy playlist reports). Attempting to fetch playlist reports in earlier versions will raise an <code>APIError</code>.</p> <p>There are no breaking changes to analytix's functionality outside of these API changes.</p>"},{"location":"guides/new-playlist-reports/#whats-different","title":"What's different?","text":""},{"location":"guides/new-playlist-reports/#accessing-playlist-reports","title":"Accessing playlist reports","text":"<p>Previously, analytix determined a report was a playlist report if the \"isCurated\" filter was provided. Now, this determination is made based on whether any of these conditions are true:</p> <ul> <li>The \"playlist\" dimension is provided</li> <li>The \"playlist\" filter is provided</li> <li>The \"group\" filter and at least one playlist metric are provided</li> </ul>"},{"location":"guides/new-playlist-reports/#dimensions-and-filters","title":"Dimensions and filters","text":"<p>Most new playlist reports support far fewer dimensions and filters and most require you to filter either by playlist or by group. The only exception is the \"Top playlists\" report which takes \"playlist\" as a dimension.</p> <p>As an example, when fetching time-based playlist activity, this is possible using deprecated reports:</p> <pre><code># This will no longer work.\nreport = client.fetch_report(\n    dimensions=(\"day\", \"youtubeProduct\"),\n    filters={\n        \"isCurated\": \"1\",\n        \"playlist\": \"a1b2c3d4e5\",\n        \"country\": \"US\",\n        \"subscribedStatus\": \"SUBSCRIBED\",\n    },\n)\nassert report.type.name == \"Time-based activity for playlists (deprecated)\"\n</code></pre> <p>With the new reports, this is as close as you can get:</p> <pre><code>report = client.fetch_report(\n    dimensions=(\"day\",),\n    filters={\n        \"playlist\": \"a1b2c3d4e5\",\n    },\n)\nassert report.type.name == \"Time-based activity for playlists\"\n</code></pre>"},{"location":"guides/new-playlist-reports/#metrics","title":"Metrics","text":"<p>YouTube Red-related metrics are not supported in new playlist reports, though some new metrics have been added:</p> <ul> <li>playlistAverageViewDuration</li> <li>playlistEstimatedMinutesWatched</li> <li>playlistSaves</li> <li>playlistViews</li> </ul> <p>There are also now two types of playlist metrics:</p> <ul> <li>Aggregate video metrics, which look at all data for videos within a playlist (only supported when the \"isCurated\" filter is not provided)</li> <li>In-playlist metrics, which only look at data where the interactions happened within the playlist itself</li> </ul> <p>Previously, all metrics were in-playlist.</p> <p>Some metrics are making the switch between in-playlist and aggregate, an example being the \"views\" metric. When the \"isCurated\" filter is provided, it acts as an in-playlist metric, otherwise it acts as an aggregate metric. In this case, the \"playlistViews\" metric serves as the in-playlist equivalent to \"views\".</p> <p>So this...</p> <pre><code>report = client.fetch_report(\n    metrics=(\"views\",),\n    filters={\n        \"isCurated\": \"1\",\n        \"playlist\": \"a1b2c3d4e5\",\n    },\n)\nassert report.type.name == \"Basic user activity for playlists (deprecated)\"\n</code></pre> <p>...is equivalent to this:</p> <pre><code>report = client.fetch_report(\n    metrics=(\"playlistViews\",),\n    filters={\n        \"playlist\": \"a1b2c3d4e5\",\n    },\n)\nassert report.type.name == \"Basic user activity for playlists\"\n</code></pre> <p>Both can be selected in the same report, and analytix always does so where possible by default.</p>"},{"location":"guides/report-types/","title":"What are report types?","text":""},{"location":"guides/report-types/#overview","title":"Overview","text":"<p>Report types define what can be provided in a request. analytix automatically selects the most appropriate report type based on the dimensions, filters, and metrics you provide, so it is probably easier to think of report types as a single standard for validating requests.</p>"},{"location":"guides/report-types/#validation","title":"Validation","text":"<p>Each report type has a set of valid:</p> <ul> <li>Dimensions</li> <li>Filters</li> <li>Metrics</li> <li>Sort options (usually the same as the valid metrics)</li> </ul> <p>After a report type is selected by analytix, the provided attributes are compared against the valid ones for that report type, and errors are thrown on mismatches. For example, if \"day\" and \"country\" (two incompatible dimensions) are both provided, analytix will detect this and throw an error. From v4.1.4, these errors are much clearer.</p> <p>This provides a system with which to prevent invalid requests from counting toward your API quota, as well as one to detail the errors you make, something that the YouTube Analytics API doesn't do.</p>"},{"location":"guides/report-types/#detailed-report-types","title":"Detailed report types","text":"<p>Some report types are stricter that others; they also have:</p> <ul> <li>A reduced set of valid sort options, separate to the set of valid metrics</li> <li>A maximum number of results (normally 200)</li> </ul> <p>These report types are referred to internally as \"detailed report types\". Oftentimes, they are also far more picky about what filters can be provided and the values that can be passed to them.</p>"},{"location":"guides/report-types/#list-of-report-types","title":"List of report types","text":"<p>Below is a list of all possible report types, complete with links to official documentation resources.</p> <p>Warning</p> <p>The official documentation is not 100% accurate. analytix does account for this wherever possible, but note some behaviour may not be as expected.</p> <p>Note</p> <p>Content owner reports are not supported.</p>"},{"location":"guides/report-types/#video-report-types","title":"Video report types","text":"<ul> <li>Basic user activity</li> <li>Basic user activity (US)</li> <li>Time-based activity</li> <li>Time-based activity (US)</li> <li>Geography-based activity</li> <li>Geography-based activity (US)</li> <li>Geography-based activity (by city) <sup>1</sup> <sup>2</sup></li> <li>User activity by subscribed status</li> <li>User activity by subscribed status (US)</li> <li>Time-based playback details (live)</li> <li>Time-based playback details (view percentage)</li> <li>Geography-based playback details (live)</li> <li>Geography-based playback details (view percentage)</li> <li>Geography-based playback details (live, US)</li> <li>Geography-based playback details (view percentage, US)</li> <li>Playback locations</li> <li>Playback locations (detailed) <sup>1</sup></li> <li>Traffic sources</li> <li>Traffic sources (detailed) <sup>1</sup></li> <li>Device types</li> <li>Operating systems</li> <li>Device types and operating systems</li> <li>Viewer demographics</li> <li>Engagement and content sharing</li> <li>Audience retention</li> <li>Top videos by region <sup>1</sup></li> <li>Top videos by state <sup>1</sup></li> <li>Top videos by subscription status <sup>1</sup></li> <li>Top videos by YouTube product <sup>1</sup></li> <li>Top videos by playback detail <sup>1</sup></li> </ul>"},{"location":"guides/report-types/#playlist-report-types","title":"Playlist report types","text":"<ul> <li>Basic user activity for playlists</li> <li>Time-based activity for playlists</li> <li>Geography-based activity for playlists</li> <li>Geography-based activity for playlists (US)</li> <li>Playback locations for playlists</li> <li>Playback locations for playlists (detailed) <sup>1</sup></li> <li>Traffic sources for playlists</li> <li>Traffic sources for playlists (detailed) <sup>1</sup></li> <li>Device types for playlists</li> <li>Operating systems for playlists</li> <li>Device types and operating systems for playlists</li> <li>Viewer demographics for playlists</li> <li>Top playlists <sup>1</sup></li> </ul>"},{"location":"guides/report-types/#ad-performance-report-types","title":"Ad performance report types","text":"<ul> <li>Ad performance</li> </ul> <ol> <li> <p>Detailed report type\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>The documentation for this report type is incorrect (as of 15 Jan 2023). The actual max number of results is 25.\u00a0\u21a9</p> </li> </ol>"},{"location":"guides/sort-options/","title":"What are sort options?","text":""},{"location":"guides/sort-options/#overview","title":"Overview","text":"<p>Sort options control how the report is sorted. This is useful when you want data sorted by a particular metric instead of the default behaviour.</p>"},{"location":"guides/sort-options/#sorting-reports","title":"Sorting reports","text":"<p>By default, reports are sorted by dimensions (from left to right), however you can sort the report by any metric by providing it as a sort option:</p> <pre><code>sort_options=[\"views\"]\n</code></pre> <p>This will sort all rows in the report by the number of views from lowest to highest.</p>"},{"location":"guides/sort-options/#sorting-in-descending-order","title":"Sorting in descending order","text":"<p>If you wish to sort in descending order, prefix the metric with a hyphen:</p> <pre><code>sort_options=[\"-views\"]\n</code></pre> <p>This will now sort all rows from highest to lowest.</p>"},{"location":"guides/sort-options/#sorting-by-multiple-metrics","title":"Sorting by multiple metrics","text":"<p>To sort by multiple metrics, provide multiple sort options:</p> <pre><code>sort_options=[\"views\", \"-likes\", \"comments\"]\n</code></pre> <p>This will sort the report using the following rules:</p> <ul> <li>Sort all rows by the number of views from lowest to highest</li> <li>Sort all rows with the same number of views by the number of likes from highest to lowest</li> <li>Sort all rows with the same number of views and likes by the number of comments from lowest to highest</li> </ul> <p>Note that the order does matter. For example, putting \"likes\" first in the list would mean all rows are sorted by likes first.</p>"},{"location":"guides/sort-options/#valid-sort-options","title":"Valid sort options","text":"<p>See the list of valid metrics.</p>"},{"location":"guides/migrating/v3-v4/","title":"Migrating from v3.x to v4.x","text":"<p>This page provides information to help users transition from version 3 to version 4 of analytix.</p> <p>Danger</p> <p>Version 4 is no longer supported. While you can still use this guide if you're upgrading from version 3, it is strongly recommended you upgrade straight to version 5 afterwards.</p> <p>Important</p> <p>Only changes between v3.6.1 and v4.0.0 are detailed here. For additional changes, view the changelog.</p>"},{"location":"guides/migrating/v3-v4/#the-clients","title":"The Clients","text":"<ul> <li>The <code>Analytics</code> class has been renamed to <code>Client</code></li> <li>The <code>AsyncAnalytics</code> class has been renamed to <code>AsyncClient</code></li> <li>There is a new <code>AsyncBaseClient</code> which can be used when building web applications</li> <li>The <code>with_secrets()</code> classmethod no longer exists -- you should now pass the path to your secrets file directly to the constructor</li> <li>The <code>close_session()</code> method has been renamed to <code>teardown()</code></li> <li>The <code>retrieve()</code> method has been renamed to <code>retrieve_report()</code></li> <li>The sync client no longer has a separate implementation, and is instead a wrapper of the async client</li> <li>The clients now use AIOHTTP instead of HTTPX for requests</li> <li>Update checks now happen upon client construction and cannot be surpressed</li> <li>The clients now have better support for multiple channels</li> </ul>"},{"location":"guides/migrating/v3-v4/#authorisation","title":"Authorisation","text":"<ul> <li>Out-of-bounds (manual copy/paste) authorisation is no longer supported</li> <li>Authorisation parameters should now be passed to the client constructor rather than to instance methods</li> <li>Authorisation can no longer be forced using the <code>force</code> kwarg</li> <li>The access token refresh token can no longer be skipped</li> <li>State token confirmation is now performed</li> <li>Replay protection is now present</li> <li>Web secrets are now supported</li> <li>The <code>Secrets.to_dict()</code> method now returns the data as a complete file, rather than just the inner-most dictionary</li> <li>The <code>Tokens.from_data()</code> method has been renamed <code>Tokens.from_dict()</code></li> <li>Secrets files can no longer be opened asynchronously</li> <li>Token files can no longer be opened or written to synchronously</li> </ul>"},{"location":"guides/migrating/v3-v4/#reports","title":"Reports","text":"<ul> <li>The <code>Report</code> class has been renamed to <code>AnalyticsReport</code></li> <li>The <code>ColumnHeader.from_json()</code> classmethod has been removed</li> <li>The <code>ColumnHeader.data</code> property has been added</li> <li><code>AnalyticsReport.data</code> has been replaced with <code>AnalyticsReport.resource</code>, which is a <code>ResultTable</code> instance<ul> <li>You can still access the raw data using the <code>data</code> attribute of the <code>resource</code> instance</li> </ul> </li> <li><code>AnalyticsReport.column_headers</code> is now <code>AnalyticsReport.resource.column_headers</code></li> <li>The <code>AnalyticsReport.rows</code> property has been removed</li> <li>The <code>AnalyticsReport.ordered_dimensions</code> and <code>.ordered_metrics</code> properties have been removed</li> <li>The <code>AnalyticsReport.dimensions</code> and <code>.metrics</code> properties now mirror the behaviours of their ordered counterparts</li> <li>The <code>AnalyticsReport.numeric</code> and <code>.non_numeric</code> properties have been added</li> <li>JSON reports can now be properly written as one-line files</li> <li>JSON and CSV reports can no longer be written asynchronously</li> <li>You can now control whether JSON, CSV, Excel, Feather, and Parquet files are overwritten (the default is <code>True</code>)</li> <li>Modin support has been removed</li> <li><code>AnalyticsReport.to_dataframe()</code> has been renamed to <code>.to_pandas()</code></li> <li>Converting to a Polars DataFrame no longer requires the use of PyArrow</li> </ul>"},{"location":"guides/migrating/v3-v4/#groups","title":"Groups","text":"<ul> <li>You can now fetch information on groups and group items!<ul> <li><code>client.fetch_groups()</code></li> <li><code>client.fetch_group_items()</code></li> </ul> </li> </ul>"},{"location":"guides/migrating/v3-v4/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>Errors have been simplified, and some error messages have been improved</li> </ul>"},{"location":"guides/migrating/v4-v5/","title":"Migrating from v4.x to v5.x","text":"<p>This document aims to assist you in migrating from analytix v4.2 to v5.0. It does not aim to be entirely comprehensive, but instead cover the biggest changes to users. All changed classes and methods have change descriptions in their docstrings.</p> <p>Important</p> <p>Only changes between v4.2.3 and v5.0.0 are detailed here. For additional changes, view the changelog.</p>"},{"location":"guides/migrating/v4-v5/#python-support","title":"Python support","text":"<ul> <li>Support for Python 3.7 has been removed</li> <li>Support for Pythons 3.12 and 3.13-dev has been added</li> </ul>"},{"location":"guides/migrating/v4-v5/#clients-and-shards","title":"Clients and shards","text":""},{"location":"guides/migrating/v4-v5/#interfaces","title":"Interfaces","text":"<p>A number of significant changes have been made to the client interfaces.</p> <ul> <li>There are now only two clients: <code>BaseClient</code> and <code>Client</code></li> <li>These clients are both fully synchronous<ul> <li>An extension library may be made at some point for those that still need async capabilites</li> <li>You should be able to run analytix in an executor if you absolutely need async support</li> </ul> </li> <li>Clients no longer need to be torn down, but retain the context manager for the sake of ease</li> <li>Monetary data is now no longer accessible by default and the fetching of such data needs to be manually enabled</li> <li>Various method names have changed</li> <li>Sensitive data is no longer emitted in debug logs</li> </ul>"},{"location":"guides/migrating/v4-v5/#authorisation","title":"Authorisation","text":"<p>The clients are now much smarter and have much more power when it comes to authorisation.</p> <ul> <li>The scripting client is now able to detect if the stored token's scopes are sufficient to perform the requested action, and trigger reauthorisation if not</li> <li>This is done using the <code>scopes_are_sufficient</code> method of the clients, which is publically accessible</li> <li>Client, not shards, now handle token refreshing</li> <li>Shards can now be given a different set of scopes to their parent clients</li> <li>The scripting client's authorise method can no longer accept token file filenames -- the base client should be properly utilised in these instances</li> <li>You now have more control over when authorisation should be forced and when access tokens should be refreshed</li> </ul>"},{"location":"guides/migrating/v4-v5/#reports","title":"Reports","text":"<p>Report interfaces are very similar to before, but a few changes have been made.</p> <ul> <li><code>AnalyticsReport</code> is now <code>Report</code></li> <li>Files will no longer be overwritten by default</li> <li>You can now pass additional arguments to the <code>to_feather</code> and <code>to_parquet</code> methods to be passed to PyArrow's respective methods</li> <li>These methods also no longer return Arrow tables</li> <li>JSON exports are no longer indented by default</li> <li>You can also now pass additional arguments to <code>to_json</code> to be passed to <code>json.dump</code><ul> <li>Because of this, <code>indent</code> is no longer an argument for this method</li> </ul> </li> <li>The <code>Report</code> and <code>ResultTable</code> classes are now in separate files<ul> <li>The <code>ResultTable</code> class has not changed</li> </ul> </li> </ul>"},{"location":"guides/migrating/v4-v5/#groups","title":"Groups","text":"<ul> <li><code>GroupList</code> and <code>GroupItemList</code> objects are now iterable</li> <li>You can now fetch a groups items by calling its <code>fetch_items</code> method</li> <li>Group objects are now documented!</li> </ul>"},{"location":"guides/migrating/v5-v6/","title":"Migrating from v5.x to v6.x","text":"<p>This document aims to assist you in migrating from analytix v5.x to v6.0. It does not aim to be entirely comprehensive, but instead cover the biggest changes to users. All changed classes and methods have change descriptions in their docstrings.</p> <p>Warning</p> <p>Version 6 is still in development. It is recommended you do not use it production yet.</p>"},{"location":"guides/migrating/v5-v6/#authorisation","title":"Authorisation","text":"<p>Many of the authorisation methods previously bound to the <code>Client</code> are now bound to <code>Tokens</code> instead:</p> <ul> <li><code>client.token_is_valid()</code> \u2794 <code>not tokens.expired</code></li> <li><code>client.scopes_are_sufficient()</code> \u2794 <code>tokens.are_scoped_for()</code></li> <li><code>client.decode_id_token()</code> \u2794 <code>tokens.decoded_id_token</code></li> </ul>"},{"location":"reference/auth/","title":"auth","text":""},{"location":"reference/auth/#analytix.auth.Scopes","title":"Scopes","text":"<p>               Bases: <code>Flag</code></p> <p>An enum for API scopes.</p> <p>Possible values are:</p> <ul> <li><code>READONLY</code> \u2014 Don't include revenue data from reports</li> <li><code>MONETARY_READONLY</code> \u2014 Only include revenue data from reports</li> <li><code>ALL_READONLY</code> \u2014 Include all data in reports</li> <li><code>OPENID</code> \u2014 Enable the OpenID scope</li> <li><code>PROFILE</code> \u2014 Include profile information in JWTs</li> <li><code>EMAIL</code> \u2014 Include email information in JWTs</li> <li><code>ALL_JWT</code> \u2014 Include all available information in JWTs</li> <li><code>ALL</code> \u2014 Include all data in reports</li> </ul> Changed in version 6.0 <p>The <code>ALL_READONLY</code> scope has been added and mimics the behaviour of the <code>ALL</code> scope from v5. The <code>ALL</code> scope now includes all JWT scopes.</p> Changed in version 5.1 <ul> <li>Added the <code>OPENID</code>, <code>PROFILE</code>, <code>EMAIL</code>, and <code>ALL_JWT</code> scopes</li> <li>This now works like a flag enum rather than a normal one; this   doesn't introduce any breaking changes (unless you're using   analytix in a particularly unconventional way), but does mean   you can now use a <code>|</code> to concatenate scopes</li> </ul> Source code in <code>analytix/auth/scopes.py</code> <pre><code>class Scopes(Flag):\n    \"\"\"An enum for API scopes.\n\n    Possible values are:\n\n    * `READONLY` \u2014 Don't include revenue data from reports\n    * `MONETARY_READONLY` \u2014 Only include revenue data from reports\n    * `ALL_READONLY` \u2014 Include all data in reports\n    * `OPENID` \u2014 Enable the OpenID scope\n    * `PROFILE` \u2014 Include profile information in JWTs\n    * `EMAIL` \u2014 Include email information in JWTs\n    * `ALL_JWT` \u2014 Include all available information in JWTs\n    * `ALL` \u2014 Include all data in reports\n\n    ???+ note \"Changed in version 6.0\"\n        The `ALL_READONLY` scope has been added and mimics the behaviour\n        of the `ALL` scope from v5. The `ALL` scope now includes all JWT\n        scopes.\n\n    ???+ note \"Changed in version 5.1\"\n        * Added the `OPENID`, `PROFILE`, `EMAIL`, and `ALL_JWT` scopes\n        * This now works like a flag enum rather than a normal one; this\n          doesn't introduce any breaking changes (unless you're using\n          analytix in a particularly unconventional way), but does mean\n          you can now use a `|` to concatenate scopes\n    \"\"\"\n\n    READONLY = 1 &lt;&lt; 0\n    MONETARY_READONLY = 1 &lt;&lt; 1\n    ALL_READONLY = READONLY | MONETARY_READONLY\n    OPENID = 1 &lt;&lt; 2\n    PROFILE = 1 &lt;&lt; 3\n    EMAIL = 1 &lt;&lt; 4\n    ALL_JWT = OPENID | PROFILE | EMAIL\n    ALL = ALL_READONLY | ALL_JWT\n\n    @property\n    def formatted(self) -&gt; str:\n        return \" \".join(\n            url for i, url in enumerate(SCOPE_URLS) if self.value &amp; (1 &lt;&lt; i)\n        )\n\n    def validate(self) -&gt; None:\n        if not (self.value &amp; (1 &lt;&lt; 0) or self.value &amp; (1 &lt;&lt; 1)):\n            raise AuthorisationError(\n                \"the READONLY or MONETARY_READONLY scope must be provided\",\n            )\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Secrets","title":"Secrets  <code>dataclass</code>","text":"<p>A set of API secrets.</p> <p>This should always be created using the <code>load_from</code> classmethod.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Literal['installed', 'web']</code> <p>The application type. This will always be either \"installed\" or \"web\".</p> required <code>client_id</code> <code>str</code> <p>The client ID.</p> required <code>project_id</code> <code>str</code> <p>The name of the project.</p> required <code>auth_uri</code> <code>str</code> <p>The authorisation server endpoint URI.</p> required <code>token_uri</code> <code>str</code> <p>The token server endpoint URI.</p> required <code>auth_provider_x509_cert_url</code> <code>str</code> <p>The URL of the public x509 certificate, used to verify the signature on JWTs, such as ID tokens, signed by the authentication provider.</p> required <code>client_secret</code> <code>str</code> <p>The client secret.</p> required <code>redirect_uris</code> <code>List[str]</code> <p>A list of valid redirection endpoint URIs. This list should match the list entered for the client ID on the API Access pane of the Google APIs Console.</p> required Source code in <code>analytix/auth/secrets.py</code> <pre><code>@dataclass(frozen=True)\nclass Secrets:\n    \"\"\"A set of API secrets.\n\n    This should always be created using the `load_from` classmethod.\n\n    Parameters\n    ----------\n    type\n        The application type. This will always be either \"installed\" or\n        \"web\".\n    client_id\n        The client ID.\n    project_id\n        The name of the project.\n    auth_uri\n        The authorisation server endpoint URI.\n    token_uri\n        The token server endpoint URI.\n    auth_provider_x509_cert_url\n        The URL of the public x509 certificate, used to verify the\n        signature on JWTs, such as ID tokens, signed by the\n        authentication provider.\n    client_secret\n        The client secret.\n    redirect_uris\n        A list of valid redirection endpoint URIs. This list should\n        match the list entered for the client ID on the API Access pane\n        of the Google APIs Console.\n    \"\"\"\n\n    __slots__ = (\n        \"type\",\n        \"client_id\",\n        \"project_id\",\n        \"auth_uri\",\n        \"token_uri\",\n        \"auth_provider_x509_cert_url\",\n        \"client_secret\",\n        \"redirect_uris\",\n    )\n\n    type: Literal[\"installed\", \"web\"]\n    client_id: str\n    project_id: str\n    auth_uri: str\n    token_uri: str\n    auth_provider_x509_cert_url: str\n    client_secret: str\n    redirect_uris: List[str]\n\n    @classmethod\n    def load_from(cls, path: PathLike) -&gt; \"Secrets\":\n        \"\"\"Load secrets from a JSON file.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `from_file`.\n\n        Parameters\n        ----------\n        path\n            The path to your secrets file.\n\n        Returns\n        -------\n        Secrets\n            Your secrets.\n\n        Raises\n        ------\n        FileNotFoundError\n            No secrets file exists at the given path.\n        JSONDecodeError\n            The given file is not a valid JSON file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Secrets.load_from(\"secrets.json\")\n        Secrets(type=\"installed\", ...)\n        \"\"\"\n        secrets_file = Path(path)\n\n        if _log.isEnabledFor(logging.DEBUG):\n            _log.debug(\"Loading secrets from %s\", secrets_file.resolve())\n\n        data = json.loads(secrets_file.read_text())\n        key = next(iter(data.keys()))\n        return cls(\n            type=key,\n            client_id=data[key][\"client_id\"],\n            project_id=data[key][\"project_id\"],\n            auth_uri=data[key][\"auth_uri\"],\n            token_uri=data[key][\"token_uri\"],\n            auth_provider_x509_cert_url=data[key][\"auth_provider_x509_cert_url\"],\n            client_secret=data[key][\"client_secret\"],\n            redirect_uris=data[key][\"redirect_uris\"],\n        )\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Secrets.load_from","title":"load_from  <code>classmethod</code>","text":"<pre><code>load_from(path: PathLike) -&gt; Secrets\n</code></pre> <p>Load secrets from a JSON file.</p> Changed in version 5.0 <p>This used to be <code>from_file</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to your secrets file.</p> required <p>Returns:</p> Type Description <code>Secrets</code> <p>Your secrets.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>No secrets file exists at the given path.</p> <code>JSONDecodeError</code> <p>The given file is not a valid JSON file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Secrets.load_from(\"secrets.json\")\nSecrets(type=\"installed\", ...)\n</code></pre> Source code in <code>analytix/auth/secrets.py</code> <pre><code>@classmethod\ndef load_from(cls, path: PathLike) -&gt; \"Secrets\":\n    \"\"\"Load secrets from a JSON file.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `from_file`.\n\n    Parameters\n    ----------\n    path\n        The path to your secrets file.\n\n    Returns\n    -------\n    Secrets\n        Your secrets.\n\n    Raises\n    ------\n    FileNotFoundError\n        No secrets file exists at the given path.\n    JSONDecodeError\n        The given file is not a valid JSON file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Secrets.load_from(\"secrets.json\")\n    Secrets(type=\"installed\", ...)\n    \"\"\"\n    secrets_file = Path(path)\n\n    if _log.isEnabledFor(logging.DEBUG):\n        _log.debug(\"Loading secrets from %s\", secrets_file.resolve())\n\n    data = json.loads(secrets_file.read_text())\n    key = next(iter(data.keys()))\n    return cls(\n        type=key,\n        client_id=data[key][\"client_id\"],\n        project_id=data[key][\"project_id\"],\n        auth_uri=data[key][\"auth_uri\"],\n        token_uri=data[key][\"token_uri\"],\n        auth_provider_x509_cert_url=data[key][\"auth_provider_x509_cert_url\"],\n        client_secret=data[key][\"client_secret\"],\n        redirect_uris=data[key][\"redirect_uris\"],\n    )\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens","title":"Tokens  <code>dataclass</code>","text":"<p>               Bases: <code>RequestMixin</code></p> <p>OAuth tokens.</p> <p>This should always be created using one of the available classmethods.</p> Changed in version 6.0 <p>The <code>expires_in</code> attribute will now show an accurate figure instead of <code>3599</code> perpetually. Due to the way it's been implemented, it can't be updated manually.</p> <p>Parameters:</p> Name Type Description Default <code>access_token</code> <code>str</code> <p>A token that can be sent to a Google API.</p> required <code>expires_in</code> <code>_ExpiresIn</code> <p>The remaining lifetime of the access token in seconds.</p> <code>_ExpiresIn()</code> <code>scope</code> <code>str</code> <p>The scopes of access granted by the access_token expressed as a list of space-delimited, case-sensitive strings.</p> required <code>token_type</code> <code>Literal['Bearer']</code> <p>Identifies the type of token returned. This will always be \"Bearer\".</p> required <code>refresh_token</code> <code>str</code> <p>A token that can be used to refresh your access token.</p> required <code>id_token</code> <code>Optional[str]</code> <p>A JWT that contains identity information about the user that is digitally signed by Google. This will be <code>None</code> if you did not specifically request JWT tokens when authorising.</p> <code>None</code> Source code in <code>analytix/auth/tokens.py</code> <pre><code>@dataclass()\nclass Tokens(RequestMixin):\n    \"\"\"OAuth tokens.\n\n    This should always be created using one of the available\n    classmethods.\n\n    ???+ note \"Changed in version 6.0\"\n        The `expires_in` attribute will now show an accurate figure\n        instead of `3599` perpetually. Due to the way it's been\n        implemented, it can't be updated manually.\n\n    Parameters\n    ----------\n    access_token\n        A token that can be sent to a Google API.\n    expires_in\n        The remaining lifetime of the access token in seconds.\n    scope\n        The scopes of access granted by the access_token expressed as a\n        list of space-delimited, case-sensitive strings.\n    token_type\n        Identifies the type of token returned. This will always be\n        \"Bearer\".\n    refresh_token\n        A token that can be used to refresh your access token.\n    id_token\n        A JWT that contains identity information about the user that is\n        digitally signed by Google. This will be `None` if you did not\n        specifically request JWT tokens when authorising.\n    \"\"\"\n\n    access_token: str\n    scope: str\n    token_type: Literal[\"Bearer\"]\n    refresh_token: str\n    expires_in: _ExpiresIn = _ExpiresIn()\n    id_token: Optional[str] = None\n    _path: Optional[Path] = field(default=None, init=False, repr=False)\n\n    @classmethod\n    def load_from(cls, path: PathLike) -&gt; \"Tokens\":\n        \"\"\"Load tokens from a JSON file.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `from_file`.\n\n        Parameters\n        ----------\n        path\n            The path to your tokens file.\n\n        Returns\n        -------\n        Tokens\n            Your tokens.\n\n        Raises\n        ------\n        FileNotFoundError\n            No tokens file exists at the given path.\n        JSONDecodeError\n            The given file is not a valid JSON file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.load_from(\"tokens.json\")\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        tokens_file = Path(path)\n\n        if _log.isEnabledFor(logging.DEBUG):\n            _log.debug(\"Loading tokens from %s\", tokens_file.resolve())\n\n        self = cls.from_json(tokens_file.read_text())\n        self._path = tokens_file\n        return self\n\n    @classmethod\n    def from_json(cls, data: Union[str, bytes]) -&gt; \"Tokens\":\n        \"\"\"Load tokens from raw JSON data.\n\n        Parameters\n        ----------\n        data\n            Your tokens in JSON form.\n\n        Returns\n        -------\n        Tokens\n            Your tokens.\n\n        Raises\n        ------\n        JSONDecodeError\n            The given file is not a valid JSON file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.from_json('{\"access_token\": \"1234567890\", ...}')\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        return cls(**json.loads(data))\n\n    def save_to(self, path: PathLike) -&gt; None:\n        \"\"\"Save your tokens to disk.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `write`.\n\n        Parameters\n        ----------\n        path\n            The path to save your tokens to.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.save_to(\"tokens.json\")\n        \"\"\"\n        tokens_file = Path(path)\n\n        if _log.isEnabledFor(logging.DEBUG):\n            _log.debug(\"Saving tokens to %s\", tokens_file.resolve())\n\n        attrs = {\n            \"access_token\": self.access_token,\n            \"expires_in\": self.expires_in,\n            \"scope\": self.scope,\n            \"token_type\": self.token_type,\n            \"refresh_token\": self.refresh_token,\n            **({\"id_token\": self.id_token} if self.id_token else {}),\n        }\n        tokens_file.write_text(json.dumps(attrs))\n        self._path = tokens_file\n\n    def refresh(self, data: Union[str, bytes]) -&gt; \"Tokens\":\n        \"\"\"Updates your tokens to match those you refreshed.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `update`.\n\n        Parameters\n        ----------\n        data\n            Your refreshed tokens in JSON form. These will not entirely\n            replace your previous tokens, but instead update any\n            out-of-date keys.\n\n        Returns\n        -------\n        Tokens\n            Your refreshed tokens.\n\n        See Also\n        --------\n        * This method does not actually refresh your access token;\n          for that, you'll need to use `Client.refresh_access_token`.\n        * To save tokens, you'll need the `save_to` method.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.refresh('{\"access_token\": \"abcdefghij\", ...}')\n        Tokens(access_token=\"abcdefghij\", ...)\n        \"\"\"\n        attrs = json.loads(data)\n        for key, value in attrs.items():\n            setattr(self, key, value)\n        return self\n\n    @property\n    def expired(self) -&gt; bool:\n        \"\"\"Whether your access token has expired.\n\n        !!! note \"New in version 6.0\"\n\n        Returns\n        -------\n        bool\n            Whether the token has expired or not. If it has, it needs\n            refreshing.\n\n        Examples\n        --------\n        &gt;&gt;&gt; tokens.expired\n        True\n        \"\"\"\n        return self.expires_in == 0\n\n    def are_scoped_for(self, scopes: Scopes) -&gt; bool:\n        \"\"\"Check whether your token's scopes are sufficient.\n\n        This cross-checks the scopes you provided the client with the\n        scopes your tokens are authorised with and determines whether\n        your tokens provide enough access.\n\n        This is not an equality check; if your tokens are authorised\n        with all scopes, but you only passed the READONLY scope to the\n        client, this will return `True`.\n\n        !!! note \"New in version 6.0\"\n\n        Parameters\n        ----------\n        scopes\n            Your client's scopes.\n\n        Returns\n        -------\n        bool\n            Whether the scopes are sufficient or not. If they're not,\n            you'll need to reauthorise.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # This would only be used internally.\n        &gt;&gt;&gt; tokens.are_scopes_for(client._scopes)\n        True\n        \"\"\"\n        sufficient = set(scopes.formatted.split(\" \")) &lt;= set(self.scope.split(\" \"))\n        _log.debug(f\"Stored scopes are {'' if sufficient else 'in'}sufficient\")\n        return sufficient\n\n    @property\n    def decoded_id_token(self) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"The decoded ID token.\n\n        ID tokens are returned from the YouTube Analytics API as a JWT,\n        which is a secure way to transfer encrypted JSON objects. This\n        property decrypts and decodes the JWT and returns the stored\n        information.\n\n        !!! note \"New in version 6.0\"\n\n        Returns\n        -------\n        Optional[Dict[str, Any]]\n            The decoded ID token, or `None` if there is no ID token.\n\n        Raises\n        ------\n        MissingOptionalComponents\n            python-jwt is not installed.\n        IdTokenError\n            Your ID token could not be decoded. This may be raised\n            alongside other errors.\n\n        Notes\n        -----\n        This requires `jwt` to be installed to use, which is an optional\n        dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; client = BaseClient(\"secrets.json\")\n        &gt;&gt;&gt; tokens = client.authorise()  # Overloaded using your impl.\n        &gt;&gt;&gt; tokens.decoded_id_token\n        \"\"\"\n        if not self.id_token:\n            return None\n\n        if not utils.can_use(\"jwt\"):\n            raise MissingOptionalComponents(\"jwt\")\n\n        from jwt import JWT\n        from jwt import jwk_from_dict\n        from jwt.exceptions import JWSDecodeError\n\n        _log.debug(\"Fetching JWKs\")\n        with self._request(JWKS_URI) as resp:\n            if resp.status &gt; 399:\n                raise IdTokenError(\"could not fetch Google JWKs\")\n\n            keys = json.loads(resp.data)[\"keys\"]\n\n        jwt = JWT()  # type: ignore[no-untyped-call]\n\n        for key in keys:\n            jwk = jwk_from_dict(key)\n            _log.debug(\"Attempting decode using JWK with KID %r\", jwk.get_kid())\n            try:\n                return jwt.decode(self.id_token, jwk)\n            except Exception as exc:\n                if not isinstance(exc.__cause__, JWSDecodeError):\n                    # If the error IS a JWSDecodeError, we want to try\n                    # other keys and error later if they also fail.\n                    raise IdTokenError(\"invalid ID token (see above error)\") from exc\n\n        raise IdTokenError(\"ID token signature could not be validated\")\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.decoded_id_token","title":"decoded_id_token  <code>property</code>","text":"<pre><code>decoded_id_token: Optional[Dict[str, Any]]\n</code></pre> <p>The decoded ID token.</p> <p>ID tokens are returned from the YouTube Analytics API as a JWT, which is a secure way to transfer encrypted JSON objects. This property decrypts and decodes the JWT and returns the stored information.</p> <p>New in version 6.0</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>The decoded ID token, or <code>None</code> if there is no ID token.</p> <p>Raises:</p> Type Description <code>MissingOptionalComponents</code> <p>python-jwt is not installed.</p> <code>IdTokenError</code> <p>Your ID token could not be decoded. This may be raised alongside other errors.</p> Notes <p>This requires <code>jwt</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; client = BaseClient(\"secrets.json\")\n&gt;&gt;&gt; tokens = client.authorise()  # Overloaded using your impl.\n&gt;&gt;&gt; tokens.decoded_id_token\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.expired","title":"expired  <code>property</code>","text":"<pre><code>expired: bool\n</code></pre> <p>Whether your access token has expired.</p> <p>New in version 6.0</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the token has expired or not. If it has, it needs refreshing.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tokens.expired\nTrue\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.are_scoped_for","title":"are_scoped_for","text":"<pre><code>are_scoped_for(scopes: Scopes) -&gt; bool\n</code></pre> <p>Check whether your token's scopes are sufficient.</p> <p>This cross-checks the scopes you provided the client with the scopes your tokens are authorised with and determines whether your tokens provide enough access.</p> <p>This is not an equality check; if your tokens are authorised with all scopes, but you only passed the READONLY scope to the client, this will return <code>True</code>.</p> <p>New in version 6.0</p> <p>Parameters:</p> Name Type Description Default <code>scopes</code> <code>Scopes</code> <p>Your client's scopes.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the scopes are sufficient or not. If they're not, you'll need to reauthorise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # This would only be used internally.\n&gt;&gt;&gt; tokens.are_scopes_for(client._scopes)\nTrue\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>def are_scoped_for(self, scopes: Scopes) -&gt; bool:\n    \"\"\"Check whether your token's scopes are sufficient.\n\n    This cross-checks the scopes you provided the client with the\n    scopes your tokens are authorised with and determines whether\n    your tokens provide enough access.\n\n    This is not an equality check; if your tokens are authorised\n    with all scopes, but you only passed the READONLY scope to the\n    client, this will return `True`.\n\n    !!! note \"New in version 6.0\"\n\n    Parameters\n    ----------\n    scopes\n        Your client's scopes.\n\n    Returns\n    -------\n    bool\n        Whether the scopes are sufficient or not. If they're not,\n        you'll need to reauthorise.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # This would only be used internally.\n    &gt;&gt;&gt; tokens.are_scopes_for(client._scopes)\n    True\n    \"\"\"\n    sufficient = set(scopes.formatted.split(\" \")) &lt;= set(self.scope.split(\" \"))\n    _log.debug(f\"Stored scopes are {'' if sufficient else 'in'}sufficient\")\n    return sufficient\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data: Union[str, bytes]) -&gt; Tokens\n</code></pre> <p>Load tokens from raw JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, bytes]</code> <p>Your tokens in JSON form.</p> required <p>Returns:</p> Type Description <code>Tokens</code> <p>Your tokens.</p> <p>Raises:</p> Type Description <code>JSONDecodeError</code> <p>The given file is not a valid JSON file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.from_json('{\"access_token\": \"1234567890\", ...}')\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Union[str, bytes]) -&gt; \"Tokens\":\n    \"\"\"Load tokens from raw JSON data.\n\n    Parameters\n    ----------\n    data\n        Your tokens in JSON form.\n\n    Returns\n    -------\n    Tokens\n        Your tokens.\n\n    Raises\n    ------\n    JSONDecodeError\n        The given file is not a valid JSON file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.from_json('{\"access_token\": \"1234567890\", ...}')\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    return cls(**json.loads(data))\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.load_from","title":"load_from  <code>classmethod</code>","text":"<pre><code>load_from(path: PathLike) -&gt; Tokens\n</code></pre> <p>Load tokens from a JSON file.</p> Changed in version 5.0 <p>This used to be <code>from_file</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to your tokens file.</p> required <p>Returns:</p> Type Description <code>Tokens</code> <p>Your tokens.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>No tokens file exists at the given path.</p> <code>JSONDecodeError</code> <p>The given file is not a valid JSON file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.load_from(\"tokens.json\")\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>@classmethod\ndef load_from(cls, path: PathLike) -&gt; \"Tokens\":\n    \"\"\"Load tokens from a JSON file.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `from_file`.\n\n    Parameters\n    ----------\n    path\n        The path to your tokens file.\n\n    Returns\n    -------\n    Tokens\n        Your tokens.\n\n    Raises\n    ------\n    FileNotFoundError\n        No tokens file exists at the given path.\n    JSONDecodeError\n        The given file is not a valid JSON file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.load_from(\"tokens.json\")\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    tokens_file = Path(path)\n\n    if _log.isEnabledFor(logging.DEBUG):\n        _log.debug(\"Loading tokens from %s\", tokens_file.resolve())\n\n    self = cls.from_json(tokens_file.read_text())\n    self._path = tokens_file\n    return self\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.refresh","title":"refresh","text":"<pre><code>refresh(data: Union[str, bytes]) -&gt; Tokens\n</code></pre> <p>Updates your tokens to match those you refreshed.</p> Changed in version 5.0 <p>This used to be <code>update</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, bytes]</code> <p>Your refreshed tokens in JSON form. These will not entirely replace your previous tokens, but instead update any out-of-date keys.</p> required <p>Returns:</p> Type Description <code>Tokens</code> <p>Your refreshed tokens.</p> See Also <ul> <li>This method does not actually refresh your access token;   for that, you'll need to use <code>Client.refresh_access_token</code>.</li> <li>To save tokens, you'll need the <code>save_to</code> method.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.refresh('{\"access_token\": \"abcdefghij\", ...}')\nTokens(access_token=\"abcdefghij\", ...)\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>def refresh(self, data: Union[str, bytes]) -&gt; \"Tokens\":\n    \"\"\"Updates your tokens to match those you refreshed.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `update`.\n\n    Parameters\n    ----------\n    data\n        Your refreshed tokens in JSON form. These will not entirely\n        replace your previous tokens, but instead update any\n        out-of-date keys.\n\n    Returns\n    -------\n    Tokens\n        Your refreshed tokens.\n\n    See Also\n    --------\n    * This method does not actually refresh your access token;\n      for that, you'll need to use `Client.refresh_access_token`.\n    * To save tokens, you'll need the `save_to` method.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.refresh('{\"access_token\": \"abcdefghij\", ...}')\n    Tokens(access_token=\"abcdefghij\", ...)\n    \"\"\"\n    attrs = json.loads(data)\n    for key, value in attrs.items():\n        setattr(self, key, value)\n    return self\n</code></pre>"},{"location":"reference/auth/#analytix.auth.Tokens.save_to","title":"save_to","text":"<pre><code>save_to(path: PathLike) -&gt; None\n</code></pre> <p>Save your tokens to disk.</p> Changed in version 5.0 <p>This used to be <code>write</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save your tokens to.</p> required <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.save_to(\"tokens.json\")\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>def save_to(self, path: PathLike) -&gt; None:\n    \"\"\"Save your tokens to disk.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `write`.\n\n    Parameters\n    ----------\n    path\n        The path to save your tokens to.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.save_to(\"tokens.json\")\n    \"\"\"\n    tokens_file = Path(path)\n\n    if _log.isEnabledFor(logging.DEBUG):\n        _log.debug(\"Saving tokens to %s\", tokens_file.resolve())\n\n    attrs = {\n        \"access_token\": self.access_token,\n        \"expires_in\": self.expires_in,\n        \"scope\": self.scope,\n        \"token_type\": self.token_type,\n        \"refresh_token\": self.refresh_token,\n        **({\"id_token\": self.id_token} if self.id_token else {}),\n    }\n    tokens_file.write_text(json.dumps(attrs))\n    self._path = tokens_file\n</code></pre>"},{"location":"reference/auth/#analytix.auth.auth_uri","title":"auth_uri","text":"<pre><code>auth_uri(secrets: Secrets, scopes: Scopes, port: int) -&gt; UriParams\n</code></pre> <p>Returns the authentication URI and parameters.</p> Changed in version 5.0 <ul> <li>This now takes scopes as a parameter</li> <li>This now returns headers (albeit always empty) to be more   consistent with other functions</li> <li>The redirect URI to use is now chosen more intelligently --   it will be the first in the list not intended to be used in   OOB authorisation.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>secrets</code> <code>Secrets</code> <p>Your secrets.</p> required <code>scopes</code> <code>Scopes</code> <p>The scopes to allow in requests.</p> required <code>port</code> <code>int</code> <p>The websocket port you wish to use.</p> required <p>Returns:</p> Name Type Description <code>auth_uri</code> <code>str</code> <p>The computed authentication URI.</p> <code>params</code> <code>Dict[str, str]</code> <p>The query parameters as a dictionary.</p> <code>headers</code> <code>Dict[str, str]</code> <p>Necessary request headers. This is always empty.</p> Source code in <code>analytix/auth/utils.py</code> <pre><code>def auth_uri(secrets: Secrets, scopes: Scopes, port: int) -&gt; UriParams:\n    \"\"\"Returns the authentication URI and parameters.\n\n    ???+ note \"Changed in version 5.0\"\n        * This now takes scopes as a parameter\n        * This now returns headers (albeit always empty) to be more\n          consistent with other functions\n        * The redirect URI to use is now chosen more intelligently --\n          it will be the first in the list not intended to be used in\n          OOB authorisation.\n\n    Parameters\n    ----------\n    secrets\n        Your secrets.\n    scopes\n        The scopes to allow in requests.\n    port\n        The websocket port you wish to use.\n\n    Returns\n    -------\n    auth_uri : str\n        The computed authentication URI.\n    params : Dict[str, str]\n        The query parameters as a dictionary.\n    headers : Dict[str, str]\n        Necessary request headers. This is always empty.\n    \"\"\"\n    redirect_uri = next(\n        uri\n        for uri in secrets.redirect_uris\n        if uri != \"oob\" and \"urn:ietf:wg:oauth:2.0:oob\" not in uri\n    )\n\n    params = {\n        \"client_id\": secrets.client_id,\n        \"nonce\": state_token(),\n        \"response_type\": \"code\",\n        \"redirect_uri\": redirect_uri + (f\":{port}\" if port != 80 else \"\"),\n        \"scope\": scopes.formatted,\n        \"state\": state_token(),\n        \"access_type\": \"offline\",\n    }\n\n    return f\"{secrets.auth_uri}?{urlencode(params)}\", params, {}\n</code></pre>"},{"location":"reference/auth/#analytix.auth.refresh_uri","title":"refresh_uri","text":"<pre><code>refresh_uri(secrets: Secrets, token: str) -&gt; UriParams\n</code></pre> <p>Returns the refresh URI, data, and headers.</p> <p>Parameters:</p> Name Type Description Default <code>secrets</code> <code>Secrets</code> <p>Your secrets.</p> required <code>token</code> <code>str</code> <p>Your refresh token.</p> required <p>Returns:</p> Name Type Description <code>token_uri</code> <code>str</code> <p>Your token URI.</p> <code>data</code> <code>Dict[str, str]</code> <p>Necessary request data.</p> <code>headers</code> <code>Dict[str, str]</code> <p>Necessary request headers.</p> Source code in <code>analytix/auth/utils.py</code> <pre><code>def refresh_uri(secrets: Secrets, token: str) -&gt; UriParams:\n    \"\"\"Returns the refresh URI, data, and headers.\n\n    Parameters\n    ----------\n    secrets\n        Your secrets.\n    token\n        Your refresh token.\n\n    Returns\n    -------\n    token_uri : str\n        Your token URI.\n    data : Dict[str, str]\n        Necessary request data.\n    headers : Dict[str, str]\n        Necessary request headers.\n    \"\"\"\n    data = {\n        \"client_id\": secrets.client_id,\n        \"client_secret\": secrets.client_secret,\n        \"refresh_token\": token,\n        \"grant_type\": \"refresh_token\",\n    }\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    return secrets.token_uri, data, headers\n</code></pre>"},{"location":"reference/auth/#analytix.auth.run_flow","title":"run_flow","text":"<pre><code>run_flow(auth_params: Dict[str, str]) -&gt; str\n</code></pre> <p>Start a webserver and listen for an authentication code.</p> Changed in version 5.0 <p>This used to be <code>authenticate</code>.</p> <p>Parameters:</p> Name Type Description Default <code>auth_params</code> <code>Dict[str, str]</code> <p>The parameters generated from the <code>auth_uri</code> method.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Your authentication code.</p> <p>Raises:</p> Type Description <code>AuthorisationError</code> <ul> <li>You provided an invalid redirect URI</li> <li>The received state does not match the generated one</li> </ul> Source code in <code>analytix/auth/flow.py</code> <pre><code>def run_flow(auth_params: Dict[str, str]) -&gt; str:\n    \"\"\"Start a webserver and listen for an authentication code.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `authenticate`.\n\n    Parameters\n    ----------\n    auth_params\n        The parameters generated from the `auth_uri` method.\n\n    Returns\n    -------\n    str\n        Your authentication code.\n\n    Raises\n    ------\n    AuthorisationError\n        * You provided an invalid redirect URI\n        * The received state does not match the generated one\n    \"\"\"\n    if not (match := REDIRECT_URI_PATTERN.match(auth_params[\"redirect_uri\"])):\n        raise AuthorisationError(\"invalid redirect URI\")\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def log_request(\n            self,\n            code: Union[int, str] = \"-\",\n            _: Union[int, str] = \"-\",\n        ) -&gt; None:\n            _log.debug(f\"Received request ({code})\")\n\n        def do_GET(self) -&gt; None:  # noqa: N802\n            self.send_response(200)\n            self.send_header(\"Content-Type\", \"text/html\")\n            self.end_headers()\n\n            self.server: Server\n            self.server.query_params = dict(parse_qsl(self.path.split(\"?\")[1]))\n            self.wfile.write((Path(__file__).parent / \"landing.html\").read_bytes())\n\n    class Server(HTTPServer):\n        def __init__(self, address: str, port: int) -&gt; None:\n            super().__init__((address, port), RequestHandler)\n            self.query_params: Dict[str, str] = {}\n            _log.debug(\"Started webserver on %s:%d\", self.server_name, self.server_port)\n\n        def server_close(self) -&gt; None:\n            super().server_close()\n            _log.debug(\"Closed webserver\")\n\n    host, port = match.groups()\n    ws = Server(host, int(port or 80))\n\n    try:\n        ws.handle_request()\n    except KeyboardInterrupt as exc:\n        raise exc\n    finally:\n        ws.server_close()\n\n    if auth_params[\"state\"] != ws.query_params[\"state\"]:\n        raise AuthorisationError(\"invalid state\")\n\n    return ws.query_params[\"code\"]\n</code></pre>"},{"location":"reference/auth/#analytix.auth.state_token","title":"state_token","text":"<pre><code>state_token() -&gt; str\n</code></pre> <p>Generates a state token.</p> <p>Returns:</p> Type Description <code>str</code> <p>A new state token.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state_token()\n'385cdc1c6e9410120755ecf1c0558299be58bd3bcc6f515addaa817df5e10fd2'\n</code></pre> Source code in <code>analytix/auth/utils.py</code> <pre><code>def state_token() -&gt; str:\n    \"\"\"Generates a state token.\n\n    Returns\n    -------\n    str\n        A new state token.\n\n    Examples\n    --------\n    &gt;&gt;&gt; state_token()\n    '385cdc1c6e9410120755ecf1c0558299be58bd3bcc6f515addaa817df5e10fd2'\n    \"\"\"\n    return hashlib.sha256(os.urandom(1024)).hexdigest()\n</code></pre>"},{"location":"reference/auth/#analytix.auth.token_uri","title":"token_uri","text":"<pre><code>token_uri(secrets: Secrets, code: str, redirect_uri: str) -&gt; UriParams\n</code></pre> <p>Returns the token URI, data, and headers.</p> <p>Parameters:</p> Name Type Description Default <code>secrets</code> <code>Secrets</code> <p>Your secrets.</p> required <code>code</code> <code>str</code> <p>Your authentication code.</p> required <code>redirect_uri</code> <code>str</code> <p>Your redirect URI. This should be identical to the one you generated in <code>auth_uri</code>.</p> required <p>Returns:</p> Name Type Description <code>token_uri</code> <code>str</code> <p>Your token URI.</p> <code>data</code> <code>Dict[str, str]</code> <p>Necessary request data.</p> <code>headers</code> <code>Dict[str, str]</code> <p>Necessary request headers.</p> Source code in <code>analytix/auth/utils.py</code> <pre><code>def token_uri(secrets: Secrets, code: str, redirect_uri: str) -&gt; UriParams:\n    \"\"\"Returns the token URI, data, and headers.\n\n    Parameters\n    ----------\n    secrets\n        Your secrets.\n    code\n        Your authentication code.\n    redirect_uri\n        Your redirect URI. This should be identical to the one you\n        generated in `auth_uri`.\n\n    Returns\n    -------\n    token_uri : str\n        Your token URI.\n    data : Dict[str, str]\n        Necessary request data.\n    headers : Dict[str, str]\n        Necessary request headers.\n    \"\"\"\n    data = {\n        \"code\": code,\n        \"client_id\": secrets.client_id,\n        \"client_secret\": secrets.client_secret,\n        \"redirect_uri\": redirect_uri,\n        \"grant_type\": \"authorization_code\",\n    }\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    return secrets.token_uri, data, headers\n</code></pre>"},{"location":"reference/client/","title":"client","text":"<p>Client interfaces for analytix.</p> <p>There are two clients to choose from:</p> <ul> <li>The base client (<code>BaseClient</code>)</li> <li>The scripting client (<code>Client</code>)</li> </ul> <p>The scripting client is the simpler of the two to use and is designed for use in scripts. Client authorisation and shard management is handled for you, allowing you to focus on the data you wish to fetch.</p> <p>The base client needs to be subclassed, and is designed for use in web applications. It needs to be told how to authorise itself to best suit your workflow, and requires you to create and destroy shards yourself.</p> <p>You may wish to use the base client if:</p> <ul> <li>you're running your application on a server</li> <li>you want control over how your applications is authorised</li> <li>you want to store tokens in a database</li> <li>you need access to JWT ID tokens</li> </ul>"},{"location":"reference/client/#analytix.client.BaseClient","title":"BaseClient","text":"<p>               Bases: <code>RequestMixin</code></p> <p>A base client designed to be subclassed for use in web applications.</p> <p>This client provides an interface for retrieving reports and group data from the YouTube Analytics API, but requires you to implement your own authorisation routine. It also requires you to manually create and manage analytix \"shards\", though utilities are available to help with that.</p> <p>This will work as a context manager.</p> <p>New in version 5.0</p> <p>Parameters:</p> Name Type Description Default <code>secrets_file</code> <code>PathLike</code> <p>The path to your secrets file.</p> required <code>scopes</code> <code>Scopes</code> <p>The scopes to allow in requests. This is used to control whether or not to allow access to monetary data, as well as whether to fetch ID tokens. If this is not provided, neither monetary data nor ID tokens will be accessible.</p> <code>READONLY</code> <p>Raises:</p> Type Description <code>AuthorisationError</code> <p>Neither the READONLY nor MONETARY_READONLY scopes were provided.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from analytix import BaseClient\n&gt;&gt;&gt; class CustomClient(BaseClient):\n...     pass\n...\n&gt;&gt;&gt; client = CustomClient(\"secrets.json\")\n</code></pre> <p>Providing custom scopes.</p> <pre><code>&gt;&gt;&gt; from analytix import BaseClient, Scopes\n&gt;&gt;&gt; class CustomClient(BaseClient):\n...     pass\n...\n&gt;&gt;&gt; client = CustomClient(\"secrets.json\", scopes=Scopes.ALL)\n</code></pre> <p>Providing JWT scopes.</p> <pre><code>&gt;&gt;&gt; from analytix import BaseClient, Scopes\n&gt;&gt;&gt; class CustomClient(BaseClient):\n...     pass\n...\n&gt;&gt;&gt; client = CustomClient(\n...     \"secrets.json\",\n...     scopes=Scopes.READONLY | Scopes.ALL_JWT,\n... )\n</code></pre> Source code in <code>analytix/client.py</code> <pre><code>class BaseClient(RequestMixin, metaclass=ABCMeta):\n    \"\"\"A base client designed to be subclassed for use in web\n    applications.\n\n    This client provides an interface for retrieving reports and group\n    data from the YouTube Analytics API, but requires you to implement\n    your own authorisation routine. It also requires you to manually\n    create and manage analytix \"shards\", though utilities are available\n    to help with that.\n\n    This will work as a context manager.\n\n    !!! note \"New in version 5.0\"\n\n    Parameters\n    ----------\n    secrets_file\n        The path to your secrets file.\n    scopes\n        The scopes to allow in requests. This is used to control whether\n        or not to allow access to monetary data, as well as whether to\n        fetch ID tokens. If this is not provided, neither monetary data\n        nor ID tokens will be accessible.\n\n    Raises\n    ------\n    AuthorisationError\n        Neither the READONLY nor MONETARY_READONLY scopes were provided.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from analytix import BaseClient\n    &gt;&gt;&gt; class CustomClient(BaseClient):\n    ...     pass\n    ...\n    &gt;&gt;&gt; client = CustomClient(\"secrets.json\")\n\n    Providing custom scopes.\n\n    &gt;&gt;&gt; from analytix import BaseClient, Scopes\n    &gt;&gt;&gt; class CustomClient(BaseClient):\n    ...     pass\n    ...\n    &gt;&gt;&gt; client = CustomClient(\"secrets.json\", scopes=Scopes.ALL)\n\n    Providing JWT scopes.\n\n    &gt;&gt;&gt; from analytix import BaseClient, Scopes\n    &gt;&gt;&gt; class CustomClient(BaseClient):\n    ...     pass\n    ...\n    &gt;&gt;&gt; client = CustomClient(\n    ...     \"secrets.json\",\n    ...     scopes=Scopes.READONLY | Scopes.ALL_JWT,\n    ... )\n    \"\"\"\n\n    __slots__ = (\"_secrets\", \"_scopes\")\n\n    def __init__(\n        self,\n        secrets_file: PathLike,\n        *,\n        scopes: Scopes = Scopes.READONLY,\n    ) -&gt; None:\n        self._secrets = Secrets.load_from(Path(secrets_file))\n        scopes.validate()\n        self._scopes = scopes\n\n        if not os.environ.get(\"PYTEST_CURRENT_TEST\"):\n            # We don't want this to run during tests.\n            self._check_for_updates()\n\n    def __enter__(self) -&gt; \"BaseClient\":\n        return self\n\n    def __exit__(self, *_: object) -&gt; None: ...\n\n    def _check_for_updates(self) -&gt; None:\n        _log.debug(\"Checking for updates\")\n\n        with self._request(UPDATE_CHECK_URL, ignore_errors=True, timeout=0.5) as resp:\n            if resp.status &gt; 399:\n                # If we can't get the info, just ignore it.\n                _log.debug(\"Failed to get version information\")\n                return\n\n            latest = json.loads(resp.data)[\"info\"][\"version\"]\n\n        from analytix import __version__\n\n        if __version__ != latest:\n            warnings.warn(\n                f\"You do not have the latest stable version of analytix (v{latest})\",\n                NotUpdatedWarning,\n                stacklevel=2,\n            )\n\n    @abstractmethod\n    def authorise(self) -&gt; Tokens:\n        \"\"\"An abstract method used to authorise the client.\n\n        The `BaseClient` requires you to overload this method when\n        subclassing to suit your application's needs. Your\n        implementation of this method must return a `Tokens` object.\n\n        Returns\n        -------\n        Tokens\n            Your tokens.\n\n        Raises\n        ------\n        NotImplementedError\n            You called this method without overloading it.\n\n        See Also\n        --------\n        You may find the `analytix.auth.auth_uri` and `.token_uri`\n        functions helpful when writing your custom implementation.\n        \"\"\"\n        raise NotImplementedError\n\n    def refresh_access_token(self, tokens: Tokens) -&gt; Optional[Tokens]:\n        \"\"\"Refresh your access token.\n\n        ???+ note \"Changed in version 5.0\"\n            This is now handled by the client rather than by individual\n            shards.\n\n        Parameters\n        ----------\n        tokens\n            Your tokens.\n\n        Returns\n        -------\n        Optional[Tokens]\n            Your refreshed tokens, or `None` if they could not be\n            refreshed. In the latter instance, your client will need to\n            be reauthorised from scratch.\n\n        Notes\n        -----\n        While this method should always be sufficient to refresh your\n        access token, the default implementation does not save new\n        tokens anywhere. If this is something you need, you will need\n        to extend this method to accommodate that.\n\n        Examples\n        --------\n        &gt;&gt;&gt; client.refresh_access_token(tokens)\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        refresh_token = tokens.refresh_token\n        refresh_uri, data, headers = auth.refresh_uri(self._secrets, refresh_token)\n\n        _log.debug(\"Refreshing access token\")\n        with self._request(\n            refresh_uri,\n            data=data,\n            headers=headers,\n            ignore_errors=True,\n        ) as resp:\n            if resp.status &gt; 399:\n                _log.debug(\"Access token could not be refreshed\")\n                return None\n\n            _log.debug(\"Access token has been refreshed successfully\")\n            return tokens.refresh(resp.data)\n\n    @contextmanager\n    def shard(\n        self,\n        tokens: Tokens,\n        *,\n        scopes: Optional[Scopes] = None,\n    ) -&gt; Generator[Shard, None, None]:\n        \"\"\"A context manager for creating shards.\n\n        You can think of shards as mini-clients, each able to make\n        requests using their own tokens. This allows you to accommodate\n        the needs of multiple users, or even allow a single user to make\n        multiple requests, without having to call your authorisation\n        routine multiple times.\n\n        Generally, shards should only live for a single request or\n        a batch of related requests.\n\n        ???+ note \"Changed in version 5.0\"\n            You can now provide custom scopes for shards.\n\n        Parameters\n        ----------\n        tokens\n            Your tokens.\n        scopes\n            The scopes to allow in requests. If this is not provided,\n            the shard will inherit the client's scopes.\n\n        Yields\n        ------\n        Shard\n            A new shard. It will be destroyed upon exiting the context\n            manager.\n\n        Examples\n        --------\n        &gt;&gt;&gt; tokens = client.authorise()\n        &gt;&gt;&gt; with client.shard(tokens) as shard:\n        ...     shard.fetch_report()\n\n        Providing custom scopes.\n\n        &gt;&gt;&gt; from analytix import Scopes\n        &gt;&gt;&gt; # Other custom logic.\n        &gt;&gt;&gt; tokens = client.authorise()\n        &gt;&gt;&gt; with client.shard(tokens, scopes=Scopes.ALL) as shard:\n        ...     shard.fetch_groups()\n        \"\"\"\n        shard = Shard(scopes or self._scopes, tokens)\n        yield shard\n        del shard\n</code></pre>"},{"location":"reference/client/#analytix.client.BaseClient.authorise","title":"authorise  <code>abstractmethod</code>","text":"<pre><code>authorise() -&gt; Tokens\n</code></pre> <p>An abstract method used to authorise the client.</p> <p>The <code>BaseClient</code> requires you to overload this method when subclassing to suit your application's needs. Your implementation of this method must return a <code>Tokens</code> object.</p> <p>Returns:</p> Type Description <code>Tokens</code> <p>Your tokens.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>You called this method without overloading it.</p> See Also <p>You may find the <code>analytix.auth.auth_uri</code> and <code>.token_uri</code> functions helpful when writing your custom implementation.</p> Source code in <code>analytix/client.py</code> <pre><code>@abstractmethod\ndef authorise(self) -&gt; Tokens:\n    \"\"\"An abstract method used to authorise the client.\n\n    The `BaseClient` requires you to overload this method when\n    subclassing to suit your application's needs. Your\n    implementation of this method must return a `Tokens` object.\n\n    Returns\n    -------\n    Tokens\n        Your tokens.\n\n    Raises\n    ------\n    NotImplementedError\n        You called this method without overloading it.\n\n    See Also\n    --------\n    You may find the `analytix.auth.auth_uri` and `.token_uri`\n    functions helpful when writing your custom implementation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/client/#analytix.client.BaseClient.refresh_access_token","title":"refresh_access_token","text":"<pre><code>refresh_access_token(tokens: Tokens) -&gt; Optional[Tokens]\n</code></pre> <p>Refresh your access token.</p> Changed in version 5.0 <p>This is now handled by the client rather than by individual shards.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>Tokens</code> <p>Your tokens.</p> required <p>Returns:</p> Type Description <code>Optional[Tokens]</code> <p>Your refreshed tokens, or <code>None</code> if they could not be refreshed. In the latter instance, your client will need to be reauthorised from scratch.</p> Notes <p>While this method should always be sufficient to refresh your access token, the default implementation does not save new tokens anywhere. If this is something you need, you will need to extend this method to accommodate that.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; client.refresh_access_token(tokens)\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/client.py</code> <pre><code>def refresh_access_token(self, tokens: Tokens) -&gt; Optional[Tokens]:\n    \"\"\"Refresh your access token.\n\n    ???+ note \"Changed in version 5.0\"\n        This is now handled by the client rather than by individual\n        shards.\n\n    Parameters\n    ----------\n    tokens\n        Your tokens.\n\n    Returns\n    -------\n    Optional[Tokens]\n        Your refreshed tokens, or `None` if they could not be\n        refreshed. In the latter instance, your client will need to\n        be reauthorised from scratch.\n\n    Notes\n    -----\n    While this method should always be sufficient to refresh your\n    access token, the default implementation does not save new\n    tokens anywhere. If this is something you need, you will need\n    to extend this method to accommodate that.\n\n    Examples\n    --------\n    &gt;&gt;&gt; client.refresh_access_token(tokens)\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    refresh_token = tokens.refresh_token\n    refresh_uri, data, headers = auth.refresh_uri(self._secrets, refresh_token)\n\n    _log.debug(\"Refreshing access token\")\n    with self._request(\n        refresh_uri,\n        data=data,\n        headers=headers,\n        ignore_errors=True,\n    ) as resp:\n        if resp.status &gt; 399:\n            _log.debug(\"Access token could not be refreshed\")\n            return None\n\n        _log.debug(\"Access token has been refreshed successfully\")\n        return tokens.refresh(resp.data)\n</code></pre>"},{"location":"reference/client/#analytix.client.BaseClient.shard","title":"shard","text":"<pre><code>shard(tokens: Tokens, *, scopes: Optional[Scopes] = None) -&gt; Generator[Shard, None, None]\n</code></pre> <p>A context manager for creating shards.</p> <p>You can think of shards as mini-clients, each able to make requests using their own tokens. This allows you to accommodate the needs of multiple users, or even allow a single user to make multiple requests, without having to call your authorisation routine multiple times.</p> <p>Generally, shards should only live for a single request or a batch of related requests.</p> Changed in version 5.0 <p>You can now provide custom scopes for shards.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>Tokens</code> <p>Your tokens.</p> required <code>scopes</code> <code>Optional[Scopes]</code> <p>The scopes to allow in requests. If this is not provided, the shard will inherit the client's scopes.</p> <code>None</code> <p>Yields:</p> Type Description <code>Shard</code> <p>A new shard. It will be destroyed upon exiting the context manager.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tokens = client.authorise()\n&gt;&gt;&gt; with client.shard(tokens) as shard:\n...     shard.fetch_report()\n</code></pre> <p>Providing custom scopes.</p> <pre><code>&gt;&gt;&gt; from analytix import Scopes\n&gt;&gt;&gt; # Other custom logic.\n&gt;&gt;&gt; tokens = client.authorise()\n&gt;&gt;&gt; with client.shard(tokens, scopes=Scopes.ALL) as shard:\n...     shard.fetch_groups()\n</code></pre> Source code in <code>analytix/client.py</code> <pre><code>@contextmanager\ndef shard(\n    self,\n    tokens: Tokens,\n    *,\n    scopes: Optional[Scopes] = None,\n) -&gt; Generator[Shard, None, None]:\n    \"\"\"A context manager for creating shards.\n\n    You can think of shards as mini-clients, each able to make\n    requests using their own tokens. This allows you to accommodate\n    the needs of multiple users, or even allow a single user to make\n    multiple requests, without having to call your authorisation\n    routine multiple times.\n\n    Generally, shards should only live for a single request or\n    a batch of related requests.\n\n    ???+ note \"Changed in version 5.0\"\n        You can now provide custom scopes for shards.\n\n    Parameters\n    ----------\n    tokens\n        Your tokens.\n    scopes\n        The scopes to allow in requests. If this is not provided,\n        the shard will inherit the client's scopes.\n\n    Yields\n    ------\n    Shard\n        A new shard. It will be destroyed upon exiting the context\n        manager.\n\n    Examples\n    --------\n    &gt;&gt;&gt; tokens = client.authorise()\n    &gt;&gt;&gt; with client.shard(tokens) as shard:\n    ...     shard.fetch_report()\n\n    Providing custom scopes.\n\n    &gt;&gt;&gt; from analytix import Scopes\n    &gt;&gt;&gt; # Other custom logic.\n    &gt;&gt;&gt; tokens = client.authorise()\n    &gt;&gt;&gt; with client.shard(tokens, scopes=Scopes.ALL) as shard:\n    ...     shard.fetch_groups()\n    \"\"\"\n    shard = Shard(scopes or self._scopes, tokens)\n    yield shard\n    del shard\n</code></pre>"},{"location":"reference/client/#analytix.client.Client","title":"Client","text":"<p>               Bases: <code>BaseClient</code></p> <p>A fully-functional client designed for use in scripts.</p> <p>Unlike the base client, this client is capable of authorising itself and provides helper methods to abstract shard management away from you.</p> <p>This will work as a context manager.</p> Changed in version 5.0 <ul> <li>You should now provide a tokens file rather than a tokens   directory</li> <li><code>auto_open_browser</code> is now set based on your OS by default</li> <li>Monetary data is now no longer accessible by default</li> </ul> <p>Parameters:</p> Name Type Description Default <code>secrets_file</code> <code>PathLike</code> <p>The path to your secrets file.</p> required <code>scopes</code> <code>Scopes</code> <p>The scopes to allow in requests. This is used to control whether or not to allow access to monetary data. If this is not provided, monetary data will not be accessible.</p> <code>READONLY</code> <code>tokens_file</code> <code>PathLike</code> <p>The path to save your tokens to. This must be a JSON file, but does not need to exist. If this is not provided, your tokens will be saved to a file called \"tokens.json\" in your current working directory.</p> <code>'tokens.json'</code> <code>ws_port</code> <code>int</code> <p>The port the client's webserver will use during authorisation.</p> <code>8080</code> <code>auto_open_browser</code> <code>Optional[bool]</code> <p>Whether to automatically open a new browser tab when authorising. If this is <code>False</code>, a link will be output to the console instead. If this is not provided, its value will be set based on your operating system; it will be set to <code>False</code> if you use WSL, and <code>True</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p><code>tokens_file</code> is not a JSON file.</p> Source code in <code>analytix/client.py</code> <pre><code>class Client(BaseClient):\n    \"\"\"A fully-functional client designed for use in scripts.\n\n    Unlike the base client, this client is capable of authorising\n    itself and provides helper methods to abstract shard management away\n    from you.\n\n    This will work as a context manager.\n\n    ???+ note \"Changed in version 5.0\"\n        * You should now provide a tokens file rather than a tokens\n          directory\n        * `auto_open_browser` is now set based on your OS by default\n        * Monetary data is now no longer accessible by default\n\n    Parameters\n    ----------\n    secrets_file\n        The path to your secrets file.\n    scopes\n        The scopes to allow in requests. This is used to control whether\n        or not to allow access to monetary data. If this is not\n        provided, monetary data will not be accessible.\n    tokens_file\n        The path to save your tokens to. This must be a JSON file, but\n        does not need to exist. If this is not provided, your tokens\n        will be saved to a file called \"tokens.json\" in your current\n        working directory.\n    ws_port\n        The port the client's webserver will use during authorisation.\n    auto_open_browser\n        Whether to automatically open a new browser tab when\n        authorising. If this is `False`, a link will be output to the\n        console instead. If this is not provided, its value will be set\n        based on your operating system; it will be set to `False` if you\n        use WSL, and `True` otherwise.\n\n    Raises\n    ------\n    ValueError\n        `tokens_file` is not a JSON file.\n    \"\"\"\n\n    def __init__(\n        self,\n        secrets_file: PathLike,\n        *,\n        scopes: Scopes = Scopes.READONLY,\n        tokens_file: PathLike = \"tokens.json\",\n        ws_port: int = 8080,\n        auto_open_browser: Optional[bool] = None,\n    ) -&gt; None:\n        def in_wsl() -&gt; bool:\n            return \"microsoft-standard\" in platform.uname().release\n\n        super().__init__(secrets_file, scopes=scopes)\n        self._ws_port = ws_port\n        self._auto_open_browser = (\n            not in_wsl() if auto_open_browser is None else auto_open_browser\n        )\n\n        self._tokens_file = Path(tokens_file)\n        if self._tokens_file.suffix != \".json\":\n            raise ValueError(\"tokens file must be a JSON file\")\n\n    def __enter__(self) -&gt; \"Client\":\n        return self\n\n    def authorise(self, *, force: bool = False, force_refresh: bool = False) -&gt; Tokens:\n        \"\"\"Authorise the client.\n\n        Client methods authorise the client for you, so you don't need\n        to call this manually when using those. If you plan to make\n        multiple requests in a row using the same client, it's better to\n        call this manually and create a shard with the generated tokens\n        to avoid authorising the client multiple times.\n\n        ???+ note \"Changed in version 5.0\"\n            * You can no longer pass a filename to load a specific set\n              of tokens; if you wish to change which channel is\n              authorised, you should either utilise shards or forcibly\n              reauthorise the client\n            * You can now forcibly refresh access tokens using this\n              method\n\n        Parameters\n        ----------\n        force\n            Whether to forcibly reauthorise the client even if your\n            tokens are still valid.\n        force_refresh\n            Whether to forcibly refresh your access token even if the\n            token is still valid.\n\n        Returns\n        -------\n        Tokens\n            Your tokens.\n\n        Raises\n        ------\n        RuntimeError\n            The client attempted to open a new browser tab, but failed.\n        AuthorisationError\n            Something went wrong during authorisation.\n\n        Notes\n        -----\n        This method always does the minimum possible work necessary to\n        authorise the client unless forced to do otherwise. This means\n        that stored tokens will be prioritised, and the full auth flow\n        will only trigger when necessary. Token refreshing is handled\n        automatically.\n\n        Examples\n        --------\n        &gt;&gt;&gt; client.authorise()\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        if not force and self._tokens_file.is_file():\n            tokens = Tokens.load_from(self._tokens_file)\n            if tokens.are_scoped_for(self._scopes) and (\n                refreshed := self.refresh_access_token(tokens, force=force_refresh)\n            ):\n                _log.info(\"Existing tokens are valid -- no authorisation necessary\")\n                return refreshed\n\n        _log.info(\"Authorisation necessary -- starting authorisation flow\")\n\n        auth_uri, params, _ = auth.auth_uri(self._secrets, self._scopes, self._ws_port)\n        if self._auto_open_browser:\n            if not webbrowser.open(auth_uri, 0, autoraise=True):\n                raise RuntimeError(\"web browser failed to open\")\n        else:\n            print(  # noqa: T201\n                \"\\33[38;5;45mYou need to authorise analytix.\\33[0m \"\n                f\"\\33[4m{auth_uri}\\33[0m\",\n            )\n\n        code = auth.run_flow(params)\n        _log.debug(\"Authorisation code: %s\", code)\n        token_uri, data, headers = auth.token_uri(\n            self._secrets,\n            code,\n            params[\"redirect_uri\"],\n        )\n\n        with self._request(token_uri, data=data, headers=headers) as resp:\n            if resp.status &gt; 399:\n                error = json.loads(resp.data)\n                raise AuthorisationError(\n                    f\"could not authorise: {error['error_description']} \"\n                    f\"({error['error']})\",\n                )\n\n            tokens = Tokens.from_json(resp.data)\n\n        tokens.save_to(self._tokens_file)\n        _log.info(\"Authorisation complete!\")\n        return tokens\n\n    def refresh_access_token(\n        self,\n        tokens: Tokens,\n        *,\n        force: bool = False,\n    ) -&gt; Optional[Tokens]:\n        \"\"\"Refresh your access token.\n\n        !!! note \"New in version 5.0\"\n\n        Parameters\n        ----------\n        tokens\n            Your tokens.\n        force\n            Whether to forcibly refresh your access token, even if the\n            token is still valid.\n\n        Returns\n        -------\n        Optional[Tokens]\n            Your refreshed tokens, or `None` if they could not be\n            refreshed.\n\n        Notes\n        -----\n        This method should never need to be called, as the `authorise`\n        method will call it automatically when necessary.\n\n        Examples\n        --------\n        &gt;&gt;&gt; client.refresh_access_token(tokens)\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        if not (force or tokens.expired):\n            return tokens\n\n        if refreshed := super().refresh_access_token(tokens):\n            refreshed.save_to(self._tokens_file)\n\n        return refreshed\n\n    def fetch_report(\n        self,\n        *,\n        dimensions: Optional[Collection[str]] = None,\n        filters: Optional[Dict[str, str]] = None,\n        metrics: Optional[Collection[str]] = None,\n        start_date: Optional[dt.date] = None,\n        end_date: Optional[dt.date] = None,\n        sort_options: Optional[Collection[str]] = None,\n        max_results: int = 0,\n        currency: str = \"USD\",\n        start_index: int = 1,\n        include_historical_data: bool = False,\n        **kwargs: Any,\n    ) -&gt; \"Report\":\n        \"\"\"Authorise the client and fetch an analytics report.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `retrieve_report`.\n\n        Parameters\n        ----------\n        dimensions\n            The dimensions to use within the request.\n        filters\n            The filters to use within the request.\n        metrics\n            The metrics to use within the request. If none are provided,\n            all supported metrics are used.\n        sort_options\n            The sort options to use within the request.\n\n        Returns\n        -------\n        Report\n            The generated report.\n\n        Other Parameters\n        ----------------\n        start_date\n            The date in which data should be pulled from. If this is\n            not provided, this is set to 28 days before `end_date`.\n        end_date\n            The date in which data should be pulled to. If this is not\n            provided, this is set to the current date.\n        max_results\n            The maximum number of results the report should include. If\n            this is `0`, no upper limit is applied.\n        currency\n            The currency revenue data should be represented using. This\n            should be an ISO 4217 currency code.\n        start_index\n            The first row in the report to include. This is one-indexed.\n            If this is `1`, all rows are included.\n        include_historical_data\n            Whether to include data from before the current channel\n            owner assumed control of the channel. You only need to worry\n            about this is the current channel owner did not create the\n            channel.\n        **kwargs\n            Additional keyword arguments to be passed to the `authorise`\n            method.\n\n        Raises\n        ------\n        InvalidRequest\n            Your request was invalid.\n        BadRequest\n            Your request was invalid, but it was not caught by\n            analytix's verification systems.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n        RuntimeError\n            The client attempted to open a new browser tab, but failed.\n        AuthorisationError\n            Something went wrong during authorisation.\n\n        Warnings\n        --------\n        * If your channel is not partnered, attempting to access\n          monetary data will result in a `Forbidden` error. Ensure your\n          scopes are set up correctly before calling this method.\n        * The \"isCurated\" filter stopped working on 30 Jun 2024. See the\n          [guide on new playlist reports](../guides/new-playlist-reports.md)\n          for information on how to migrate.\n\n        See Also\n        --------\n        You can learn more about dimensions, filters, metrics, and sort\n        options by reading the [detailed guides](../guides/\n        dimensions.md).\n\n        Examples\n        --------\n        Fetching daily analytics data for 2022.\n\n        &gt;&gt;&gt; import datetime\n        &gt;&gt;&gt; shard.fetch_report(\n        ...     dimensions=(\"day\",),\n        ...     start_date=datetime.date(2022, 1, 1),\n        ...     end_date=datetime.date(2022, 12, 31),\n        ... )\n\n        Fetching 10 most watched videos over last 28 days.\n\n        &gt;&gt;&gt; shard.fetch_report(\n        ...     dimensions=(\"video\",),\n        ...     metrics=(\"estimatedMinutesWatched\", \"views\"),\n        ...     sort_options=(\"-estimatedMinutesWatched\",),\n        ...     max_results=10,\n        ... )\n        \"\"\"\n        tokens = self.authorise(**kwargs)\n        with self.shard(tokens) as shard:\n            return shard.fetch_report(\n                dimensions=dimensions,\n                filters=filters,\n                metrics=metrics,\n                start_date=start_date,\n                end_date=end_date,\n                sort_options=sort_options,\n                max_results=max_results,\n                currency=currency,\n                start_index=start_index,\n                include_historical_data=include_historical_data,\n            )\n\n    def fetch_groups(\n        self,\n        *,\n        ids: Optional[Collection[str]] = None,\n        next_page_token: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; \"GroupList\":\n        \"\"\"Authorise the client and fetch a list of analytics groups.\n\n        ???+ note \"Changed in version 5.0\"\n            You can now pass a series of keyword arguments to be passed\n            on to the `authorise` method.\n\n        Parameters\n        ----------\n        ids\n            The IDs of groups you want to fetch. If none are provided,\n            all your groups will be fetched.\n        next_page_token\n            If you need to make multiple requests, you can pass this to\n            load a specific page. To check if you've arrived back at the\n            first page, check the next page token from the request and\n            compare it to the next page token from the first page.\n        **kwargs\n            Additional keyword arguments to be passed to the `authorise`\n            method.\n\n        Returns\n        -------\n        GroupList\n            An object containing the list of your groups and the next\n            page token.\n\n        Raises\n        ------\n        BadRequest\n            Your request was invalid.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n        RuntimeError\n            The client attempted to open a new browser tab, but failed.\n        AuthorisationError\n            Something went wrong during authorisation.\n        \"\"\"\n        tokens = self.authorise(**kwargs)\n        with self.shard(tokens) as shard:\n            return shard.fetch_groups(ids=ids, next_page_token=next_page_token)\n\n    def fetch_group_items(self, group_id: str, **kwargs: Any) -&gt; \"GroupItemList\":\n        \"\"\"Authorise the client and fetch a list of all items within a\n        group.\n\n        ???+ note \"Changed in version 5.0\"\n            You can now pass a series of keyword arguments to be passed\n            on to the `authorise` method.\n\n        Parameters\n        ----------\n        group_id\n            The ID of the group to fetch items for.\n        **kwargs\n            Additional keyword arguments to be passed to the `authorise`\n            method.\n\n        Returns\n        -------\n        GroupItemList\n            An object containing the list of group items and the next\n            page token.\n\n        Raises\n        ------\n        BadRequest\n            Your request was invalid.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n        RuntimeError\n            The client attempted to open a new browser tab, but failed.\n        AuthorisationError\n            Something went wrong during authorisation.\n        \"\"\"\n        tokens = self.authorise(**kwargs)\n        with self.shard(tokens) as shard:\n            return shard.fetch_group_items(group_id)\n</code></pre>"},{"location":"reference/client/#analytix.client.Client.authorise","title":"authorise","text":"<pre><code>authorise(*, force: bool = False, force_refresh: bool = False) -&gt; Tokens\n</code></pre> <p>Authorise the client.</p> <p>Client methods authorise the client for you, so you don't need to call this manually when using those. If you plan to make multiple requests in a row using the same client, it's better to call this manually and create a shard with the generated tokens to avoid authorising the client multiple times.</p> Changed in version 5.0 <ul> <li>You can no longer pass a filename to load a specific set   of tokens; if you wish to change which channel is   authorised, you should either utilise shards or forcibly   reauthorise the client</li> <li>You can now forcibly refresh access tokens using this   method</li> </ul> <p>Parameters:</p> Name Type Description Default <code>force</code> <code>bool</code> <p>Whether to forcibly reauthorise the client even if your tokens are still valid.</p> <code>False</code> <code>force_refresh</code> <code>bool</code> <p>Whether to forcibly refresh your access token even if the token is still valid.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tokens</code> <p>Your tokens.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>The client attempted to open a new browser tab, but failed.</p> <code>AuthorisationError</code> <p>Something went wrong during authorisation.</p> Notes <p>This method always does the minimum possible work necessary to authorise the client unless forced to do otherwise. This means that stored tokens will be prioritised, and the full auth flow will only trigger when necessary. Token refreshing is handled automatically.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; client.authorise()\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/client.py</code> <pre><code>def authorise(self, *, force: bool = False, force_refresh: bool = False) -&gt; Tokens:\n    \"\"\"Authorise the client.\n\n    Client methods authorise the client for you, so you don't need\n    to call this manually when using those. If you plan to make\n    multiple requests in a row using the same client, it's better to\n    call this manually and create a shard with the generated tokens\n    to avoid authorising the client multiple times.\n\n    ???+ note \"Changed in version 5.0\"\n        * You can no longer pass a filename to load a specific set\n          of tokens; if you wish to change which channel is\n          authorised, you should either utilise shards or forcibly\n          reauthorise the client\n        * You can now forcibly refresh access tokens using this\n          method\n\n    Parameters\n    ----------\n    force\n        Whether to forcibly reauthorise the client even if your\n        tokens are still valid.\n    force_refresh\n        Whether to forcibly refresh your access token even if the\n        token is still valid.\n\n    Returns\n    -------\n    Tokens\n        Your tokens.\n\n    Raises\n    ------\n    RuntimeError\n        The client attempted to open a new browser tab, but failed.\n    AuthorisationError\n        Something went wrong during authorisation.\n\n    Notes\n    -----\n    This method always does the minimum possible work necessary to\n    authorise the client unless forced to do otherwise. This means\n    that stored tokens will be prioritised, and the full auth flow\n    will only trigger when necessary. Token refreshing is handled\n    automatically.\n\n    Examples\n    --------\n    &gt;&gt;&gt; client.authorise()\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    if not force and self._tokens_file.is_file():\n        tokens = Tokens.load_from(self._tokens_file)\n        if tokens.are_scoped_for(self._scopes) and (\n            refreshed := self.refresh_access_token(tokens, force=force_refresh)\n        ):\n            _log.info(\"Existing tokens are valid -- no authorisation necessary\")\n            return refreshed\n\n    _log.info(\"Authorisation necessary -- starting authorisation flow\")\n\n    auth_uri, params, _ = auth.auth_uri(self._secrets, self._scopes, self._ws_port)\n    if self._auto_open_browser:\n        if not webbrowser.open(auth_uri, 0, autoraise=True):\n            raise RuntimeError(\"web browser failed to open\")\n    else:\n        print(  # noqa: T201\n            \"\\33[38;5;45mYou need to authorise analytix.\\33[0m \"\n            f\"\\33[4m{auth_uri}\\33[0m\",\n        )\n\n    code = auth.run_flow(params)\n    _log.debug(\"Authorisation code: %s\", code)\n    token_uri, data, headers = auth.token_uri(\n        self._secrets,\n        code,\n        params[\"redirect_uri\"],\n    )\n\n    with self._request(token_uri, data=data, headers=headers) as resp:\n        if resp.status &gt; 399:\n            error = json.loads(resp.data)\n            raise AuthorisationError(\n                f\"could not authorise: {error['error_description']} \"\n                f\"({error['error']})\",\n            )\n\n        tokens = Tokens.from_json(resp.data)\n\n    tokens.save_to(self._tokens_file)\n    _log.info(\"Authorisation complete!\")\n    return tokens\n</code></pre>"},{"location":"reference/client/#analytix.client.Client.fetch_group_items","title":"fetch_group_items","text":"<pre><code>fetch_group_items(group_id: str, **kwargs: Any) -&gt; GroupItemList\n</code></pre> <p>Authorise the client and fetch a list of all items within a group.</p> Changed in version 5.0 <p>You can now pass a series of keyword arguments to be passed on to the <code>authorise</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>str</code> <p>The ID of the group to fetch items for.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the <code>authorise</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GroupItemList</code> <p>An object containing the list of group items and the next page token.</p> <p>Raises:</p> Type Description <code>BadRequest</code> <p>Your request was invalid.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> <code>RuntimeError</code> <p>The client attempted to open a new browser tab, but failed.</p> <code>AuthorisationError</code> <p>Something went wrong during authorisation.</p> Source code in <code>analytix/client.py</code> <pre><code>def fetch_group_items(self, group_id: str, **kwargs: Any) -&gt; \"GroupItemList\":\n    \"\"\"Authorise the client and fetch a list of all items within a\n    group.\n\n    ???+ note \"Changed in version 5.0\"\n        You can now pass a series of keyword arguments to be passed\n        on to the `authorise` method.\n\n    Parameters\n    ----------\n    group_id\n        The ID of the group to fetch items for.\n    **kwargs\n        Additional keyword arguments to be passed to the `authorise`\n        method.\n\n    Returns\n    -------\n    GroupItemList\n        An object containing the list of group items and the next\n        page token.\n\n    Raises\n    ------\n    BadRequest\n        Your request was invalid.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n    RuntimeError\n        The client attempted to open a new browser tab, but failed.\n    AuthorisationError\n        Something went wrong during authorisation.\n    \"\"\"\n    tokens = self.authorise(**kwargs)\n    with self.shard(tokens) as shard:\n        return shard.fetch_group_items(group_id)\n</code></pre>"},{"location":"reference/client/#analytix.client.Client.fetch_groups","title":"fetch_groups","text":"<pre><code>fetch_groups(*, ids: Optional[Collection[str]] = None, next_page_token: Optional[str] = None, **kwargs: Any) -&gt; GroupList\n</code></pre> <p>Authorise the client and fetch a list of analytics groups.</p> Changed in version 5.0 <p>You can now pass a series of keyword arguments to be passed on to the <code>authorise</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>Optional[Collection[str]]</code> <p>The IDs of groups you want to fetch. If none are provided, all your groups will be fetched.</p> <code>None</code> <code>next_page_token</code> <code>Optional[str]</code> <p>If you need to make multiple requests, you can pass this to load a specific page. To check if you've arrived back at the first page, check the next page token from the request and compare it to the next page token from the first page.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the <code>authorise</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GroupList</code> <p>An object containing the list of your groups and the next page token.</p> <p>Raises:</p> Type Description <code>BadRequest</code> <p>Your request was invalid.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> <code>RuntimeError</code> <p>The client attempted to open a new browser tab, but failed.</p> <code>AuthorisationError</code> <p>Something went wrong during authorisation.</p> Source code in <code>analytix/client.py</code> <pre><code>def fetch_groups(\n    self,\n    *,\n    ids: Optional[Collection[str]] = None,\n    next_page_token: Optional[str] = None,\n    **kwargs: Any,\n) -&gt; \"GroupList\":\n    \"\"\"Authorise the client and fetch a list of analytics groups.\n\n    ???+ note \"Changed in version 5.0\"\n        You can now pass a series of keyword arguments to be passed\n        on to the `authorise` method.\n\n    Parameters\n    ----------\n    ids\n        The IDs of groups you want to fetch. If none are provided,\n        all your groups will be fetched.\n    next_page_token\n        If you need to make multiple requests, you can pass this to\n        load a specific page. To check if you've arrived back at the\n        first page, check the next page token from the request and\n        compare it to the next page token from the first page.\n    **kwargs\n        Additional keyword arguments to be passed to the `authorise`\n        method.\n\n    Returns\n    -------\n    GroupList\n        An object containing the list of your groups and the next\n        page token.\n\n    Raises\n    ------\n    BadRequest\n        Your request was invalid.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n    RuntimeError\n        The client attempted to open a new browser tab, but failed.\n    AuthorisationError\n        Something went wrong during authorisation.\n    \"\"\"\n    tokens = self.authorise(**kwargs)\n    with self.shard(tokens) as shard:\n        return shard.fetch_groups(ids=ids, next_page_token=next_page_token)\n</code></pre>"},{"location":"reference/client/#analytix.client.Client.fetch_report","title":"fetch_report","text":"<pre><code>fetch_report(*, dimensions: Optional[Collection[str]] = None, filters: Optional[Dict[str, str]] = None, metrics: Optional[Collection[str]] = None, start_date: Optional[dt.date] = None, end_date: Optional[dt.date] = None, sort_options: Optional[Collection[str]] = None, max_results: int = 0, currency: str = 'USD', start_index: int = 1, include_historical_data: bool = False, **kwargs: Any) -&gt; Report\n</code></pre> <p>Authorise the client and fetch an analytics report.</p> Changed in version 5.0 <p>This used to be <code>retrieve_report</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dimensions</code> <code>Optional[Collection[str]]</code> <p>The dimensions to use within the request.</p> <code>None</code> <code>filters</code> <code>Optional[Dict[str, str]]</code> <p>The filters to use within the request.</p> <code>None</code> <code>metrics</code> <code>Optional[Collection[str]]</code> <p>The metrics to use within the request. If none are provided, all supported metrics are used.</p> <code>None</code> <code>sort_options</code> <code>Optional[Collection[str]]</code> <p>The sort options to use within the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Report</code> <p>The generated report.</p> <p>Other Parameters:</p> Name Type Description <code>start_date</code> <code>Optional[date]</code> <p>The date in which data should be pulled from. If this is not provided, this is set to 28 days before <code>end_date</code>.</p> <code>end_date</code> <code>Optional[date]</code> <p>The date in which data should be pulled to. If this is not provided, this is set to the current date.</p> <code>max_results</code> <code>int</code> <p>The maximum number of results the report should include. If this is <code>0</code>, no upper limit is applied.</p> <code>currency</code> <code>str</code> <p>The currency revenue data should be represented using. This should be an ISO 4217 currency code.</p> <code>start_index</code> <code>int</code> <p>The first row in the report to include. This is one-indexed. If this is <code>1</code>, all rows are included.</p> <code>include_historical_data</code> <code>bool</code> <p>Whether to include data from before the current channel owner assumed control of the channel. You only need to worry about this is the current channel owner did not create the channel.</p> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the <code>authorise</code> method.</p> <p>Raises:</p> Type Description <code>InvalidRequest</code> <p>Your request was invalid.</p> <code>BadRequest</code> <p>Your request was invalid, but it was not caught by analytix's verification systems.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> <code>RuntimeError</code> <p>The client attempted to open a new browser tab, but failed.</p> <code>AuthorisationError</code> <p>Something went wrong during authorisation.</p> Warnings <ul> <li>If your channel is not partnered, attempting to access   monetary data will result in a <code>Forbidden</code> error. Ensure your   scopes are set up correctly before calling this method.</li> <li>The \"isCurated\" filter stopped working on 30 Jun 2024. See the   guide on new playlist reports   for information on how to migrate.</li> </ul> See Also <p>You can learn more about dimensions, filters, metrics, and sort options by reading the detailed guides.</p> <p>Examples:</p> <p>Fetching daily analytics data for 2022.</p> <pre><code>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; shard.fetch_report(\n...     dimensions=(\"day\",),\n...     start_date=datetime.date(2022, 1, 1),\n...     end_date=datetime.date(2022, 12, 31),\n... )\n</code></pre> <p>Fetching 10 most watched videos over last 28 days.</p> <pre><code>&gt;&gt;&gt; shard.fetch_report(\n...     dimensions=(\"video\",),\n...     metrics=(\"estimatedMinutesWatched\", \"views\"),\n...     sort_options=(\"-estimatedMinutesWatched\",),\n...     max_results=10,\n... )\n</code></pre> Source code in <code>analytix/client.py</code> <pre><code>def fetch_report(\n    self,\n    *,\n    dimensions: Optional[Collection[str]] = None,\n    filters: Optional[Dict[str, str]] = None,\n    metrics: Optional[Collection[str]] = None,\n    start_date: Optional[dt.date] = None,\n    end_date: Optional[dt.date] = None,\n    sort_options: Optional[Collection[str]] = None,\n    max_results: int = 0,\n    currency: str = \"USD\",\n    start_index: int = 1,\n    include_historical_data: bool = False,\n    **kwargs: Any,\n) -&gt; \"Report\":\n    \"\"\"Authorise the client and fetch an analytics report.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `retrieve_report`.\n\n    Parameters\n    ----------\n    dimensions\n        The dimensions to use within the request.\n    filters\n        The filters to use within the request.\n    metrics\n        The metrics to use within the request. If none are provided,\n        all supported metrics are used.\n    sort_options\n        The sort options to use within the request.\n\n    Returns\n    -------\n    Report\n        The generated report.\n\n    Other Parameters\n    ----------------\n    start_date\n        The date in which data should be pulled from. If this is\n        not provided, this is set to 28 days before `end_date`.\n    end_date\n        The date in which data should be pulled to. If this is not\n        provided, this is set to the current date.\n    max_results\n        The maximum number of results the report should include. If\n        this is `0`, no upper limit is applied.\n    currency\n        The currency revenue data should be represented using. This\n        should be an ISO 4217 currency code.\n    start_index\n        The first row in the report to include. This is one-indexed.\n        If this is `1`, all rows are included.\n    include_historical_data\n        Whether to include data from before the current channel\n        owner assumed control of the channel. You only need to worry\n        about this is the current channel owner did not create the\n        channel.\n    **kwargs\n        Additional keyword arguments to be passed to the `authorise`\n        method.\n\n    Raises\n    ------\n    InvalidRequest\n        Your request was invalid.\n    BadRequest\n        Your request was invalid, but it was not caught by\n        analytix's verification systems.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n    RuntimeError\n        The client attempted to open a new browser tab, but failed.\n    AuthorisationError\n        Something went wrong during authorisation.\n\n    Warnings\n    --------\n    * If your channel is not partnered, attempting to access\n      monetary data will result in a `Forbidden` error. Ensure your\n      scopes are set up correctly before calling this method.\n    * The \"isCurated\" filter stopped working on 30 Jun 2024. See the\n      [guide on new playlist reports](../guides/new-playlist-reports.md)\n      for information on how to migrate.\n\n    See Also\n    --------\n    You can learn more about dimensions, filters, metrics, and sort\n    options by reading the [detailed guides](../guides/\n    dimensions.md).\n\n    Examples\n    --------\n    Fetching daily analytics data for 2022.\n\n    &gt;&gt;&gt; import datetime\n    &gt;&gt;&gt; shard.fetch_report(\n    ...     dimensions=(\"day\",),\n    ...     start_date=datetime.date(2022, 1, 1),\n    ...     end_date=datetime.date(2022, 12, 31),\n    ... )\n\n    Fetching 10 most watched videos over last 28 days.\n\n    &gt;&gt;&gt; shard.fetch_report(\n    ...     dimensions=(\"video\",),\n    ...     metrics=(\"estimatedMinutesWatched\", \"views\"),\n    ...     sort_options=(\"-estimatedMinutesWatched\",),\n    ...     max_results=10,\n    ... )\n    \"\"\"\n    tokens = self.authorise(**kwargs)\n    with self.shard(tokens) as shard:\n        return shard.fetch_report(\n            dimensions=dimensions,\n            filters=filters,\n            metrics=metrics,\n            start_date=start_date,\n            end_date=end_date,\n            sort_options=sort_options,\n            max_results=max_results,\n            currency=currency,\n            start_index=start_index,\n            include_historical_data=include_historical_data,\n        )\n</code></pre>"},{"location":"reference/client/#analytix.client.Client.refresh_access_token","title":"refresh_access_token","text":"<pre><code>refresh_access_token(tokens: Tokens, *, force: bool = False) -&gt; Optional[Tokens]\n</code></pre> <p>Refresh your access token.</p> <p>New in version 5.0</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>Tokens</code> <p>Your tokens.</p> required <code>force</code> <code>bool</code> <p>Whether to forcibly refresh your access token, even if the token is still valid.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[Tokens]</code> <p>Your refreshed tokens, or <code>None</code> if they could not be refreshed.</p> Notes <p>This method should never need to be called, as the <code>authorise</code> method will call it automatically when necessary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; client.refresh_access_token(tokens)\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/client.py</code> <pre><code>def refresh_access_token(\n    self,\n    tokens: Tokens,\n    *,\n    force: bool = False,\n) -&gt; Optional[Tokens]:\n    \"\"\"Refresh your access token.\n\n    !!! note \"New in version 5.0\"\n\n    Parameters\n    ----------\n    tokens\n        Your tokens.\n    force\n        Whether to forcibly refresh your access token, even if the\n        token is still valid.\n\n    Returns\n    -------\n    Optional[Tokens]\n        Your refreshed tokens, or `None` if they could not be\n        refreshed.\n\n    Notes\n    -----\n    This method should never need to be called, as the `authorise`\n    method will call it automatically when necessary.\n\n    Examples\n    --------\n    &gt;&gt;&gt; client.refresh_access_token(tokens)\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    if not (force or tokens.expired):\n        return tokens\n\n    if refreshed := super().refresh_access_token(tokens):\n        refreshed.save_to(self._tokens_file)\n\n    return refreshed\n</code></pre>"},{"location":"reference/errors/","title":"errors","text":"<p>Exception classes for analytix.</p>"},{"location":"reference/errors/#analytix.errors.APIError","title":"APIError","text":"<p>               Bases: <code>AnalytixError</code></p> <p>The YouTube Analytics API has returned an error.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>Union[str, int]</code> <p>The error code.</p> required <code>message</code> <code>str</code> <p>The error message.</p> required Source code in <code>analytix/errors.py</code> <pre><code>class APIError(AnalytixError):\n    \"\"\"The YouTube Analytics API has returned an error.\n\n    Parameters\n    ----------\n    code\n        The error code.\n    message\n        The error message.\n    \"\"\"\n\n    def __init__(self, code: Union[str, int], message: str) -&gt; None:\n        super().__init__(f\"API returned {code}: {message}\")\n</code></pre>"},{"location":"reference/errors/#analytix.errors.AnalytixError","title":"AnalytixError","text":"<p>               Bases: <code>Exception</code></p> <p>The base exception class for analytix.</p> Source code in <code>analytix/errors.py</code> <pre><code>class AnalytixError(Exception):\n    \"\"\"The base exception class for analytix.\"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.AuthorisationError","title":"AuthorisationError","text":"<p>               Bases: <code>AnalytixError</code></p> <p>Something's gone wrong during the authorisation process.</p> Source code in <code>analytix/errors.py</code> <pre><code>class AuthorisationError(AnalytixError):\n    \"\"\"Something's gone wrong during the authorisation process.\"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.BadRequest","title":"BadRequest","text":"<p>               Bases: <code>APIError</code></p> <p>The YouTube Analytics API has returned a 400 status.</p> <p>This only happens when analytix has failed to catch an invalid request. If you see an error like this, report it!</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>Union[str, int]</code> <p>The error code.</p> required <code>message</code> <code>str</code> <p>The error message.</p> required Source code in <code>analytix/errors.py</code> <pre><code>class BadRequest(APIError):\n    \"\"\"The YouTube Analytics API has returned a 400 status.\n\n    This only happens when analytix has failed to catch an invalid\n    request. If you see an error like this, report it!\n\n    Parameters\n    ----------\n    code\n        The error code.\n    message\n        The error message.\n    \"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.DataFrameConversionError","title":"DataFrameConversionError","text":"<p>               Bases: <code>AnalytixError</code></p> <p>Your report could not be converted to a DataFrame or table.</p> Source code in <code>analytix/errors.py</code> <pre><code>class DataFrameConversionError(AnalytixError):\n    \"\"\"Your report could not be converted to a DataFrame or table.\"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.Forbidden","title":"Forbidden","text":"<p>               Bases: <code>APIError</code></p> <p>The YouTube Analytics API has returned a 403 status.</p> <p>This is raised when you attempt to access monetary data from a non-partnered channel.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>Union[str, int]</code> <p>The error code.</p> required <code>message</code> <code>str</code> <p>The error message.</p> required Source code in <code>analytix/errors.py</code> <pre><code>class Forbidden(APIError):\n    \"\"\"The YouTube Analytics API has returned a 403 status.\n\n    This is raised when you attempt to access monetary data from a\n    non-partnered channel.\n\n    Parameters\n    ----------\n    code\n        The error code.\n    message\n        The error message.\n    \"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.IdTokenError","title":"IdTokenError","text":"<p>               Bases: <code>AuthorisationError</code></p> <p>Your ID token could not be token.</p> Source code in <code>analytix/errors.py</code> <pre><code>class IdTokenError(AuthorisationError):\n    \"\"\"Your ID token could not be token.\"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.InvalidRequest","title":"InvalidRequest","text":"<p>               Bases: <code>AnalytixError</code></p> <p>analytix has found a problem in the request you tried to make to the YouTube Analytics API.</p> Source code in <code>analytix/errors.py</code> <pre><code>class InvalidRequest(AnalytixError):\n    \"\"\"analytix has found a problem in the request you tried to make\n    to the YouTube Analytics API.\"\"\"\n\n    @staticmethod\n    def list_of(values: Set[str]) -&gt; str:\n        items = tuple(f\"{v!r}\" for v in sorted(values))\n\n        if len(items) &gt; 2:\n            return f\"{', '.join(items[:-1])}, and {items[-1]}\"\n\n        return \" and \".join(items)\n\n    @classmethod\n    def invalid(cls, key: str, values: Set[str]) -&gt; \"InvalidRequest\":\n        plural = \"s\" if len(values) &gt; 1 else \"\"\n        return cls(f\"invalid {key}{plural} provided: {cls.list_of(values)}\")\n\n    @classmethod\n    def incompatible_dimensions(cls, values: Set[str]) -&gt; \"InvalidRequest\":\n        return cls(f\"dimensions {cls.list_of(values)} cannot be used together\")\n\n    @classmethod\n    def incompatible_filters(cls, values: Set[str]) -&gt; \"InvalidRequest\":\n        return cls(f\"filters {cls.list_of(values)} cannot be used together\")\n\n    @classmethod\n    def invalid_filter_value(cls, key: str, value: str) -&gt; \"InvalidRequest\":\n        return cls(f\"invalid value {value!r} for filter {key!r}\")\n\n    @classmethod\n    def incompatible_filter_value(cls, key: str, value: str) -&gt; \"InvalidRequest\":\n        return cls(\n            f\"value {value!r} for filter {key!r} cannot be used with the given \"\n            \"dimensions\",\n        )\n\n    @classmethod\n    def incompatible_metrics(cls, values: Set[str]) -&gt; \"InvalidRequest\":\n        plural = \"s\" if len(values) &gt; 1 else \"\"\n        return cls(\n            f\"metric{plural} {cls.list_of(values)} cannot be used with the given \"\n            \"dimensions and filters\",\n        )\n\n    @classmethod\n    def incompatible_sort_options(cls, values: Set[str]) -&gt; \"InvalidRequest\":\n        plural = \"s\" if len(values) &gt; 1 else \"\"\n        return cls(\n            f\"sort option{plural} {cls.list_of(values)} cannot be used with the given \"\n            \"dimensions and filters\",\n        )\n\n    @classmethod\n    def non_matching_sort_options(cls, values: Set[str]) -&gt; \"InvalidRequest\":\n        plural = \"s\" if len(values) &gt; 1 else \"\"\n        isare = \"are\" if plural else \"is\"\n        return cls(\n            f\"sort option{plural} {cls.list_of(values)} {isare} not part of the given \"\n            \"metrics\",\n        )\n\n    @classmethod\n    def invalid_set(\n        cls,\n        key: str,\n        values: Set[str],\n        expd: str,\n        recv: int,\n    ) -&gt; \"InvalidRequest\":\n        plural = \"\" if expd in {\"1\", \"at least 1\"} else \"s\"\n        return cls(\n            f\"expected {expd} {key}{plural} from {cls.list_of(values)}, got {recv}\",\n        )\n</code></pre>"},{"location":"reference/errors/#analytix.errors.MissingOptionalComponents","title":"MissingOptionalComponents","text":"<p>               Bases: <code>AnalytixError</code></p> <p>Components not installed by analytix by default are required for a specific operation, but are not installed.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>The libraries that need to be installed.</p> <code>()</code> Source code in <code>analytix/errors.py</code> <pre><code>class MissingOptionalComponents(AnalytixError):\n    \"\"\"Components not installed by analytix by default are required for\n    a specific operation, but are not installed.\n\n    Parameters\n    ----------\n    *args\n        The libraries that need to be installed.\n    \"\"\"\n\n    def __init__(self, *args: str) -&gt; None:\n        vals = \" \".join(args)\n        super().__init__(\n            f\"some necessary libraries are not installed (hint: pip install {vals})\",\n        )\n</code></pre>"},{"location":"reference/errors/#analytix.errors.NotAuthorised","title":"NotAuthorised","text":"<p>               Bases: <code>AuthorisationError</code></p> <p>The client does not have sufficient authorisation to complete the requested operation.</p> Source code in <code>analytix/errors.py</code> <pre><code>class NotAuthorised(AuthorisationError):\n    \"\"\"The client does not have sufficient authorisation to complete the\n    requested operation.\"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.NotFound","title":"NotFound","text":"<p>               Bases: <code>APIError</code></p> <p>The YouTube Analytics API has returned a 404 status.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>Union[str, int]</code> <p>The error code.</p> required <code>message</code> <code>str</code> <p>The error message.</p> required Source code in <code>analytix/errors.py</code> <pre><code>class NotFound(APIError):\n    \"\"\"The YouTube Analytics API has returned a 404 status.\n\n    Parameters\n    ----------\n    code\n        The error code.\n    message\n        The error message.\n    \"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.RefreshTokenExpired","title":"RefreshTokenExpired","text":"<p>               Bases: <code>AuthorisationError</code></p> <p>Your refresh token has expired.</p> Source code in <code>analytix/errors.py</code> <pre><code>class RefreshTokenExpired(AuthorisationError):\n    \"\"\"Your refresh token has expired.\"\"\"\n</code></pre>"},{"location":"reference/errors/#analytix.errors.Unauthorised","title":"Unauthorised","text":"<p>               Bases: <code>APIError</code></p> <p>The YouTube Analytics API has returned a 401 status.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>Union[str, int]</code> <p>The error code.</p> required <code>message</code> <code>str</code> <p>The error message.</p> required Source code in <code>analytix/errors.py</code> <pre><code>class Unauthorised(APIError):\n    \"\"\"The YouTube Analytics API has returned a 401 status.\n\n    Parameters\n    ----------\n    code\n        The error code.\n    message\n        The error message.\n    \"\"\"\n</code></pre>"},{"location":"reference/shard/","title":"shard","text":"<p>A shard interface for analytix.</p> <p>Shards are used by clients as an interface through which to make requests, and are particularly useful when multiple users are likely to make requests at the same time.</p>"},{"location":"reference/shard/#analytix.shard.Shard","title":"Shard","text":"<p>               Bases: <code>RequestMixin</code></p> <p>A \"mini-client\" used to handle requests to the YouTube Analytics API.</p> <p>Shards should only be created using the <code>BaseClient.shard</code> or <code>Client.shard</code> context managers.</p> Changed in version 5.0 <ul> <li>Shard-specific scopes can now be passed to the constructor</li> <li>Shards can no longer refresh their own tokens</li> </ul> <p>Parameters:</p> Name Type Description Default <code>scopes</code> <code>Scopes</code> <p>The scopes to allow in requests. This is used to control whether or not to allow access to monetary data.</p> required <code>tokens</code> <code>Tokens</code> <p>Your tokens.</p> required Warnings <p>Shards cannot refresh their own tokens. You may want to take extra precautions to ensure a shard's tokens don't expire during its lifetime.</p> Source code in <code>analytix/shard.py</code> <pre><code>class Shard(RequestMixin):\n    \"\"\"A \"mini-client\" used to handle requests to the YouTube Analytics\n    API.\n\n    Shards should only be created using the `BaseClient.shard` or\n    `Client.shard` context managers.\n\n    ???+ note \"Changed in version 5.0\"\n        * Shard-specific scopes can now be passed to the constructor\n        * Shards can no longer refresh their own tokens\n\n    Parameters\n    ----------\n    scopes\n        The scopes to allow in requests. This is used to control whether\n        or not to allow access to monetary data.\n    tokens\n        Your tokens.\n\n    Warnings\n    --------\n    Shards cannot refresh their own tokens. You may want to take extra\n    precautions to ensure a shard's tokens don't expire during its\n    lifetime.\n    \"\"\"\n\n    __slots__ = (\"_scopes\", \"_tokens\")\n\n    def __init__(self, scopes: \"Scopes\", tokens: \"Tokens\") -&gt; None:\n        self._scopes = scopes\n        self._tokens = tokens\n\n    def fetch_report(\n        self,\n        *,\n        dimensions: Optional[Collection[str]] = None,\n        filters: Optional[Dict[str, str]] = None,\n        metrics: Optional[Collection[str]] = None,\n        sort_options: Optional[Collection[str]] = None,\n        start_date: Optional[dt.date] = None,\n        end_date: Optional[dt.date] = None,\n        max_results: int = 0,\n        currency: str = \"USD\",\n        start_index: int = 1,\n        include_historical_data: bool = False,\n    ) -&gt; Report:\n        \"\"\"Fetch an analytics report.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `retrieve_report`.\n\n        Parameters\n        ----------\n        dimensions\n            The dimensions to use within the request.\n        filters\n            The filters to use within the request.\n        metrics\n            The metrics to use within the request. If none are provided,\n            all supported metrics are used.\n        sort_options\n            The sort options to use within the request.\n\n        Returns\n        -------\n        Report\n            The generated report.\n\n        Other Parameters\n        ----------------\n        start_date\n            The date in which data should be pulled from. If this is\n            not provided, this is set to 28 days before `end_date`.\n        end_date\n            The date in which data should be pulled to. If this is not\n            provided, this is set to the current date.\n        max_results\n            The maximum number of results the report should include. If\n            this is `0`, no upper limit is applied.\n        currency\n            The currency revenue data should be represented using. This\n            should be an ISO 4217 currency code.\n        start_index\n            The first row in the report to include. This is one-indexed.\n            If this is `1`, all rows are included.\n        include_historical_data\n            Whether to include data from before the current channel\n            owner assumed control of the channel. You only need to worry\n            about this is the current channel owner did not create the\n            channel.\n\n        Raises\n        ------\n        InvalidRequest\n            Your request was invalid.\n        BadRequest\n            Your request was invalid, but it was not caught by\n            analytix's verification systems.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n\n        Warnings\n        --------\n        * If your channel is not partnered, attempting to access\n          monetary data will result in a `Forbidden` error. Ensure\n          your scopes are set up correctly before calling this method.\n        * The \"isCurated\" filter stopped working on 30 Jun 2024. See the\n          [guide on new playlist reports](../guides/new-playlist-reports.md)\n          for information on how to migrate.\n\n        See Also\n        --------\n        You can learn more about dimensions, filters, metrics, and sort\n        options by reading the [detailed guides](../guides/\n        dimensions.md).\n\n        Examples\n        --------\n        Fetching daily analytics data for 2022.\n\n        &gt;&gt;&gt; import datetime\n        &gt;&gt;&gt; shard.fetch_report(\n        ...     dimensions=(\"day\",),\n        ...     start_date=datetime.date(2022, 1, 1),\n        ...     end_date=datetime.date(2022, 12, 31),\n        ... )\n\n        Fetching 10 most watched videos over last 28 days.\n\n        &gt;&gt;&gt; shard.fetch_report(\n        ...     dimensions=(\"video\",),\n        ...     metrics=(\"estimatedMinutesWatched\", \"views\"),\n        ...     sort_options=(\"-estimatedMinutesWatched\",),\n        ...     max_results=10,\n        ... )\n        \"\"\"\n        query = ReportQuery(\n            dimensions,\n            filters,\n            metrics,\n            sort_options,\n            max_results,\n            start_date,\n            end_date,\n            currency,\n            start_index,\n            include_historical_data,\n        )\n        query.validate(self._scopes)\n\n        with self._request(query.url, token=self._tokens.access_token) as resp:\n            data = json.loads(resp.data)\n\n        assert query.rtype\n        report = Report(data, query.rtype)\n        _log.info(\"Created '%s' report of shape %s\", query.rtype, report.shape)\n        return report\n\n    def fetch_groups(\n        self,\n        *,\n        ids: Optional[Collection[str]] = None,\n        next_page_token: Optional[str] = None,\n    ) -&gt; GroupList:\n        \"\"\"Fetch a list of analytics groups.\n\n        Parameters\n        ----------\n        ids\n            The IDs of groups you want to fetch. If none are provided,\n            all your groups will be fetched.\n        next_page_token\n            If you need to make multiple requests, you can pass this to\n            load a specific page. To check if you've arrived back at the\n            first page, check the next page token from the request and\n            compare it to the next page token from the first page.\n\n        Returns\n        -------\n        GroupList\n            An object containing the list of your groups and the next\n            page token.\n\n        Raises\n        ------\n        BadRequest\n            Your request was invalid.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n        \"\"\"\n        query = GroupQuery(ids, next_page_token)\n        with self._request(query.url, token=self._tokens.access_token) as resp:\n            return GroupList.from_json(self, json.loads(resp.data))\n\n    def fetch_group_items(self, group_id: str) -&gt; GroupItemList:\n        \"\"\"Fetch a list of all items within a group.\n\n        Parameters\n        ----------\n        group_id\n            The ID of the group to fetch items for.\n\n        Returns\n        -------\n        GroupItemList\n            An object containing the list of group items and the next\n            page token.\n\n        Raises\n        ------\n        BadRequest\n            Your request was invalid.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n        \"\"\"\n        query = GroupItemQuery(group_id)\n        with self._request(query.url, token=self._tokens.access_token) as resp:\n            return GroupItemList.from_json(json.loads(resp.data))\n</code></pre>"},{"location":"reference/shard/#analytix.shard.Shard.fetch_group_items","title":"fetch_group_items","text":"<pre><code>fetch_group_items(group_id: str) -&gt; GroupItemList\n</code></pre> <p>Fetch a list of all items within a group.</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>str</code> <p>The ID of the group to fetch items for.</p> required <p>Returns:</p> Type Description <code>GroupItemList</code> <p>An object containing the list of group items and the next page token.</p> <p>Raises:</p> Type Description <code>BadRequest</code> <p>Your request was invalid.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> Source code in <code>analytix/shard.py</code> <pre><code>def fetch_group_items(self, group_id: str) -&gt; GroupItemList:\n    \"\"\"Fetch a list of all items within a group.\n\n    Parameters\n    ----------\n    group_id\n        The ID of the group to fetch items for.\n\n    Returns\n    -------\n    GroupItemList\n        An object containing the list of group items and the next\n        page token.\n\n    Raises\n    ------\n    BadRequest\n        Your request was invalid.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n    \"\"\"\n    query = GroupItemQuery(group_id)\n    with self._request(query.url, token=self._tokens.access_token) as resp:\n        return GroupItemList.from_json(json.loads(resp.data))\n</code></pre>"},{"location":"reference/shard/#analytix.shard.Shard.fetch_groups","title":"fetch_groups","text":"<pre><code>fetch_groups(*, ids: Optional[Collection[str]] = None, next_page_token: Optional[str] = None) -&gt; GroupList\n</code></pre> <p>Fetch a list of analytics groups.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>Optional[Collection[str]]</code> <p>The IDs of groups you want to fetch. If none are provided, all your groups will be fetched.</p> <code>None</code> <code>next_page_token</code> <code>Optional[str]</code> <p>If you need to make multiple requests, you can pass this to load a specific page. To check if you've arrived back at the first page, check the next page token from the request and compare it to the next page token from the first page.</p> <code>None</code> <p>Returns:</p> Type Description <code>GroupList</code> <p>An object containing the list of your groups and the next page token.</p> <p>Raises:</p> Type Description <code>BadRequest</code> <p>Your request was invalid.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> Source code in <code>analytix/shard.py</code> <pre><code>def fetch_groups(\n    self,\n    *,\n    ids: Optional[Collection[str]] = None,\n    next_page_token: Optional[str] = None,\n) -&gt; GroupList:\n    \"\"\"Fetch a list of analytics groups.\n\n    Parameters\n    ----------\n    ids\n        The IDs of groups you want to fetch. If none are provided,\n        all your groups will be fetched.\n    next_page_token\n        If you need to make multiple requests, you can pass this to\n        load a specific page. To check if you've arrived back at the\n        first page, check the next page token from the request and\n        compare it to the next page token from the first page.\n\n    Returns\n    -------\n    GroupList\n        An object containing the list of your groups and the next\n        page token.\n\n    Raises\n    ------\n    BadRequest\n        Your request was invalid.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n    \"\"\"\n    query = GroupQuery(ids, next_page_token)\n    with self._request(query.url, token=self._tokens.access_token) as resp:\n        return GroupList.from_json(self, json.loads(resp.data))\n</code></pre>"},{"location":"reference/shard/#analytix.shard.Shard.fetch_report","title":"fetch_report","text":"<pre><code>fetch_report(*, dimensions: Optional[Collection[str]] = None, filters: Optional[Dict[str, str]] = None, metrics: Optional[Collection[str]] = None, sort_options: Optional[Collection[str]] = None, start_date: Optional[dt.date] = None, end_date: Optional[dt.date] = None, max_results: int = 0, currency: str = 'USD', start_index: int = 1, include_historical_data: bool = False) -&gt; Report\n</code></pre> <p>Fetch an analytics report.</p> Changed in version 5.0 <p>This used to be <code>retrieve_report</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dimensions</code> <code>Optional[Collection[str]]</code> <p>The dimensions to use within the request.</p> <code>None</code> <code>filters</code> <code>Optional[Dict[str, str]]</code> <p>The filters to use within the request.</p> <code>None</code> <code>metrics</code> <code>Optional[Collection[str]]</code> <p>The metrics to use within the request. If none are provided, all supported metrics are used.</p> <code>None</code> <code>sort_options</code> <code>Optional[Collection[str]]</code> <p>The sort options to use within the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Report</code> <p>The generated report.</p> <p>Other Parameters:</p> Name Type Description <code>start_date</code> <code>Optional[date]</code> <p>The date in which data should be pulled from. If this is not provided, this is set to 28 days before <code>end_date</code>.</p> <code>end_date</code> <code>Optional[date]</code> <p>The date in which data should be pulled to. If this is not provided, this is set to the current date.</p> <code>max_results</code> <code>int</code> <p>The maximum number of results the report should include. If this is <code>0</code>, no upper limit is applied.</p> <code>currency</code> <code>str</code> <p>The currency revenue data should be represented using. This should be an ISO 4217 currency code.</p> <code>start_index</code> <code>int</code> <p>The first row in the report to include. This is one-indexed. If this is <code>1</code>, all rows are included.</p> <code>include_historical_data</code> <code>bool</code> <p>Whether to include data from before the current channel owner assumed control of the channel. You only need to worry about this is the current channel owner did not create the channel.</p> <p>Raises:</p> Type Description <code>InvalidRequest</code> <p>Your request was invalid.</p> <code>BadRequest</code> <p>Your request was invalid, but it was not caught by analytix's verification systems.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> Warnings <ul> <li>If your channel is not partnered, attempting to access   monetary data will result in a <code>Forbidden</code> error. Ensure   your scopes are set up correctly before calling this method.</li> <li>The \"isCurated\" filter stopped working on 30 Jun 2024. See the   guide on new playlist reports   for information on how to migrate.</li> </ul> See Also <p>You can learn more about dimensions, filters, metrics, and sort options by reading the detailed guides.</p> <p>Examples:</p> <p>Fetching daily analytics data for 2022.</p> <pre><code>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; shard.fetch_report(\n...     dimensions=(\"day\",),\n...     start_date=datetime.date(2022, 1, 1),\n...     end_date=datetime.date(2022, 12, 31),\n... )\n</code></pre> <p>Fetching 10 most watched videos over last 28 days.</p> <pre><code>&gt;&gt;&gt; shard.fetch_report(\n...     dimensions=(\"video\",),\n...     metrics=(\"estimatedMinutesWatched\", \"views\"),\n...     sort_options=(\"-estimatedMinutesWatched\",),\n...     max_results=10,\n... )\n</code></pre> Source code in <code>analytix/shard.py</code> <pre><code>def fetch_report(\n    self,\n    *,\n    dimensions: Optional[Collection[str]] = None,\n    filters: Optional[Dict[str, str]] = None,\n    metrics: Optional[Collection[str]] = None,\n    sort_options: Optional[Collection[str]] = None,\n    start_date: Optional[dt.date] = None,\n    end_date: Optional[dt.date] = None,\n    max_results: int = 0,\n    currency: str = \"USD\",\n    start_index: int = 1,\n    include_historical_data: bool = False,\n) -&gt; Report:\n    \"\"\"Fetch an analytics report.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `retrieve_report`.\n\n    Parameters\n    ----------\n    dimensions\n        The dimensions to use within the request.\n    filters\n        The filters to use within the request.\n    metrics\n        The metrics to use within the request. If none are provided,\n        all supported metrics are used.\n    sort_options\n        The sort options to use within the request.\n\n    Returns\n    -------\n    Report\n        The generated report.\n\n    Other Parameters\n    ----------------\n    start_date\n        The date in which data should be pulled from. If this is\n        not provided, this is set to 28 days before `end_date`.\n    end_date\n        The date in which data should be pulled to. If this is not\n        provided, this is set to the current date.\n    max_results\n        The maximum number of results the report should include. If\n        this is `0`, no upper limit is applied.\n    currency\n        The currency revenue data should be represented using. This\n        should be an ISO 4217 currency code.\n    start_index\n        The first row in the report to include. This is one-indexed.\n        If this is `1`, all rows are included.\n    include_historical_data\n        Whether to include data from before the current channel\n        owner assumed control of the channel. You only need to worry\n        about this is the current channel owner did not create the\n        channel.\n\n    Raises\n    ------\n    InvalidRequest\n        Your request was invalid.\n    BadRequest\n        Your request was invalid, but it was not caught by\n        analytix's verification systems.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n\n    Warnings\n    --------\n    * If your channel is not partnered, attempting to access\n      monetary data will result in a `Forbidden` error. Ensure\n      your scopes are set up correctly before calling this method.\n    * The \"isCurated\" filter stopped working on 30 Jun 2024. See the\n      [guide on new playlist reports](../guides/new-playlist-reports.md)\n      for information on how to migrate.\n\n    See Also\n    --------\n    You can learn more about dimensions, filters, metrics, and sort\n    options by reading the [detailed guides](../guides/\n    dimensions.md).\n\n    Examples\n    --------\n    Fetching daily analytics data for 2022.\n\n    &gt;&gt;&gt; import datetime\n    &gt;&gt;&gt; shard.fetch_report(\n    ...     dimensions=(\"day\",),\n    ...     start_date=datetime.date(2022, 1, 1),\n    ...     end_date=datetime.date(2022, 12, 31),\n    ... )\n\n    Fetching 10 most watched videos over last 28 days.\n\n    &gt;&gt;&gt; shard.fetch_report(\n    ...     dimensions=(\"video\",),\n    ...     metrics=(\"estimatedMinutesWatched\", \"views\"),\n    ...     sort_options=(\"-estimatedMinutesWatched\",),\n    ...     max_results=10,\n    ... )\n    \"\"\"\n    query = ReportQuery(\n        dimensions,\n        filters,\n        metrics,\n        sort_options,\n        max_results,\n        start_date,\n        end_date,\n        currency,\n        start_index,\n        include_historical_data,\n    )\n    query.validate(self._scopes)\n\n    with self._request(query.url, token=self._tokens.access_token) as resp:\n        data = json.loads(resp.data)\n\n    assert query.rtype\n    report = Report(data, query.rtype)\n    _log.info(\"Created '%s' report of shape %s\", query.rtype, report.shape)\n    return report\n</code></pre>"},{"location":"reference/ux/","title":"ux","text":"<p>User experience utilities.</p>"},{"location":"reference/ux/#analytix.ux.enable_logging","title":"enable_logging","text":"<pre><code>enable_logging(level: int = logging.INFO) -&gt; logging.StreamHandler[TextIO]\n</code></pre> <p>Enable analytix's preconfigured logger.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>The log level to use.</p> <code>INFO</code> <p>Returns:</p> Type Description <code>StreamHandler object</code> <p>The created log handler.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; analytix.enable_logging(logging.DEBUG)\n</code></pre> <p>Enable the logger in DEBUG mode.</p> <pre><code>&gt;&gt;&gt; analytix.enable_logging(logging.DEBUG)\n</code></pre> Source code in <code>analytix/ux.py</code> <pre><code>def enable_logging(level: int = logging.INFO) -&gt; \"logging.StreamHandler[TextIO]\":\n    \"\"\"Enable analytix's preconfigured logger.\n\n    Parameters\n    ----------\n    level\n        The log level to use.\n\n    Returns\n    -------\n    StreamHandler object\n        The created log handler.\n\n    Examples\n    --------\n    &gt;&gt;&gt; analytix.enable_logging(logging.DEBUG)\n\n    Enable the logger in DEBUG mode.\n\n    &gt;&gt;&gt; analytix.enable_logging(logging.DEBUG)\n    \"\"\"\n\n    fmt = \"{asctime}.{msecs:03.0f} [ {levelname:&lt;7} ] {name}: {message}\"\n    formats = {\n        logging.DEBUG: f\"\\33[38;5;244m{fmt}\\33[0m\",\n        logging.INFO: f\"\\33[38;5;248m{fmt}\\33[0m\",\n        logging.WARNING: f\"\\33[1m\\33[38;5;178m{fmt}\\33[0m\",\n        logging.ERROR: f\"\\33[1m\\33[38;5;196m{fmt}\\33[0m\",\n        logging.CRITICAL: f\"\\33[1m\\33[48;5;196m{fmt}\\33[0m\",\n    }\n\n    class CustomFormatter(logging.Formatter):\n        def format(self, record: logging.LogRecord) -&gt; str:\n            log_fmt = formats[record.levelno]\n            formatter = logging.Formatter(log_fmt, \"%F %X\", style=\"{\")\n            return formatter.format(record)\n\n    handler = logging.StreamHandler()\n    handler.setFormatter(CustomFormatter())\n    logging.basicConfig(level=level, handlers=[handler])\n    logging._srcfile = None  # noqa: SLF001\n    logging.logThreads = False\n    logging.logProcesses = False\n    logging.logMultiprocessing = False\n\n    def showwarning(\n        message: Union[Warning, str],\n        category: Type[Warning],\n        filename: str,\n        lineno: int,\n        file: Optional[\"TextIO\"] = None,\n        line: Optional[str] = None,\n    ) -&gt; None:\n        for _module_name, module in sys.modules.items():\n            module_path = getattr(module, \"__file__\", None)\n            if module_path and os.path.samefile(module_path, filename):\n                break\n        else:\n            _module_name = os.path.splitext(os.path.split(filename)[1])[0]\n        log = logging.getLogger(_module_name)\n        log.warning(message)\n\n    warnings.simplefilter(\"always\", DeprecationWarning)\n    warnings.showwarning = showwarning\n\n    return handler\n</code></pre>"},{"location":"reference/warnings/","title":"warnings","text":"<p>Warning classes for analytix.</p>"},{"location":"reference/warnings/#analytix.warnings.AnalytixWarning","title":"AnalytixWarning","text":"<p>               Bases: <code>Warning</code></p> <p>The base warning class for analytix.</p> Source code in <code>analytix/warnings.py</code> <pre><code>class AnalytixWarning(Warning):\n    \"\"\"The base warning class for analytix.\"\"\"\n</code></pre>"},{"location":"reference/warnings/#analytix.warnings.CityReportWarning","title":"CityReportWarning","text":"<p>               Bases: <code>AnalytixWarning</code></p> <p>The YouTube API docs are wrong (genuinely).</p> Source code in <code>analytix/warnings.py</code> <pre><code>class CityReportWarning(AnalytixWarning):\n    \"\"\"The YouTube API docs are wrong (genuinely).\"\"\"\n</code></pre>"},{"location":"reference/warnings/#analytix.warnings.InvalidMonthFormatWarning","title":"InvalidMonthFormatWarning","text":"<p>               Bases: <code>AnalytixWarning</code></p> <p>The months in your request had to be fixed.</p> Source code in <code>analytix/warnings.py</code> <pre><code>class InvalidMonthFormatWarning(AnalytixWarning):\n    \"\"\"The months in your request had to be fixed.\"\"\"\n</code></pre>"},{"location":"reference/warnings/#analytix.warnings.NotUpdatedWarning","title":"NotUpdatedWarning","text":"<p>               Bases: <code>AnalytixWarning</code></p> <p>Your client is not updated.</p> Source code in <code>analytix/warnings.py</code> <pre><code>class NotUpdatedWarning(AnalytixWarning):\n    \"\"\"Your client is not updated.\"\"\"\n</code></pre>"},{"location":"reference/auth/flow/","title":"flow","text":""},{"location":"reference/auth/flow/#analytix.auth.flow.run_flow","title":"run_flow","text":"<pre><code>run_flow(auth_params: Dict[str, str]) -&gt; str\n</code></pre> <p>Start a webserver and listen for an authentication code.</p> Changed in version 5.0 <p>This used to be <code>authenticate</code>.</p> <p>Parameters:</p> Name Type Description Default <code>auth_params</code> <code>Dict[str, str]</code> <p>The parameters generated from the <code>auth_uri</code> method.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Your authentication code.</p> <p>Raises:</p> Type Description <code>AuthorisationError</code> <ul> <li>You provided an invalid redirect URI</li> <li>The received state does not match the generated one</li> </ul> Source code in <code>analytix/auth/flow.py</code> <pre><code>def run_flow(auth_params: Dict[str, str]) -&gt; str:\n    \"\"\"Start a webserver and listen for an authentication code.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `authenticate`.\n\n    Parameters\n    ----------\n    auth_params\n        The parameters generated from the `auth_uri` method.\n\n    Returns\n    -------\n    str\n        Your authentication code.\n\n    Raises\n    ------\n    AuthorisationError\n        * You provided an invalid redirect URI\n        * The received state does not match the generated one\n    \"\"\"\n    if not (match := REDIRECT_URI_PATTERN.match(auth_params[\"redirect_uri\"])):\n        raise AuthorisationError(\"invalid redirect URI\")\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def log_request(\n            self,\n            code: Union[int, str] = \"-\",\n            _: Union[int, str] = \"-\",\n        ) -&gt; None:\n            _log.debug(f\"Received request ({code})\")\n\n        def do_GET(self) -&gt; None:  # noqa: N802\n            self.send_response(200)\n            self.send_header(\"Content-Type\", \"text/html\")\n            self.end_headers()\n\n            self.server: Server\n            self.server.query_params = dict(parse_qsl(self.path.split(\"?\")[1]))\n            self.wfile.write((Path(__file__).parent / \"landing.html\").read_bytes())\n\n    class Server(HTTPServer):\n        def __init__(self, address: str, port: int) -&gt; None:\n            super().__init__((address, port), RequestHandler)\n            self.query_params: Dict[str, str] = {}\n            _log.debug(\"Started webserver on %s:%d\", self.server_name, self.server_port)\n\n        def server_close(self) -&gt; None:\n            super().server_close()\n            _log.debug(\"Closed webserver\")\n\n    host, port = match.groups()\n    ws = Server(host, int(port or 80))\n\n    try:\n        ws.handle_request()\n    except KeyboardInterrupt as exc:\n        raise exc\n    finally:\n        ws.server_close()\n\n    if auth_params[\"state\"] != ws.query_params[\"state\"]:\n        raise AuthorisationError(\"invalid state\")\n\n    return ws.query_params[\"code\"]\n</code></pre>"},{"location":"reference/auth/scopes/","title":"scopes","text":""},{"location":"reference/auth/scopes/#analytix.auth.scopes.Scopes","title":"Scopes","text":"<p>               Bases: <code>Flag</code></p> <p>An enum for API scopes.</p> <p>Possible values are:</p> <ul> <li><code>READONLY</code> \u2014 Don't include revenue data from reports</li> <li><code>MONETARY_READONLY</code> \u2014 Only include revenue data from reports</li> <li><code>ALL_READONLY</code> \u2014 Include all data in reports</li> <li><code>OPENID</code> \u2014 Enable the OpenID scope</li> <li><code>PROFILE</code> \u2014 Include profile information in JWTs</li> <li><code>EMAIL</code> \u2014 Include email information in JWTs</li> <li><code>ALL_JWT</code> \u2014 Include all available information in JWTs</li> <li><code>ALL</code> \u2014 Include all data in reports</li> </ul> Changed in version 6.0 <p>The <code>ALL_READONLY</code> scope has been added and mimics the behaviour of the <code>ALL</code> scope from v5. The <code>ALL</code> scope now includes all JWT scopes.</p> Changed in version 5.1 <ul> <li>Added the <code>OPENID</code>, <code>PROFILE</code>, <code>EMAIL</code>, and <code>ALL_JWT</code> scopes</li> <li>This now works like a flag enum rather than a normal one; this   doesn't introduce any breaking changes (unless you're using   analytix in a particularly unconventional way), but does mean   you can now use a <code>|</code> to concatenate scopes</li> </ul> Source code in <code>analytix/auth/scopes.py</code> <pre><code>class Scopes(Flag):\n    \"\"\"An enum for API scopes.\n\n    Possible values are:\n\n    * `READONLY` \u2014 Don't include revenue data from reports\n    * `MONETARY_READONLY` \u2014 Only include revenue data from reports\n    * `ALL_READONLY` \u2014 Include all data in reports\n    * `OPENID` \u2014 Enable the OpenID scope\n    * `PROFILE` \u2014 Include profile information in JWTs\n    * `EMAIL` \u2014 Include email information in JWTs\n    * `ALL_JWT` \u2014 Include all available information in JWTs\n    * `ALL` \u2014 Include all data in reports\n\n    ???+ note \"Changed in version 6.0\"\n        The `ALL_READONLY` scope has been added and mimics the behaviour\n        of the `ALL` scope from v5. The `ALL` scope now includes all JWT\n        scopes.\n\n    ???+ note \"Changed in version 5.1\"\n        * Added the `OPENID`, `PROFILE`, `EMAIL`, and `ALL_JWT` scopes\n        * This now works like a flag enum rather than a normal one; this\n          doesn't introduce any breaking changes (unless you're using\n          analytix in a particularly unconventional way), but does mean\n          you can now use a `|` to concatenate scopes\n    \"\"\"\n\n    READONLY = 1 &lt;&lt; 0\n    MONETARY_READONLY = 1 &lt;&lt; 1\n    ALL_READONLY = READONLY | MONETARY_READONLY\n    OPENID = 1 &lt;&lt; 2\n    PROFILE = 1 &lt;&lt; 3\n    EMAIL = 1 &lt;&lt; 4\n    ALL_JWT = OPENID | PROFILE | EMAIL\n    ALL = ALL_READONLY | ALL_JWT\n\n    @property\n    def formatted(self) -&gt; str:\n        return \" \".join(\n            url for i, url in enumerate(SCOPE_URLS) if self.value &amp; (1 &lt;&lt; i)\n        )\n\n    def validate(self) -&gt; None:\n        if not (self.value &amp; (1 &lt;&lt; 0) or self.value &amp; (1 &lt;&lt; 1)):\n            raise AuthorisationError(\n                \"the READONLY or MONETARY_READONLY scope must be provided\",\n            )\n</code></pre>"},{"location":"reference/auth/secrets/","title":"secrets","text":""},{"location":"reference/auth/secrets/#analytix.auth.secrets.Secrets","title":"Secrets  <code>dataclass</code>","text":"<p>A set of API secrets.</p> <p>This should always be created using the <code>load_from</code> classmethod.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Literal['installed', 'web']</code> <p>The application type. This will always be either \"installed\" or \"web\".</p> required <code>client_id</code> <code>str</code> <p>The client ID.</p> required <code>project_id</code> <code>str</code> <p>The name of the project.</p> required <code>auth_uri</code> <code>str</code> <p>The authorisation server endpoint URI.</p> required <code>token_uri</code> <code>str</code> <p>The token server endpoint URI.</p> required <code>auth_provider_x509_cert_url</code> <code>str</code> <p>The URL of the public x509 certificate, used to verify the signature on JWTs, such as ID tokens, signed by the authentication provider.</p> required <code>client_secret</code> <code>str</code> <p>The client secret.</p> required <code>redirect_uris</code> <code>List[str]</code> <p>A list of valid redirection endpoint URIs. This list should match the list entered for the client ID on the API Access pane of the Google APIs Console.</p> required Source code in <code>analytix/auth/secrets.py</code> <pre><code>@dataclass(frozen=True)\nclass Secrets:\n    \"\"\"A set of API secrets.\n\n    This should always be created using the `load_from` classmethod.\n\n    Parameters\n    ----------\n    type\n        The application type. This will always be either \"installed\" or\n        \"web\".\n    client_id\n        The client ID.\n    project_id\n        The name of the project.\n    auth_uri\n        The authorisation server endpoint URI.\n    token_uri\n        The token server endpoint URI.\n    auth_provider_x509_cert_url\n        The URL of the public x509 certificate, used to verify the\n        signature on JWTs, such as ID tokens, signed by the\n        authentication provider.\n    client_secret\n        The client secret.\n    redirect_uris\n        A list of valid redirection endpoint URIs. This list should\n        match the list entered for the client ID on the API Access pane\n        of the Google APIs Console.\n    \"\"\"\n\n    __slots__ = (\n        \"type\",\n        \"client_id\",\n        \"project_id\",\n        \"auth_uri\",\n        \"token_uri\",\n        \"auth_provider_x509_cert_url\",\n        \"client_secret\",\n        \"redirect_uris\",\n    )\n\n    type: Literal[\"installed\", \"web\"]\n    client_id: str\n    project_id: str\n    auth_uri: str\n    token_uri: str\n    auth_provider_x509_cert_url: str\n    client_secret: str\n    redirect_uris: List[str]\n\n    @classmethod\n    def load_from(cls, path: PathLike) -&gt; \"Secrets\":\n        \"\"\"Load secrets from a JSON file.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `from_file`.\n\n        Parameters\n        ----------\n        path\n            The path to your secrets file.\n\n        Returns\n        -------\n        Secrets\n            Your secrets.\n\n        Raises\n        ------\n        FileNotFoundError\n            No secrets file exists at the given path.\n        JSONDecodeError\n            The given file is not a valid JSON file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Secrets.load_from(\"secrets.json\")\n        Secrets(type=\"installed\", ...)\n        \"\"\"\n        secrets_file = Path(path)\n\n        if _log.isEnabledFor(logging.DEBUG):\n            _log.debug(\"Loading secrets from %s\", secrets_file.resolve())\n\n        data = json.loads(secrets_file.read_text())\n        key = next(iter(data.keys()))\n        return cls(\n            type=key,\n            client_id=data[key][\"client_id\"],\n            project_id=data[key][\"project_id\"],\n            auth_uri=data[key][\"auth_uri\"],\n            token_uri=data[key][\"token_uri\"],\n            auth_provider_x509_cert_url=data[key][\"auth_provider_x509_cert_url\"],\n            client_secret=data[key][\"client_secret\"],\n            redirect_uris=data[key][\"redirect_uris\"],\n        )\n</code></pre>"},{"location":"reference/auth/secrets/#analytix.auth.secrets.Secrets.load_from","title":"load_from  <code>classmethod</code>","text":"<pre><code>load_from(path: PathLike) -&gt; Secrets\n</code></pre> <p>Load secrets from a JSON file.</p> Changed in version 5.0 <p>This used to be <code>from_file</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to your secrets file.</p> required <p>Returns:</p> Type Description <code>Secrets</code> <p>Your secrets.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>No secrets file exists at the given path.</p> <code>JSONDecodeError</code> <p>The given file is not a valid JSON file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Secrets.load_from(\"secrets.json\")\nSecrets(type=\"installed\", ...)\n</code></pre> Source code in <code>analytix/auth/secrets.py</code> <pre><code>@classmethod\ndef load_from(cls, path: PathLike) -&gt; \"Secrets\":\n    \"\"\"Load secrets from a JSON file.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `from_file`.\n\n    Parameters\n    ----------\n    path\n        The path to your secrets file.\n\n    Returns\n    -------\n    Secrets\n        Your secrets.\n\n    Raises\n    ------\n    FileNotFoundError\n        No secrets file exists at the given path.\n    JSONDecodeError\n        The given file is not a valid JSON file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Secrets.load_from(\"secrets.json\")\n    Secrets(type=\"installed\", ...)\n    \"\"\"\n    secrets_file = Path(path)\n\n    if _log.isEnabledFor(logging.DEBUG):\n        _log.debug(\"Loading secrets from %s\", secrets_file.resolve())\n\n    data = json.loads(secrets_file.read_text())\n    key = next(iter(data.keys()))\n    return cls(\n        type=key,\n        client_id=data[key][\"client_id\"],\n        project_id=data[key][\"project_id\"],\n        auth_uri=data[key][\"auth_uri\"],\n        token_uri=data[key][\"token_uri\"],\n        auth_provider_x509_cert_url=data[key][\"auth_provider_x509_cert_url\"],\n        client_secret=data[key][\"client_secret\"],\n        redirect_uris=data[key][\"redirect_uris\"],\n    )\n</code></pre>"},{"location":"reference/auth/tokens/","title":"tokens","text":""},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens","title":"Tokens  <code>dataclass</code>","text":"<p>               Bases: <code>RequestMixin</code></p> <p>OAuth tokens.</p> <p>This should always be created using one of the available classmethods.</p> Changed in version 6.0 <p>The <code>expires_in</code> attribute will now show an accurate figure instead of <code>3599</code> perpetually. Due to the way it's been implemented, it can't be updated manually.</p> <p>Parameters:</p> Name Type Description Default <code>access_token</code> <code>str</code> <p>A token that can be sent to a Google API.</p> required <code>expires_in</code> <code>_ExpiresIn</code> <p>The remaining lifetime of the access token in seconds.</p> <code>_ExpiresIn()</code> <code>scope</code> <code>str</code> <p>The scopes of access granted by the access_token expressed as a list of space-delimited, case-sensitive strings.</p> required <code>token_type</code> <code>Literal['Bearer']</code> <p>Identifies the type of token returned. This will always be \"Bearer\".</p> required <code>refresh_token</code> <code>str</code> <p>A token that can be used to refresh your access token.</p> required <code>id_token</code> <code>Optional[str]</code> <p>A JWT that contains identity information about the user that is digitally signed by Google. This will be <code>None</code> if you did not specifically request JWT tokens when authorising.</p> <code>None</code> Source code in <code>analytix/auth/tokens.py</code> <pre><code>@dataclass()\nclass Tokens(RequestMixin):\n    \"\"\"OAuth tokens.\n\n    This should always be created using one of the available\n    classmethods.\n\n    ???+ note \"Changed in version 6.0\"\n        The `expires_in` attribute will now show an accurate figure\n        instead of `3599` perpetually. Due to the way it's been\n        implemented, it can't be updated manually.\n\n    Parameters\n    ----------\n    access_token\n        A token that can be sent to a Google API.\n    expires_in\n        The remaining lifetime of the access token in seconds.\n    scope\n        The scopes of access granted by the access_token expressed as a\n        list of space-delimited, case-sensitive strings.\n    token_type\n        Identifies the type of token returned. This will always be\n        \"Bearer\".\n    refresh_token\n        A token that can be used to refresh your access token.\n    id_token\n        A JWT that contains identity information about the user that is\n        digitally signed by Google. This will be `None` if you did not\n        specifically request JWT tokens when authorising.\n    \"\"\"\n\n    access_token: str\n    scope: str\n    token_type: Literal[\"Bearer\"]\n    refresh_token: str\n    expires_in: _ExpiresIn = _ExpiresIn()\n    id_token: Optional[str] = None\n    _path: Optional[Path] = field(default=None, init=False, repr=False)\n\n    @classmethod\n    def load_from(cls, path: PathLike) -&gt; \"Tokens\":\n        \"\"\"Load tokens from a JSON file.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `from_file`.\n\n        Parameters\n        ----------\n        path\n            The path to your tokens file.\n\n        Returns\n        -------\n        Tokens\n            Your tokens.\n\n        Raises\n        ------\n        FileNotFoundError\n            No tokens file exists at the given path.\n        JSONDecodeError\n            The given file is not a valid JSON file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.load_from(\"tokens.json\")\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        tokens_file = Path(path)\n\n        if _log.isEnabledFor(logging.DEBUG):\n            _log.debug(\"Loading tokens from %s\", tokens_file.resolve())\n\n        self = cls.from_json(tokens_file.read_text())\n        self._path = tokens_file\n        return self\n\n    @classmethod\n    def from_json(cls, data: Union[str, bytes]) -&gt; \"Tokens\":\n        \"\"\"Load tokens from raw JSON data.\n\n        Parameters\n        ----------\n        data\n            Your tokens in JSON form.\n\n        Returns\n        -------\n        Tokens\n            Your tokens.\n\n        Raises\n        ------\n        JSONDecodeError\n            The given file is not a valid JSON file.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.from_json('{\"access_token\": \"1234567890\", ...}')\n        Tokens(access_token=\"1234567890\", ...)\n        \"\"\"\n        return cls(**json.loads(data))\n\n    def save_to(self, path: PathLike) -&gt; None:\n        \"\"\"Save your tokens to disk.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `write`.\n\n        Parameters\n        ----------\n        path\n            The path to save your tokens to.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.save_to(\"tokens.json\")\n        \"\"\"\n        tokens_file = Path(path)\n\n        if _log.isEnabledFor(logging.DEBUG):\n            _log.debug(\"Saving tokens to %s\", tokens_file.resolve())\n\n        attrs = {\n            \"access_token\": self.access_token,\n            \"expires_in\": self.expires_in,\n            \"scope\": self.scope,\n            \"token_type\": self.token_type,\n            \"refresh_token\": self.refresh_token,\n            **({\"id_token\": self.id_token} if self.id_token else {}),\n        }\n        tokens_file.write_text(json.dumps(attrs))\n        self._path = tokens_file\n\n    def refresh(self, data: Union[str, bytes]) -&gt; \"Tokens\":\n        \"\"\"Updates your tokens to match those you refreshed.\n\n        ???+ note \"Changed in version 5.0\"\n            This used to be `update`.\n\n        Parameters\n        ----------\n        data\n            Your refreshed tokens in JSON form. These will not entirely\n            replace your previous tokens, but instead update any\n            out-of-date keys.\n\n        Returns\n        -------\n        Tokens\n            Your refreshed tokens.\n\n        See Also\n        --------\n        * This method does not actually refresh your access token;\n          for that, you'll need to use `Client.refresh_access_token`.\n        * To save tokens, you'll need the `save_to` method.\n\n        Examples\n        --------\n        &gt;&gt;&gt; Tokens.refresh('{\"access_token\": \"abcdefghij\", ...}')\n        Tokens(access_token=\"abcdefghij\", ...)\n        \"\"\"\n        attrs = json.loads(data)\n        for key, value in attrs.items():\n            setattr(self, key, value)\n        return self\n\n    @property\n    def expired(self) -&gt; bool:\n        \"\"\"Whether your access token has expired.\n\n        !!! note \"New in version 6.0\"\n\n        Returns\n        -------\n        bool\n            Whether the token has expired or not. If it has, it needs\n            refreshing.\n\n        Examples\n        --------\n        &gt;&gt;&gt; tokens.expired\n        True\n        \"\"\"\n        return self.expires_in == 0\n\n    def are_scoped_for(self, scopes: Scopes) -&gt; bool:\n        \"\"\"Check whether your token's scopes are sufficient.\n\n        This cross-checks the scopes you provided the client with the\n        scopes your tokens are authorised with and determines whether\n        your tokens provide enough access.\n\n        This is not an equality check; if your tokens are authorised\n        with all scopes, but you only passed the READONLY scope to the\n        client, this will return `True`.\n\n        !!! note \"New in version 6.0\"\n\n        Parameters\n        ----------\n        scopes\n            Your client's scopes.\n\n        Returns\n        -------\n        bool\n            Whether the scopes are sufficient or not. If they're not,\n            you'll need to reauthorise.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # This would only be used internally.\n        &gt;&gt;&gt; tokens.are_scopes_for(client._scopes)\n        True\n        \"\"\"\n        sufficient = set(scopes.formatted.split(\" \")) &lt;= set(self.scope.split(\" \"))\n        _log.debug(f\"Stored scopes are {'' if sufficient else 'in'}sufficient\")\n        return sufficient\n\n    @property\n    def decoded_id_token(self) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"The decoded ID token.\n\n        ID tokens are returned from the YouTube Analytics API as a JWT,\n        which is a secure way to transfer encrypted JSON objects. This\n        property decrypts and decodes the JWT and returns the stored\n        information.\n\n        !!! note \"New in version 6.0\"\n\n        Returns\n        -------\n        Optional[Dict[str, Any]]\n            The decoded ID token, or `None` if there is no ID token.\n\n        Raises\n        ------\n        MissingOptionalComponents\n            python-jwt is not installed.\n        IdTokenError\n            Your ID token could not be decoded. This may be raised\n            alongside other errors.\n\n        Notes\n        -----\n        This requires `jwt` to be installed to use, which is an optional\n        dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; client = BaseClient(\"secrets.json\")\n        &gt;&gt;&gt; tokens = client.authorise()  # Overloaded using your impl.\n        &gt;&gt;&gt; tokens.decoded_id_token\n        \"\"\"\n        if not self.id_token:\n            return None\n\n        if not utils.can_use(\"jwt\"):\n            raise MissingOptionalComponents(\"jwt\")\n\n        from jwt import JWT\n        from jwt import jwk_from_dict\n        from jwt.exceptions import JWSDecodeError\n\n        _log.debug(\"Fetching JWKs\")\n        with self._request(JWKS_URI) as resp:\n            if resp.status &gt; 399:\n                raise IdTokenError(\"could not fetch Google JWKs\")\n\n            keys = json.loads(resp.data)[\"keys\"]\n\n        jwt = JWT()  # type: ignore[no-untyped-call]\n\n        for key in keys:\n            jwk = jwk_from_dict(key)\n            _log.debug(\"Attempting decode using JWK with KID %r\", jwk.get_kid())\n            try:\n                return jwt.decode(self.id_token, jwk)\n            except Exception as exc:\n                if not isinstance(exc.__cause__, JWSDecodeError):\n                    # If the error IS a JWSDecodeError, we want to try\n                    # other keys and error later if they also fail.\n                    raise IdTokenError(\"invalid ID token (see above error)\") from exc\n\n        raise IdTokenError(\"ID token signature could not be validated\")\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.decoded_id_token","title":"decoded_id_token  <code>property</code>","text":"<pre><code>decoded_id_token: Optional[Dict[str, Any]]\n</code></pre> <p>The decoded ID token.</p> <p>ID tokens are returned from the YouTube Analytics API as a JWT, which is a secure way to transfer encrypted JSON objects. This property decrypts and decodes the JWT and returns the stored information.</p> <p>New in version 6.0</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>The decoded ID token, or <code>None</code> if there is no ID token.</p> <p>Raises:</p> Type Description <code>MissingOptionalComponents</code> <p>python-jwt is not installed.</p> <code>IdTokenError</code> <p>Your ID token could not be decoded. This may be raised alongside other errors.</p> Notes <p>This requires <code>jwt</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; client = BaseClient(\"secrets.json\")\n&gt;&gt;&gt; tokens = client.authorise()  # Overloaded using your impl.\n&gt;&gt;&gt; tokens.decoded_id_token\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.expired","title":"expired  <code>property</code>","text":"<pre><code>expired: bool\n</code></pre> <p>Whether your access token has expired.</p> <p>New in version 6.0</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the token has expired or not. If it has, it needs refreshing.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tokens.expired\nTrue\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.are_scoped_for","title":"are_scoped_for","text":"<pre><code>are_scoped_for(scopes: Scopes) -&gt; bool\n</code></pre> <p>Check whether your token's scopes are sufficient.</p> <p>This cross-checks the scopes you provided the client with the scopes your tokens are authorised with and determines whether your tokens provide enough access.</p> <p>This is not an equality check; if your tokens are authorised with all scopes, but you only passed the READONLY scope to the client, this will return <code>True</code>.</p> <p>New in version 6.0</p> <p>Parameters:</p> Name Type Description Default <code>scopes</code> <code>Scopes</code> <p>Your client's scopes.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the scopes are sufficient or not. If they're not, you'll need to reauthorise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # This would only be used internally.\n&gt;&gt;&gt; tokens.are_scopes_for(client._scopes)\nTrue\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>def are_scoped_for(self, scopes: Scopes) -&gt; bool:\n    \"\"\"Check whether your token's scopes are sufficient.\n\n    This cross-checks the scopes you provided the client with the\n    scopes your tokens are authorised with and determines whether\n    your tokens provide enough access.\n\n    This is not an equality check; if your tokens are authorised\n    with all scopes, but you only passed the READONLY scope to the\n    client, this will return `True`.\n\n    !!! note \"New in version 6.0\"\n\n    Parameters\n    ----------\n    scopes\n        Your client's scopes.\n\n    Returns\n    -------\n    bool\n        Whether the scopes are sufficient or not. If they're not,\n        you'll need to reauthorise.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # This would only be used internally.\n    &gt;&gt;&gt; tokens.are_scopes_for(client._scopes)\n    True\n    \"\"\"\n    sufficient = set(scopes.formatted.split(\" \")) &lt;= set(self.scope.split(\" \"))\n    _log.debug(f\"Stored scopes are {'' if sufficient else 'in'}sufficient\")\n    return sufficient\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data: Union[str, bytes]) -&gt; Tokens\n</code></pre> <p>Load tokens from raw JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, bytes]</code> <p>Your tokens in JSON form.</p> required <p>Returns:</p> Type Description <code>Tokens</code> <p>Your tokens.</p> <p>Raises:</p> Type Description <code>JSONDecodeError</code> <p>The given file is not a valid JSON file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.from_json('{\"access_token\": \"1234567890\", ...}')\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Union[str, bytes]) -&gt; \"Tokens\":\n    \"\"\"Load tokens from raw JSON data.\n\n    Parameters\n    ----------\n    data\n        Your tokens in JSON form.\n\n    Returns\n    -------\n    Tokens\n        Your tokens.\n\n    Raises\n    ------\n    JSONDecodeError\n        The given file is not a valid JSON file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.from_json('{\"access_token\": \"1234567890\", ...}')\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    return cls(**json.loads(data))\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.load_from","title":"load_from  <code>classmethod</code>","text":"<pre><code>load_from(path: PathLike) -&gt; Tokens\n</code></pre> <p>Load tokens from a JSON file.</p> Changed in version 5.0 <p>This used to be <code>from_file</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to your tokens file.</p> required <p>Returns:</p> Type Description <code>Tokens</code> <p>Your tokens.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>No tokens file exists at the given path.</p> <code>JSONDecodeError</code> <p>The given file is not a valid JSON file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.load_from(\"tokens.json\")\nTokens(access_token=\"1234567890\", ...)\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>@classmethod\ndef load_from(cls, path: PathLike) -&gt; \"Tokens\":\n    \"\"\"Load tokens from a JSON file.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `from_file`.\n\n    Parameters\n    ----------\n    path\n        The path to your tokens file.\n\n    Returns\n    -------\n    Tokens\n        Your tokens.\n\n    Raises\n    ------\n    FileNotFoundError\n        No tokens file exists at the given path.\n    JSONDecodeError\n        The given file is not a valid JSON file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.load_from(\"tokens.json\")\n    Tokens(access_token=\"1234567890\", ...)\n    \"\"\"\n    tokens_file = Path(path)\n\n    if _log.isEnabledFor(logging.DEBUG):\n        _log.debug(\"Loading tokens from %s\", tokens_file.resolve())\n\n    self = cls.from_json(tokens_file.read_text())\n    self._path = tokens_file\n    return self\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.refresh","title":"refresh","text":"<pre><code>refresh(data: Union[str, bytes]) -&gt; Tokens\n</code></pre> <p>Updates your tokens to match those you refreshed.</p> Changed in version 5.0 <p>This used to be <code>update</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, bytes]</code> <p>Your refreshed tokens in JSON form. These will not entirely replace your previous tokens, but instead update any out-of-date keys.</p> required <p>Returns:</p> Type Description <code>Tokens</code> <p>Your refreshed tokens.</p> See Also <ul> <li>This method does not actually refresh your access token;   for that, you'll need to use <code>Client.refresh_access_token</code>.</li> <li>To save tokens, you'll need the <code>save_to</code> method.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.refresh('{\"access_token\": \"abcdefghij\", ...}')\nTokens(access_token=\"abcdefghij\", ...)\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>def refresh(self, data: Union[str, bytes]) -&gt; \"Tokens\":\n    \"\"\"Updates your tokens to match those you refreshed.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `update`.\n\n    Parameters\n    ----------\n    data\n        Your refreshed tokens in JSON form. These will not entirely\n        replace your previous tokens, but instead update any\n        out-of-date keys.\n\n    Returns\n    -------\n    Tokens\n        Your refreshed tokens.\n\n    See Also\n    --------\n    * This method does not actually refresh your access token;\n      for that, you'll need to use `Client.refresh_access_token`.\n    * To save tokens, you'll need the `save_to` method.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.refresh('{\"access_token\": \"abcdefghij\", ...}')\n    Tokens(access_token=\"abcdefghij\", ...)\n    \"\"\"\n    attrs = json.loads(data)\n    for key, value in attrs.items():\n        setattr(self, key, value)\n    return self\n</code></pre>"},{"location":"reference/auth/tokens/#analytix.auth.tokens.Tokens.save_to","title":"save_to","text":"<pre><code>save_to(path: PathLike) -&gt; None\n</code></pre> <p>Save your tokens to disk.</p> Changed in version 5.0 <p>This used to be <code>write</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save your tokens to.</p> required <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Tokens.save_to(\"tokens.json\")\n</code></pre> Source code in <code>analytix/auth/tokens.py</code> <pre><code>def save_to(self, path: PathLike) -&gt; None:\n    \"\"\"Save your tokens to disk.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `write`.\n\n    Parameters\n    ----------\n    path\n        The path to save your tokens to.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Tokens.save_to(\"tokens.json\")\n    \"\"\"\n    tokens_file = Path(path)\n\n    if _log.isEnabledFor(logging.DEBUG):\n        _log.debug(\"Saving tokens to %s\", tokens_file.resolve())\n\n    attrs = {\n        \"access_token\": self.access_token,\n        \"expires_in\": self.expires_in,\n        \"scope\": self.scope,\n        \"token_type\": self.token_type,\n        \"refresh_token\": self.refresh_token,\n        **({\"id_token\": self.id_token} if self.id_token else {}),\n    }\n    tokens_file.write_text(json.dumps(attrs))\n    self._path = tokens_file\n</code></pre>"},{"location":"reference/auth/utils/","title":"utils","text":""},{"location":"reference/auth/utils/#analytix.auth.utils.auth_uri","title":"auth_uri","text":"<pre><code>auth_uri(secrets: Secrets, scopes: Scopes, port: int) -&gt; UriParams\n</code></pre> <p>Returns the authentication URI and parameters.</p> Changed in version 5.0 <ul> <li>This now takes scopes as a parameter</li> <li>This now returns headers (albeit always empty) to be more   consistent with other functions</li> <li>The redirect URI to use is now chosen more intelligently --   it will be the first in the list not intended to be used in   OOB authorisation.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>secrets</code> <code>Secrets</code> <p>Your secrets.</p> required <code>scopes</code> <code>Scopes</code> <p>The scopes to allow in requests.</p> required <code>port</code> <code>int</code> <p>The websocket port you wish to use.</p> required <p>Returns:</p> Name Type Description <code>auth_uri</code> <code>str</code> <p>The computed authentication URI.</p> <code>params</code> <code>Dict[str, str]</code> <p>The query parameters as a dictionary.</p> <code>headers</code> <code>Dict[str, str]</code> <p>Necessary request headers. This is always empty.</p> Source code in <code>analytix/auth/utils.py</code> <pre><code>def auth_uri(secrets: Secrets, scopes: Scopes, port: int) -&gt; UriParams:\n    \"\"\"Returns the authentication URI and parameters.\n\n    ???+ note \"Changed in version 5.0\"\n        * This now takes scopes as a parameter\n        * This now returns headers (albeit always empty) to be more\n          consistent with other functions\n        * The redirect URI to use is now chosen more intelligently --\n          it will be the first in the list not intended to be used in\n          OOB authorisation.\n\n    Parameters\n    ----------\n    secrets\n        Your secrets.\n    scopes\n        The scopes to allow in requests.\n    port\n        The websocket port you wish to use.\n\n    Returns\n    -------\n    auth_uri : str\n        The computed authentication URI.\n    params : Dict[str, str]\n        The query parameters as a dictionary.\n    headers : Dict[str, str]\n        Necessary request headers. This is always empty.\n    \"\"\"\n    redirect_uri = next(\n        uri\n        for uri in secrets.redirect_uris\n        if uri != \"oob\" and \"urn:ietf:wg:oauth:2.0:oob\" not in uri\n    )\n\n    params = {\n        \"client_id\": secrets.client_id,\n        \"nonce\": state_token(),\n        \"response_type\": \"code\",\n        \"redirect_uri\": redirect_uri + (f\":{port}\" if port != 80 else \"\"),\n        \"scope\": scopes.formatted,\n        \"state\": state_token(),\n        \"access_type\": \"offline\",\n    }\n\n    return f\"{secrets.auth_uri}?{urlencode(params)}\", params, {}\n</code></pre>"},{"location":"reference/auth/utils/#analytix.auth.utils.refresh_uri","title":"refresh_uri","text":"<pre><code>refresh_uri(secrets: Secrets, token: str) -&gt; UriParams\n</code></pre> <p>Returns the refresh URI, data, and headers.</p> <p>Parameters:</p> Name Type Description Default <code>secrets</code> <code>Secrets</code> <p>Your secrets.</p> required <code>token</code> <code>str</code> <p>Your refresh token.</p> required <p>Returns:</p> Name Type Description <code>token_uri</code> <code>str</code> <p>Your token URI.</p> <code>data</code> <code>Dict[str, str]</code> <p>Necessary request data.</p> <code>headers</code> <code>Dict[str, str]</code> <p>Necessary request headers.</p> Source code in <code>analytix/auth/utils.py</code> <pre><code>def refresh_uri(secrets: Secrets, token: str) -&gt; UriParams:\n    \"\"\"Returns the refresh URI, data, and headers.\n\n    Parameters\n    ----------\n    secrets\n        Your secrets.\n    token\n        Your refresh token.\n\n    Returns\n    -------\n    token_uri : str\n        Your token URI.\n    data : Dict[str, str]\n        Necessary request data.\n    headers : Dict[str, str]\n        Necessary request headers.\n    \"\"\"\n    data = {\n        \"client_id\": secrets.client_id,\n        \"client_secret\": secrets.client_secret,\n        \"refresh_token\": token,\n        \"grant_type\": \"refresh_token\",\n    }\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    return secrets.token_uri, data, headers\n</code></pre>"},{"location":"reference/auth/utils/#analytix.auth.utils.state_token","title":"state_token","text":"<pre><code>state_token() -&gt; str\n</code></pre> <p>Generates a state token.</p> <p>Returns:</p> Type Description <code>str</code> <p>A new state token.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state_token()\n'385cdc1c6e9410120755ecf1c0558299be58bd3bcc6f515addaa817df5e10fd2'\n</code></pre> Source code in <code>analytix/auth/utils.py</code> <pre><code>def state_token() -&gt; str:\n    \"\"\"Generates a state token.\n\n    Returns\n    -------\n    str\n        A new state token.\n\n    Examples\n    --------\n    &gt;&gt;&gt; state_token()\n    '385cdc1c6e9410120755ecf1c0558299be58bd3bcc6f515addaa817df5e10fd2'\n    \"\"\"\n    return hashlib.sha256(os.urandom(1024)).hexdigest()\n</code></pre>"},{"location":"reference/auth/utils/#analytix.auth.utils.token_uri","title":"token_uri","text":"<pre><code>token_uri(secrets: Secrets, code: str, redirect_uri: str) -&gt; UriParams\n</code></pre> <p>Returns the token URI, data, and headers.</p> <p>Parameters:</p> Name Type Description Default <code>secrets</code> <code>Secrets</code> <p>Your secrets.</p> required <code>code</code> <code>str</code> <p>Your authentication code.</p> required <code>redirect_uri</code> <code>str</code> <p>Your redirect URI. This should be identical to the one you generated in <code>auth_uri</code>.</p> required <p>Returns:</p> Name Type Description <code>token_uri</code> <code>str</code> <p>Your token URI.</p> <code>data</code> <code>Dict[str, str]</code> <p>Necessary request data.</p> <code>headers</code> <code>Dict[str, str]</code> <p>Necessary request headers.</p> Source code in <code>analytix/auth/utils.py</code> <pre><code>def token_uri(secrets: Secrets, code: str, redirect_uri: str) -&gt; UriParams:\n    \"\"\"Returns the token URI, data, and headers.\n\n    Parameters\n    ----------\n    secrets\n        Your secrets.\n    code\n        Your authentication code.\n    redirect_uri\n        Your redirect URI. This should be identical to the one you\n        generated in `auth_uri`.\n\n    Returns\n    -------\n    token_uri : str\n        Your token URI.\n    data : Dict[str, str]\n        Necessary request data.\n    headers : Dict[str, str]\n        Necessary request headers.\n    \"\"\"\n    data = {\n        \"code\": code,\n        \"client_id\": secrets.client_id,\n        \"client_secret\": secrets.client_secret,\n        \"redirect_uri\": redirect_uri,\n        \"grant_type\": \"authorization_code\",\n    }\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    return secrets.token_uri, data, headers\n</code></pre>"},{"location":"reference/groups/groups/","title":"groups","text":"<p>Group interfaces for analytix.</p> <p>You should never need to create any of these yourself.</p>"},{"location":"reference/groups/groups/#analytix.groups.groups.Group","title":"Group  <code>dataclass</code>","text":"<p>               Bases: <code>_Resource</code></p> <p>A group.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>The kind of resource this is. This will always be \"youtube#group\".</p> required <code>etag</code> <code>Optional[str]</code> <p>The Etag of this resource.</p> required <code>id</code> <code>str</code> <p>The ID that YouTube uses to uniquely identify the group.</p> required <code>published_at</code> <code>datetime</code> <p>The date and time that the group was created.</p> required <code>title</code> <code>str</code> <p>The group name.</p> required <code>item_count</code> <code>int</code> <p>The number of items in the group.</p> required <code>item_type</code> <code>str</code> <p>The type of resources that the group contains.</p> required <code>shard</code> <code>Shard</code> <p>The shard instance used to fetch this group.</p> required Source code in <code>analytix/groups/groups.py</code> <pre><code>@dataclass(frozen=True)\nclass Group(_Resource):\n    \"\"\"A group.\n\n    Parameters\n    ----------\n    kind\n        The kind of resource this is. This will always be\n        \"youtube#group\".\n    etag\n        The Etag of this resource.\n    id\n        The ID that YouTube uses to uniquely identify the group.\n    published_at\n        The date and time that the group was created.\n    title\n        The group name.\n    item_count\n        The number of items in the group.\n    item_type\n        The type of resources that the group contains.\n    shard\n        The shard instance used to fetch this group.\n    \"\"\"\n\n    __slots__ = (\"id\", \"published_at\", \"title\", \"item_count\", \"item_type\", \"shard\")\n\n    id: str\n    published_at: dt.datetime\n    title: str\n    item_count: int\n    item_type: str\n    shard: \"Shard\"\n\n    @classmethod\n    def from_json(cls, shard: \"Shard\", data: Dict[str, Any]) -&gt; \"Group\":\n        \"\"\"Create a new `Group` instance from JSON data.\n\n        ???+ note \"Changed in version 5.0\"\n            This now takes the shard instance used to fetch the data.\n\n        Parameters\n        ----------\n        shard\n            The shard instance used to fetch the data.\n        data\n            The raw JSON data from the API.\n\n        Returns\n        -------\n        Group\n            The newly created instance.\n        \"\"\"\n        return cls(\n            data[\"kind\"],\n            data[\"etag\"],\n            data[\"id\"],\n            dt.datetime.fromisoformat(\n                data[\"snippet\"][\"publishedAt\"].replace(\"Z\", \"+00:00\"),\n            ),\n            data[\"snippet\"][\"title\"],\n            int(data[\"contentDetails\"][\"itemCount\"]),\n            data[\"contentDetails\"][\"itemType\"],\n            shard,\n        )\n\n    @property\n    def data(self) -&gt; Dict[str, Any]:\n        \"\"\"The raw data for this group in JSON format.\n\n        Returns\n        -------\n        Dict[str, Any]\n            The response data.\n        \"\"\"\n        return {\n            \"kind\": self.kind,\n            \"etag\": self.etag,\n            \"id\": self.id,\n            \"snippet\": {\n                \"publishedAt\": (\n                    self.published_at.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n                ),\n                \"title\": self.title,\n            },\n            \"contentDetails\": {\n                \"itemCount\": str(self.item_count),\n                \"itemType\": self.item_type,\n            },\n        }\n\n    def fetch_items(self) -&gt; \"GroupItemList\":\n        \"\"\"Fetch a list of all items within this group.\n\n        !!! note \"New in version 5.0\"\n\n        Returns\n        -------\n        GroupItemList\n            An object containing the list of group items and the next\n            page token.\n\n        Raises\n        ------\n        BadRequest\n            Your request was invalid.\n        Unauthorised\n            Your access token is invalid.\n        Forbidden\n            You tried to access data you're not allowed to access. If\n            your channel is not partnered, this is raised when you try\n            to access monetary data.\n        \"\"\"\n        return self.shard.fetch_group_items(self.id)\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.Group.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The raw data for this group in JSON format.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The response data.</p>"},{"location":"reference/groups/groups/#analytix.groups.groups.Group.fetch_items","title":"fetch_items","text":"<pre><code>fetch_items() -&gt; GroupItemList\n</code></pre> <p>Fetch a list of all items within this group.</p> <p>New in version 5.0</p> <p>Returns:</p> Type Description <code>GroupItemList</code> <p>An object containing the list of group items and the next page token.</p> <p>Raises:</p> Type Description <code>BadRequest</code> <p>Your request was invalid.</p> <code>Unauthorised</code> <p>Your access token is invalid.</p> <code>Forbidden</code> <p>You tried to access data you're not allowed to access. If your channel is not partnered, this is raised when you try to access monetary data.</p> Source code in <code>analytix/groups/groups.py</code> <pre><code>def fetch_items(self) -&gt; \"GroupItemList\":\n    \"\"\"Fetch a list of all items within this group.\n\n    !!! note \"New in version 5.0\"\n\n    Returns\n    -------\n    GroupItemList\n        An object containing the list of group items and the next\n        page token.\n\n    Raises\n    ------\n    BadRequest\n        Your request was invalid.\n    Unauthorised\n        Your access token is invalid.\n    Forbidden\n        You tried to access data you're not allowed to access. If\n        your channel is not partnered, this is raised when you try\n        to access monetary data.\n    \"\"\"\n    return self.shard.fetch_group_items(self.id)\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.Group.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(shard: Shard, data: Dict[str, Any]) -&gt; Group\n</code></pre> <p>Create a new <code>Group</code> instance from JSON data.</p> Changed in version 5.0 <p>This now takes the shard instance used to fetch the data.</p> <p>Parameters:</p> Name Type Description Default <code>shard</code> <code>Shard</code> <p>The shard instance used to fetch the data.</p> required <code>data</code> <code>Dict[str, Any]</code> <p>The raw JSON data from the API.</p> required <p>Returns:</p> Type Description <code>Group</code> <p>The newly created instance.</p> Source code in <code>analytix/groups/groups.py</code> <pre><code>@classmethod\ndef from_json(cls, shard: \"Shard\", data: Dict[str, Any]) -&gt; \"Group\":\n    \"\"\"Create a new `Group` instance from JSON data.\n\n    ???+ note \"Changed in version 5.0\"\n        This now takes the shard instance used to fetch the data.\n\n    Parameters\n    ----------\n    shard\n        The shard instance used to fetch the data.\n    data\n        The raw JSON data from the API.\n\n    Returns\n    -------\n    Group\n        The newly created instance.\n    \"\"\"\n    return cls(\n        data[\"kind\"],\n        data[\"etag\"],\n        data[\"id\"],\n        dt.datetime.fromisoformat(\n            data[\"snippet\"][\"publishedAt\"].replace(\"Z\", \"+00:00\"),\n        ),\n        data[\"snippet\"][\"title\"],\n        int(data[\"contentDetails\"][\"itemCount\"]),\n        data[\"contentDetails\"][\"itemType\"],\n        shard,\n    )\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItem","title":"GroupItem  <code>dataclass</code>","text":"<p>               Bases: <code>_Resource</code></p> <p>A group item.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>The kind of resource this is. This will always be \"youtube#groupItem\".</p> required <code>etag</code> <code>Optional[str]</code> <p>The Etag of this resource.</p> required <code>id</code> <code>str</code> <p>The ID that YouTube uses to uniquely identify the channel, video, playlist, or asset resource that is included in the group.</p> required <code>resource</code> <code>GroupItemResource</code> <p>The resource object contains information that identifies the item being added to the group.</p> required Notes <p>The <code>id</code> parameter does NOT refer to the actual ID of the channel, video, playlist, or asset, but instead an ID related to its inclusion within the group.</p> <p>To get the actual ID of the resource, use <code>resource.id</code>.</p> Source code in <code>analytix/groups/groups.py</code> <pre><code>@dataclass(frozen=True)\nclass GroupItem(_Resource):\n    \"\"\"A group item.\n\n    Parameters\n    ----------\n    kind\n        The kind of resource this is. This will always be\n        \"youtube#groupItem\".\n    etag\n        The Etag of this resource.\n    id\n        The ID that YouTube uses to uniquely identify the channel,\n        video, playlist, or asset resource that is included in the\n        group.\n    resource\n        The resource object contains information that identifies the\n        item being added to the group.\n\n    Notes\n    -----\n    The `id` parameter does NOT refer to the actual ID of the channel,\n    video, playlist, or asset, but instead an ID related to its\n    inclusion within the group.\n\n    To get the actual ID of the resource, use `resource.id`.\n    \"\"\"\n\n    __slots__ = (\"id\", \"group_id\", \"resource\")\n\n    id: str\n    group_id: str\n    resource: \"GroupItemResource\"\n\n    @classmethod\n    def from_json(cls, data: Dict[str, Any]) -&gt; \"GroupItem\":\n        \"\"\"Create a new `GroupItem` instance from JSON data.\n\n        Parameters\n        ----------\n        data\n            The raw JSON data from the API.\n\n        Returns\n        -------\n        GroupItem\n            The newly created instance.\n        \"\"\"\n        return cls(\n            data[\"kind\"],\n            data[\"etag\"],\n            data[\"id\"],\n            data[\"groupId\"],\n            GroupItemResource(\n                data[\"resource\"][\"kind\"],\n                data[\"resource\"][\"id\"],\n            ),\n        )\n\n    @property\n    def data(self) -&gt; Dict[str, Any]:\n        \"\"\"The raw data for this group in JSON format.\n\n        Returns\n        -------\n        Dict[str, Any]\n            The response data.\n        \"\"\"\n        return {\n            \"kind\": self.kind,\n            \"etag\": self.etag,\n            \"id\": self.id,\n            \"groupId\": self.group_id,\n            \"resource\": {\n                \"kind\": self.resource.kind,\n                \"id\": self.resource.id,\n            },\n        }\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItem.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The raw data for this group in JSON format.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The response data.</p>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItem.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data: Dict[str, Any]) -&gt; GroupItem\n</code></pre> <p>Create a new <code>GroupItem</code> instance from JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw JSON data from the API.</p> required <p>Returns:</p> Type Description <code>GroupItem</code> <p>The newly created instance.</p> Source code in <code>analytix/groups/groups.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Dict[str, Any]) -&gt; \"GroupItem\":\n    \"\"\"Create a new `GroupItem` instance from JSON data.\n\n    Parameters\n    ----------\n    data\n        The raw JSON data from the API.\n\n    Returns\n    -------\n    GroupItem\n        The newly created instance.\n    \"\"\"\n    return cls(\n        data[\"kind\"],\n        data[\"etag\"],\n        data[\"id\"],\n        data[\"groupId\"],\n        GroupItemResource(\n            data[\"resource\"][\"kind\"],\n            data[\"resource\"][\"id\"],\n        ),\n    )\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItemList","title":"GroupItemList  <code>dataclass</code>","text":"<p>               Bases: <code>_Resource</code></p> <p>A list of group items.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>The kind of resource this is. This will always be \"youtube#groupListResponse\".</p> required <code>etag</code> <code>Optional[str]</code> <p>The Etag of this resource.</p> required <code>items</code> <code>List[GroupItem]</code> <p>A list of items that the group contains. Each item in the list represents a groupItem resource.</p> required Source code in <code>analytix/groups/groups.py</code> <pre><code>@dataclass(frozen=True)\nclass GroupItemList(_Resource):\n    \"\"\"A list of group items.\n\n    Parameters\n    ----------\n    kind\n        The kind of resource this is. This will always be\n        \"youtube#groupListResponse\".\n    etag\n        The Etag of this resource.\n    items\n        A list of items that the group contains. Each item in the list\n        represents a groupItem resource.\n    \"\"\"\n\n    __slots__ = \"items\"\n\n    items: List[\"GroupItem\"]\n\n    def __getitem__(self, key: int) -&gt; \"GroupItem\":\n        return self.items[key]\n\n    def __iter__(self) -&gt; Iterator[\"GroupItem\"]:\n        return iter(self.items)\n\n    @classmethod\n    def from_json(cls, data: Dict[str, Any]) -&gt; \"GroupItemList\":\n        \"\"\"Create a new `GroupItemList` instance from JSON data.\n\n        Parameters\n        ----------\n        data\n            The raw JSON data from the API.\n\n        Returns\n        -------\n        GroupItemList\n            The newly created instance.\n        \"\"\"\n        return cls(\n            data[\"kind\"],\n            data[\"etag\"],\n            [GroupItem.from_json(item) for item in data[\"items\"]],\n        )\n\n    @property\n    def data(self) -&gt; Dict[str, Any]:\n        \"\"\"The raw data for this group in JSON format.\n\n        Returns\n        -------\n        Dict[str, Any]\n            The response data.\n        \"\"\"\n        return {\n            \"kind\": self.kind,\n            \"etag\": self.etag,\n            \"items\": [g_item.data for g_item in self.items],\n        }\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItemList.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The raw data for this group in JSON format.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The response data.</p>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItemList.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data: Dict[str, Any]) -&gt; GroupItemList\n</code></pre> <p>Create a new <code>GroupItemList</code> instance from JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw JSON data from the API.</p> required <p>Returns:</p> Type Description <code>GroupItemList</code> <p>The newly created instance.</p> Source code in <code>analytix/groups/groups.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Dict[str, Any]) -&gt; \"GroupItemList\":\n    \"\"\"Create a new `GroupItemList` instance from JSON data.\n\n    Parameters\n    ----------\n    data\n        The raw JSON data from the API.\n\n    Returns\n    -------\n    GroupItemList\n        The newly created instance.\n    \"\"\"\n    return cls(\n        data[\"kind\"],\n        data[\"etag\"],\n        [GroupItem.from_json(item) for item in data[\"items\"]],\n    )\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupItemResource","title":"GroupItemResource  <code>dataclass</code>","text":"<p>A group item resource.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Identifies the type of resource being added to the group.</p> required <code>id</code> <code>str</code> <p>The channel, video, playlist, or asset ID that YouTube uses to uniquely identify the item that is being added to the group.</p> required Source code in <code>analytix/groups/groups.py</code> <pre><code>@dataclass(frozen=True)\nclass GroupItemResource:\n    \"\"\"A group item resource.\n\n    Parameters\n    ----------\n    kind\n        Identifies the type of resource being added to the group.\n    id\n        The channel, video, playlist, or asset ID that YouTube uses to\n        uniquely identify the item that is being added to the group.\n    \"\"\"\n\n    __slots__ = (\"kind\", \"id\")\n\n    kind: str\n    id: str\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupList","title":"GroupList  <code>dataclass</code>","text":"<p>               Bases: <code>_Resource</code></p> <p>A list of groups.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>The kind of resource this is. This will always be \"youtube#groupListResponse\".</p> required <code>etag</code> <code>Optional[str]</code> <p>The Etag of this resource.</p> required <code>items</code> <code>List[Group]</code> <p>A list of groups that match the API request parameters. Each item in the list represents a group resource.</p> required <code>next_page_token</code> <code>Optional[str]</code> <p>The token that can be used as the value of the <code>pageToken</code> parameter to retrieve the next page in the result set.</p> required Source code in <code>analytix/groups/groups.py</code> <pre><code>@dataclass(frozen=True)\nclass GroupList(_Resource):\n    \"\"\"A list of groups.\n\n    Parameters\n    ----------\n    kind\n        The kind of resource this is. This will always be\n        \"youtube#groupListResponse\".\n    etag\n        The Etag of this resource.\n    items\n        A list of groups that match the API request parameters. Each\n        item in the list represents a group resource.\n    next_page_token\n        The token that can be used as the value of the `pageToken`\n        parameter to retrieve the next page in the result set.\n    \"\"\"\n\n    __slots__ = (\"items\", \"next_page_token\")\n\n    items: List[\"Group\"]\n    next_page_token: Optional[str]\n\n    def __getitem__(self, key: int) -&gt; \"Group\":\n        return self.items[key]\n\n    def __iter__(self) -&gt; Iterator[\"Group\"]:\n        return iter(self.items)\n\n    @classmethod\n    def from_json(cls, shard: \"Shard\", data: Dict[str, Any]) -&gt; \"GroupList\":\n        \"\"\"Create a new `GroupList` instance from JSON data.\n\n        ???+ note \"Changed in version 5.0\"\n            * This now takes the shard instance used to fetch the data\n            * This will no longer raise an error if a channel has no\n              groups\n\n        Parameters\n        ----------\n        shard\n            The shard instance used to fetch the data.\n        data\n            The raw JSON data from the API.\n\n        Returns\n        -------\n        GroupList\n            The newly created instance.\n        \"\"\"\n        return cls(\n            data[\"kind\"],\n            data.get(\"etag\"),\n            [Group.from_json(shard, item) for item in data[\"items\"]],\n            data.get(\"nextPageToken\"),\n        )\n\n    @property\n    def data(self) -&gt; Dict[str, Any]:\n        \"\"\"The raw data for this group in JSON format.\n\n        Returns\n        -------\n        Dict[str, Any]\n            The response data.\n        \"\"\"\n        return {\n            \"kind\": self.kind,\n            \"etag\": self.etag,\n            \"items\": [group.data for group in self.items],\n            \"nextPageToken\": self.next_page_token,\n        }\n</code></pre>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupList.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The raw data for this group in JSON format.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The response data.</p>"},{"location":"reference/groups/groups/#analytix.groups.groups.GroupList.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(shard: Shard, data: Dict[str, Any]) -&gt; GroupList\n</code></pre> <p>Create a new <code>GroupList</code> instance from JSON data.</p> Changed in version 5.0 <ul> <li>This now takes the shard instance used to fetch the data</li> <li>This will no longer raise an error if a channel has no   groups</li> </ul> <p>Parameters:</p> Name Type Description Default <code>shard</code> <code>Shard</code> <p>The shard instance used to fetch the data.</p> required <code>data</code> <code>Dict[str, Any]</code> <p>The raw JSON data from the API.</p> required <p>Returns:</p> Type Description <code>GroupList</code> <p>The newly created instance.</p> Source code in <code>analytix/groups/groups.py</code> <pre><code>@classmethod\ndef from_json(cls, shard: \"Shard\", data: Dict[str, Any]) -&gt; \"GroupList\":\n    \"\"\"Create a new `GroupList` instance from JSON data.\n\n    ???+ note \"Changed in version 5.0\"\n        * This now takes the shard instance used to fetch the data\n        * This will no longer raise an error if a channel has no\n          groups\n\n    Parameters\n    ----------\n    shard\n        The shard instance used to fetch the data.\n    data\n        The raw JSON data from the API.\n\n    Returns\n    -------\n    GroupList\n        The newly created instance.\n    \"\"\"\n    return cls(\n        data[\"kind\"],\n        data.get(\"etag\"),\n        [Group.from_json(shard, item) for item in data[\"items\"]],\n        data.get(\"nextPageToken\"),\n    )\n</code></pre>"},{"location":"reference/reports/interfaces/","title":"interfaces","text":"<p>Report interfaces for analytix.</p> <p>These are report interfaces equipped with various methods of saving and exporting report data to different formats. They are not designed to be like-for-like mappings of YouTube Analytics API resources.</p> <p>Currently, there is only one of these interfaces.</p>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report","title":"Report","text":"<p>An analytics report.</p> <p>This is an abstraction of the <code>resultTable</code> resource rather than a direct mapping. This class provides additional properties and methods designed to make it easier to perform certain operations.</p> Changed in version 5.0 <p>This used to be <code>AnalyticsReport</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw JSON data from the API.</p> required <code>type</code> <code>ReportType</code> <p>The report type.</p> required <p>Attributes:</p> Name Type Description <code>resource</code> <code>ResultTable</code> <p>An instance representing a <code>resultTable</code> resource.</p> <code>type</code> <code>ReportType</code> <p>The report type.</p> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>class Report:\n    \"\"\"An analytics report.\n\n    This is an abstraction of the `resultTable` resource rather than a\n    direct mapping. This class provides additional properties and\n    methods designed to make it easier to perform certain operations.\n\n    ???+ note \"Changed in version 5.0\"\n        This used to be `AnalyticsReport`.\n\n    Parameters\n    ----------\n    data\n        The raw JSON data from the API.\n    type\n        The report type.\n\n    Attributes\n    ----------\n    resource : ResultTable\n        An instance representing a `resultTable` resource.\n    type : ReportType\n        The report type.\n    \"\"\"\n\n    def __init__(self, data: Dict[str, Any], type: \"ReportType\") -&gt; None:\n        self.resource = ResultTable.from_json(data)\n        self.type = type\n        self._shape = (len(data[\"rows\"]), len(self.resource.column_headers))\n\n    @property\n    def shape(self) -&gt; Tuple[int, int]:\n        \"\"\"The shape of the report.\n\n        This is presented in (rows, columns) format.\n\n        Returns\n        -------\n        Tuple[int, int]\n            The shape of the report.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.shape\n        (120, 42)\n        \"\"\"\n        return self._shape\n\n    @property\n    def columns(self) -&gt; List[str]:\n        \"\"\"A list of all columns names in the report.\n\n        Returns\n        -------\n        List[str]\n            The column list.\n\n        See Also\n        --------\n        This does not return a list of column headers. If you want that,\n        use `report.resource.column_headers` instead.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.columns\n        [\"day\", \"subscribedStatus\", \"views\", \"likes\", \"comments\"]\n        \"\"\"\n        return [c.name for c in self.resource.column_headers]\n\n    @property\n    def dimensions(self) -&gt; List[str]:\n        \"\"\"A list of all dimensions in the report.\n\n        Returns\n        -------\n        List[str]\n            The dimension list.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.dimensions\n        [\"day\", \"subscribedStatus\"]\n        \"\"\"\n        return [\n            c.name\n            for c in self.resource.column_headers\n            if c.column_type == ColumnType.DIMENSION\n        ]\n\n    @property\n    def metrics(self) -&gt; List[str]:\n        \"\"\"A list of all metrics in the report.\n\n        Returns\n        -------\n        List[str]\n            The metric list.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.metrics\n        [\"views\", \"likes\", \"comments\"]\n        \"\"\"\n        return [\n            c.name\n            for c in self.resource.column_headers\n            if c.column_type == ColumnType.METRIC\n        ]\n\n    def to_json(\n        self,\n        path: \"PathLike\",\n        *,\n        overwrite: bool = False,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Save this report in JSON format.\n\n        This saves the data as it arrived from the YouTube Analytics\n        API.\n\n        ???+ note \"Changed in version 5.0\"\n            * `indent` is no longer an argument, but can still be\n              provided as part of the `**kwargs`; as such, JSON exports\n              are no longer indented by default\n            * This will no longer overwrite existing files by default\n            * You can now pass additional keyword arguments to be passed\n              to the `json.dump` function\n\n        Parameters\n        ----------\n        path\n            The path to save the file to.\n        overwrite\n            Whether to overwrite an existing file.\n        **kwargs\n            Additional arguments to pass to `json.dump`. This includes\n            `indent`.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.to_json(\"output.json\")\n\n        Saving in a pretty format.\n\n        &gt;&gt;&gt; report.to_json(\"output.json\", indent=4)\n        \"\"\"\n        path = process_path(path, \".json\", overwrite=overwrite)\n        data = self.resource.data\n\n        with open(path, \"w\") as f:\n            json.dump(data, f, **kwargs)\n\n        _log.info(f\"Saved report as JSON to {path.resolve()}\")\n\n    def to_csv(\n        self,\n        path: \"PathLike\",\n        *,\n        delimiter: str = \",\",\n        overwrite: bool = False,\n    ) -&gt; None:\n        \"\"\"Save this report as a CSV or TSV file.\n\n        The filetype is dependent on the delimiter you provide \u2014 if you\n        pass a tab character as a delimiter, the file will be saved as\n        a TSV. It will be saved as a CSV in all other instances.\n\n        ???+ note \"Changed in version 5.0\"\n            This will no longer overwrite existing files by default.\n\n        Parameters\n        ----------\n        path\n            The path to save the file to.\n        delimiter\n            The character to use as a delimiter. If this is `\\\\t`, the\n            report will be saved as a TSV.\n        overwrite\n            Whether to overwrite an existing file.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.to_csv(\"output.csv\")\n\n        Saving as a TSV.\n\n        &gt;&gt;&gt; report.to_csv(\"output.tsv\", delimiter=\"\\\\t\")\n        \"\"\"\n        extension = \".tsv\" if delimiter == \"\\t\" else \".csv\"\n        path = process_path(path, extension, overwrite=overwrite)\n\n        with open(path, \"w\") as f:\n            f.write(f\"{delimiter.join(self.columns)}\\n\")\n            for row in self.resource.rows:\n                line = delimiter.join(f\"{v}\" for v in row)\n                f.write(f\"{line}\\n\")\n\n        _log.info(f\"Saved report as {extension[1:].upper()} to {path.resolve()}\")\n\n    def to_excel(\n        self,\n        path: \"PathLike\",\n        *,\n        sheet_name: str = \"Analytics\",\n        overwrite: bool = False,\n    ) -&gt; None:\n        \"\"\"Save this report as an Excel spreadsheet.\n\n        The data cannot be saved to a new sheet in an existing workbook.\n        If you wish to do this, you will need to save the data to a new\n        spreadsheet file, then copy the data over.\n\n        ???+ note \"Changed in version 5.0\"\n            This will no longer overwrite existing files by default.\n\n        Parameters\n        ----------\n        path\n            The path to save the spreadsheet to.\n        sheet_name\n            The name to give the sheet the data will be inserted into.\n        overwrite\n            Whether to overwrite an existing file.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Notes\n        -----\n        This requires `openpyxl` to be installed to use, which is an\n        optional dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.to_excel(\"output.xlsx\")\n        \"\"\"\n        if not utils.can_use(\"openpyxl\"):\n            raise MissingOptionalComponents(\"openpyxl\")\n\n        from openpyxl import Workbook\n\n        path = process_path(path, \".xlsx\", overwrite=overwrite)\n        wb = Workbook()\n        ws = wb.active\n        ws.title = sheet_name\n\n        ws.append(self.columns)\n        for row in self.resource.rows:\n            ws.append(row)\n\n        wb.save(str(path))\n        _log.info(f\"Saved report as spreadsheet to {path.resolve()}\")\n\n    def to_pandas(self, *, skip_date_conversion: bool = False) -&gt; \"pd.DataFrame\":\n        \"\"\"Return this report as a pandas DataFrame.\n\n        Parameters\n        ----------\n        skip_date_conversion\n            Whether or not to skip the conversion of \"day\" and \"month\"\n            columns into a datetime format. If you choose to skip this,\n            these columns will be left as strings.\n\n        Returns\n        -------\n        pandas DataFrame\n            A pandas DataFrame.\n\n        Raises\n        ------\n        MissingOptionalComponents\n            pandas is not installed.\n        DataFrameConversionError\n            There is no data from which to create a DataFrame.\n\n        Notes\n        -----\n        This requires `pandas` to be installed to use, which is an\n        optional dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = report.to_pandas()\n        &gt;&gt;&gt; df.head(5)\n                 day  views  likes  comments  grossRevenue\n        0 2022-06-20    778      8         0         2.249\n        1 2022-06-21   1062     32         8         3.558\n        2 2022-06-22    946     38         6         2.910\n        3 2022-06-23   5107    199        15        24.428\n        4 2022-06-24   2137     61         2         6.691\n        \"\"\"\n        # sourcery skip: class-extract-method\n        if not utils.can_use(\"pandas\"):\n            raise MissingOptionalComponents(\"pandas\")\n\n        if not self._shape[0]:\n            raise DataFrameConversionError(\n                \"cannot convert to DataFrame as the returned data has no rows\",\n            )\n\n        import pandas as pd\n\n        df = pd.DataFrame(self.resource.rows, columns=self.columns)\n\n        if not skip_date_conversion and len(s := {\"day\", \"month\"} &amp; set(df.columns)):\n            col = next(iter(s))\n            fmt = {\"day\": \"%Y-%m-%d\", \"month\": \"%Y-%m\"}[col]\n            df[col] = pd.to_datetime(df[col], format=fmt)\n            _log.debug(f\"Converted {col!r} column to datetime format\")\n\n        return df\n\n    def to_arrow(self, *, skip_date_conversion: bool = False) -&gt; \"pa.Table\":\n        \"\"\"Export this report as an Apache Arrow table.\n\n        Parameters\n        ----------\n        skip_date_conversion\n            Whether or not to skip the conversion of \"day\" and \"month\"\n            columns into a datetime format. If you choose to skip this,\n            these columns will be left as strings.\n\n        Returns\n        -------\n        PyArrow Table\n            An Apache Arrow table.\n\n        Raises\n        ------\n        MissingOptionalComponents\n            PyArrow is not installed.\n        DataFrameConversionError\n            There is no data from which to create an Arrow table.\n\n        Notes\n        -----\n        This requires `pyarrow` to be installed to use, which is an\n        optional dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; table = report.to_arrow()\n        &gt;&gt;&gt; table.slice(length=3)\n        pyarrow.Table\n        day: timestamp[ns]\n        views: int64\n        likes: int64\n        comments: int64\n        grossRevenue: double\n        ----\n        day: [[2022-06-20 00:00:00.000000000,...]]\n        views: [[778,1062,946,5107,2137]]\n        likes: [[8,32,38,199,61]]\n        comments: [[0,8,6,15,2]]\n        grossRevenue: [[2.249,3.558,2.91,24.428,6.691]]\n        \"\"\"\n        if not utils.can_use(\"pyarrow\"):\n            raise MissingOptionalComponents(\"pyarrow\")\n\n        if not self._shape[0]:\n            raise DataFrameConversionError(\n                \"cannot convert to Arrow table as the returned data has no rows\",\n            )\n\n        import pyarrow as pa\n        import pyarrow.compute as pc\n\n        table = pa.table(list(zip(*self.resource.rows)), names=self.columns)\n\n        if not skip_date_conversion and len(\n            s := {\"day\", \"month\"} &amp; set(table.column_names),\n        ):\n            col = next(iter(s))\n            fmt = {\"day\": \"%Y-%m-%d\", \"month\": \"%Y-%m\"}[col]\n            dt_series = pc.strptime(table.column(col), format=fmt, unit=\"ns\")\n            table = table.set_column(0, \"day\", dt_series)\n            _log.debug(f\"Converted {col!r} column to datetime format\")\n\n        return table\n\n    def to_polars(self, *, skip_date_conversion: bool = False) -&gt; \"pl.DataFrame\":\n        \"\"\"Return the data as a Polars DataFrame.\n\n        Parameters\n        ----------\n        skip_date_conversion\n            Whether or not to skip the conversion of \"day\" and \"month\"\n            columns into a date format. If you choose to skip this,\n            these columns will be left as strings.\n\n        Returns\n        -------\n        Polars DataFrame\n            A Polars DataFrame.\n\n        Raises\n        ------\n        MissingOptionalComponents\n            Polars is not installed.\n        DataFrameConversionError\n            There is no data from which to create a DataFrame.\n\n        Notes\n        -----\n        This requires `polars` to be installed to use, which is an\n        optional dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; df = report.to_polars()\n        &gt;&gt;&gt; df.head(5)\n        shape: (5, 5)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 day        \u2506 views \u2506 likes \u2506 comments \u2506 grossRevenue \u2502\n        \u2502 ---        \u2506 ---   \u2506 ---   \u2506 ---      \u2506 ---          \u2502\n        \u2502 date       \u2506 i64   \u2506 i64   \u2506 i64      \u2506 f64          \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 2022-06-20 \u2506 778   \u2506 8     \u2506 0        \u2506 2.249        \u2502\n        \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n        \u2502 2022-06-21 \u2506 1062  \u2506 32    \u2506 8        \u2506 3.558        \u2502\n        \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n        \u2502 2022-06-22 \u2506 946   \u2506 38    \u2506 6        \u2506 2.91         \u2502\n        \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n        \u2502 2022-06-23 \u2506 5107  \u2506 199   \u2506 15       \u2506 24.428       \u2502\n        \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n        \u2502 2022-06-24 \u2506 2137  \u2506 61    \u2506 2        \u2506 6.691        \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \"\"\"\n        if not utils.can_use(\"polars\"):\n            raise MissingOptionalComponents(\"polars\")\n\n        if not self._shape[0]:\n            raise DataFrameConversionError(\n                \"cannot convert to DataFrame as the returned data has no rows\",\n            )\n\n        import polars as pl\n\n        df = pl.DataFrame(self.resource.rows, schema=self.columns)\n\n        if not skip_date_conversion and len(s := {\"day\", \"month\"} &amp; set(df.columns)):\n            col = next(iter(s))\n            fmt = {\"day\": \"%Y-%m-%d\", \"month\": \"%Y-%m\"}[col]\n            df = df.with_columns(pl.col(col).str.strptime(pl.Date, fmt))\n            _log.debug(f\"Converted {col!r} column to date format\")\n\n        return df\n\n    def to_feather(\n        self,\n        path: \"PathLike\",\n        *,\n        skip_date_conversion: bool = False,\n        overwrite: bool = False,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Save this report as an Apache Feather file.\n\n        ???+ note \"Changed in version 5.0\"\n            * This will no longer overwrite existing files by default\n            * You can now pass additional keyword arguments to be passed\n              to the `pf.write_feather` function\n            * This no longer returns a PyArrow table\n\n        Parameters\n        ----------\n        path\n            The path to save the file to.\n        skip_date_conversion\n            Whether or not to skip the conversion of \"day\" and \"month\"\n            columns into a datetime format. If you choose to skip this,\n            these columns will be left as strings.\n        overwrite\n            Whether to overwrite an existing file.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Other Parameters\n        ----------------\n        **kwargs\n            Additional arguments to pass to `pf.write_feather`.\n\n        Notes\n        -----\n        This requires `pyarrow` to be installed to use, which is an\n        optional dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.to_feather(\"output.feather\")\n        \"\"\"\n        if not utils.can_use(\"pyarrow\"):\n            raise MissingOptionalComponents(\"pyarrow\")\n\n        import pyarrow.feather as pf\n\n        path = process_path(path, \".feather\", overwrite=overwrite)\n        pf.write_feather(\n            self.to_arrow(skip_date_conversion=skip_date_conversion),\n            path,\n            **kwargs,\n        )\n\n        _log.info(f\"Saved report as Apache Feather file to {path.resolve()}\")\n\n    def to_parquet(\n        self,\n        path: \"PathLike\",\n        *,\n        skip_date_conversion: bool = False,\n        overwrite: bool = False,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Save this report as an Apache Parquet file.\n\n        ???+ note \"Changed in version 5.0\"\n            * This will no longer overwrite existing files by default\n            * You can now pass additional keyword arguments to be passed\n              to the `pq.write_table` function\n            * This no longer returns a PyArrow table\n\n        Parameters\n        ----------\n        path\n            The path to save the file to.\n        skip_date_conversion\n            Whether or not to skip the conversion of \"day\" and \"month\"\n            columns into a datetime format. If you choose to skip this,\n            these columns will be left as strings.\n        overwrite\n            Whether to overwrite an existing file.\n\n        Returns\n        -------\n        None\n            This method doesn't return anything.\n\n        Other Parameters\n        ----------------\n        **kwargs\n            Additional arguments to pass to `pq.write_table`.\n\n        Notes\n        -----\n        This requires `pyarrow` to be installed to use, which is an\n        optional dependency.\n\n        Examples\n        --------\n        &gt;&gt;&gt; report.to_parquet(\"output.parquet\")\n        \"\"\"\n\n        if not utils.can_use(\"pyarrow\"):\n            raise MissingOptionalComponents(\"pyarrow\")\n\n        import pyarrow.parquet as pq\n\n        path = process_path(path, \".parquet\", overwrite=overwrite)\n        pq.write_table(\n            self.to_arrow(skip_date_conversion=skip_date_conversion),\n            path,\n            **kwargs,\n        )\n\n        _log.info(f\"Saved report as Apache Parquet file to {path.resolve()}\")\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.columns","title":"columns  <code>property</code>","text":"<pre><code>columns: List[str]\n</code></pre> <p>A list of all columns names in the report.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>The column list.</p> See Also <p>This does not return a list of column headers. If you want that, use <code>report.resource.column_headers</code> instead.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.columns\n[\"day\", \"subscribedStatus\", \"views\", \"likes\", \"comments\"]\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.dimensions","title":"dimensions  <code>property</code>","text":"<pre><code>dimensions: List[str]\n</code></pre> <p>A list of all dimensions in the report.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>The dimension list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.dimensions\n[\"day\", \"subscribedStatus\"]\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.metrics","title":"metrics  <code>property</code>","text":"<pre><code>metrics: List[str]\n</code></pre> <p>A list of all metrics in the report.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>The metric list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.metrics\n[\"views\", \"likes\", \"comments\"]\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.shape","title":"shape  <code>property</code>","text":"<pre><code>shape: Tuple[int, int]\n</code></pre> <p>The shape of the report.</p> <p>This is presented in (rows, columns) format.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>The shape of the report.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.shape\n(120, 42)\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_arrow","title":"to_arrow","text":"<pre><code>to_arrow(*, skip_date_conversion: bool = False) -&gt; pa.Table\n</code></pre> <p>Export this report as an Apache Arrow table.</p> <p>Parameters:</p> Name Type Description Default <code>skip_date_conversion</code> <code>bool</code> <p>Whether or not to skip the conversion of \"day\" and \"month\" columns into a datetime format. If you choose to skip this, these columns will be left as strings.</p> <code>False</code> <p>Returns:</p> Type Description <code>PyArrow Table</code> <p>An Apache Arrow table.</p> <p>Raises:</p> Type Description <code>MissingOptionalComponents</code> <p>PyArrow is not installed.</p> <code>DataFrameConversionError</code> <p>There is no data from which to create an Arrow table.</p> Notes <p>This requires <code>pyarrow</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = report.to_arrow()\n&gt;&gt;&gt; table.slice(length=3)\npyarrow.Table\nday: timestamp[ns]\nviews: int64\nlikes: int64\ncomments: int64\ngrossRevenue: double\n----\nday: [[2022-06-20 00:00:00.000000000,...]]\nviews: [[778,1062,946,5107,2137]]\nlikes: [[8,32,38,199,61]]\ncomments: [[0,8,6,15,2]]\ngrossRevenue: [[2.249,3.558,2.91,24.428,6.691]]\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_arrow(self, *, skip_date_conversion: bool = False) -&gt; \"pa.Table\":\n    \"\"\"Export this report as an Apache Arrow table.\n\n    Parameters\n    ----------\n    skip_date_conversion\n        Whether or not to skip the conversion of \"day\" and \"month\"\n        columns into a datetime format. If you choose to skip this,\n        these columns will be left as strings.\n\n    Returns\n    -------\n    PyArrow Table\n        An Apache Arrow table.\n\n    Raises\n    ------\n    MissingOptionalComponents\n        PyArrow is not installed.\n    DataFrameConversionError\n        There is no data from which to create an Arrow table.\n\n    Notes\n    -----\n    This requires `pyarrow` to be installed to use, which is an\n    optional dependency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; table = report.to_arrow()\n    &gt;&gt;&gt; table.slice(length=3)\n    pyarrow.Table\n    day: timestamp[ns]\n    views: int64\n    likes: int64\n    comments: int64\n    grossRevenue: double\n    ----\n    day: [[2022-06-20 00:00:00.000000000,...]]\n    views: [[778,1062,946,5107,2137]]\n    likes: [[8,32,38,199,61]]\n    comments: [[0,8,6,15,2]]\n    grossRevenue: [[2.249,3.558,2.91,24.428,6.691]]\n    \"\"\"\n    if not utils.can_use(\"pyarrow\"):\n        raise MissingOptionalComponents(\"pyarrow\")\n\n    if not self._shape[0]:\n        raise DataFrameConversionError(\n            \"cannot convert to Arrow table as the returned data has no rows\",\n        )\n\n    import pyarrow as pa\n    import pyarrow.compute as pc\n\n    table = pa.table(list(zip(*self.resource.rows)), names=self.columns)\n\n    if not skip_date_conversion and len(\n        s := {\"day\", \"month\"} &amp; set(table.column_names),\n    ):\n        col = next(iter(s))\n        fmt = {\"day\": \"%Y-%m-%d\", \"month\": \"%Y-%m\"}[col]\n        dt_series = pc.strptime(table.column(col), format=fmt, unit=\"ns\")\n        table = table.set_column(0, \"day\", dt_series)\n        _log.debug(f\"Converted {col!r} column to datetime format\")\n\n    return table\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_csv","title":"to_csv","text":"<pre><code>to_csv(path: PathLike, *, delimiter: str = ',', overwrite: bool = False) -&gt; None\n</code></pre> <p>Save this report as a CSV or TSV file.</p> <p>The filetype is dependent on the delimiter you provide \u2014 if you pass a tab character as a delimiter, the file will be saved as a TSV. It will be saved as a CSV in all other instances.</p> Changed in version 5.0 <p>This will no longer overwrite existing files by default.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save the file to.</p> required <code>delimiter</code> <code>str</code> <p>The character to use as a delimiter. If this is <code>\\t</code>, the report will be saved as a TSV.</p> <code>','</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing file.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.to_csv(\"output.csv\")\n</code></pre> <p>Saving as a TSV.</p> <pre><code>&gt;&gt;&gt; report.to_csv(\"output.tsv\", delimiter=\"\\t\")\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_csv(\n    self,\n    path: \"PathLike\",\n    *,\n    delimiter: str = \",\",\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Save this report as a CSV or TSV file.\n\n    The filetype is dependent on the delimiter you provide \u2014 if you\n    pass a tab character as a delimiter, the file will be saved as\n    a TSV. It will be saved as a CSV in all other instances.\n\n    ???+ note \"Changed in version 5.0\"\n        This will no longer overwrite existing files by default.\n\n    Parameters\n    ----------\n    path\n        The path to save the file to.\n    delimiter\n        The character to use as a delimiter. If this is `\\\\t`, the\n        report will be saved as a TSV.\n    overwrite\n        Whether to overwrite an existing file.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Examples\n    --------\n    &gt;&gt;&gt; report.to_csv(\"output.csv\")\n\n    Saving as a TSV.\n\n    &gt;&gt;&gt; report.to_csv(\"output.tsv\", delimiter=\"\\\\t\")\n    \"\"\"\n    extension = \".tsv\" if delimiter == \"\\t\" else \".csv\"\n    path = process_path(path, extension, overwrite=overwrite)\n\n    with open(path, \"w\") as f:\n        f.write(f\"{delimiter.join(self.columns)}\\n\")\n        for row in self.resource.rows:\n            line = delimiter.join(f\"{v}\" for v in row)\n            f.write(f\"{line}\\n\")\n\n    _log.info(f\"Saved report as {extension[1:].upper()} to {path.resolve()}\")\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_excel","title":"to_excel","text":"<pre><code>to_excel(path: PathLike, *, sheet_name: str = 'Analytics', overwrite: bool = False) -&gt; None\n</code></pre> <p>Save this report as an Excel spreadsheet.</p> <p>The data cannot be saved to a new sheet in an existing workbook. If you wish to do this, you will need to save the data to a new spreadsheet file, then copy the data over.</p> Changed in version 5.0 <p>This will no longer overwrite existing files by default.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save the spreadsheet to.</p> required <code>sheet_name</code> <code>str</code> <p>The name to give the sheet the data will be inserted into.</p> <code>'Analytics'</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing file.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> Notes <p>This requires <code>openpyxl</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.to_excel(\"output.xlsx\")\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_excel(\n    self,\n    path: \"PathLike\",\n    *,\n    sheet_name: str = \"Analytics\",\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Save this report as an Excel spreadsheet.\n\n    The data cannot be saved to a new sheet in an existing workbook.\n    If you wish to do this, you will need to save the data to a new\n    spreadsheet file, then copy the data over.\n\n    ???+ note \"Changed in version 5.0\"\n        This will no longer overwrite existing files by default.\n\n    Parameters\n    ----------\n    path\n        The path to save the spreadsheet to.\n    sheet_name\n        The name to give the sheet the data will be inserted into.\n    overwrite\n        Whether to overwrite an existing file.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Notes\n    -----\n    This requires `openpyxl` to be installed to use, which is an\n    optional dependency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; report.to_excel(\"output.xlsx\")\n    \"\"\"\n    if not utils.can_use(\"openpyxl\"):\n        raise MissingOptionalComponents(\"openpyxl\")\n\n    from openpyxl import Workbook\n\n    path = process_path(path, \".xlsx\", overwrite=overwrite)\n    wb = Workbook()\n    ws = wb.active\n    ws.title = sheet_name\n\n    ws.append(self.columns)\n    for row in self.resource.rows:\n        ws.append(row)\n\n    wb.save(str(path))\n    _log.info(f\"Saved report as spreadsheet to {path.resolve()}\")\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_feather","title":"to_feather","text":"<pre><code>to_feather(path: PathLike, *, skip_date_conversion: bool = False, overwrite: bool = False, **kwargs: Any) -&gt; None\n</code></pre> <p>Save this report as an Apache Feather file.</p> Changed in version 5.0 <ul> <li>This will no longer overwrite existing files by default</li> <li>You can now pass additional keyword arguments to be passed   to the <code>pf.write_feather</code> function</li> <li>This no longer returns a PyArrow table</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save the file to.</p> required <code>skip_date_conversion</code> <code>bool</code> <p>Whether or not to skip the conversion of \"day\" and \"month\" columns into a datetime format. If you choose to skip this, these columns will be left as strings.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing file.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to <code>pf.write_feather</code>.</p> Notes <p>This requires <code>pyarrow</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.to_feather(\"output.feather\")\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_feather(\n    self,\n    path: \"PathLike\",\n    *,\n    skip_date_conversion: bool = False,\n    overwrite: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Save this report as an Apache Feather file.\n\n    ???+ note \"Changed in version 5.0\"\n        * This will no longer overwrite existing files by default\n        * You can now pass additional keyword arguments to be passed\n          to the `pf.write_feather` function\n        * This no longer returns a PyArrow table\n\n    Parameters\n    ----------\n    path\n        The path to save the file to.\n    skip_date_conversion\n        Whether or not to skip the conversion of \"day\" and \"month\"\n        columns into a datetime format. If you choose to skip this,\n        these columns will be left as strings.\n    overwrite\n        Whether to overwrite an existing file.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Other Parameters\n    ----------------\n    **kwargs\n        Additional arguments to pass to `pf.write_feather`.\n\n    Notes\n    -----\n    This requires `pyarrow` to be installed to use, which is an\n    optional dependency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; report.to_feather(\"output.feather\")\n    \"\"\"\n    if not utils.can_use(\"pyarrow\"):\n        raise MissingOptionalComponents(\"pyarrow\")\n\n    import pyarrow.feather as pf\n\n    path = process_path(path, \".feather\", overwrite=overwrite)\n    pf.write_feather(\n        self.to_arrow(skip_date_conversion=skip_date_conversion),\n        path,\n        **kwargs,\n    )\n\n    _log.info(f\"Saved report as Apache Feather file to {path.resolve()}\")\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_json","title":"to_json","text":"<pre><code>to_json(path: PathLike, *, overwrite: bool = False, **kwargs: Any) -&gt; None\n</code></pre> <p>Save this report in JSON format.</p> <p>This saves the data as it arrived from the YouTube Analytics API.</p> Changed in version 5.0 <ul> <li><code>indent</code> is no longer an argument, but can still be   provided as part of the <code>**kwargs</code>; as such, JSON exports   are no longer indented by default</li> <li>This will no longer overwrite existing files by default</li> <li>You can now pass additional keyword arguments to be passed   to the <code>json.dump</code> function</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save the file to.</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing file.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to <code>json.dump</code>. This includes <code>indent</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.to_json(\"output.json\")\n</code></pre> <p>Saving in a pretty format.</p> <pre><code>&gt;&gt;&gt; report.to_json(\"output.json\", indent=4)\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_json(\n    self,\n    path: \"PathLike\",\n    *,\n    overwrite: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Save this report in JSON format.\n\n    This saves the data as it arrived from the YouTube Analytics\n    API.\n\n    ???+ note \"Changed in version 5.0\"\n        * `indent` is no longer an argument, but can still be\n          provided as part of the `**kwargs`; as such, JSON exports\n          are no longer indented by default\n        * This will no longer overwrite existing files by default\n        * You can now pass additional keyword arguments to be passed\n          to the `json.dump` function\n\n    Parameters\n    ----------\n    path\n        The path to save the file to.\n    overwrite\n        Whether to overwrite an existing file.\n    **kwargs\n        Additional arguments to pass to `json.dump`. This includes\n        `indent`.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Examples\n    --------\n    &gt;&gt;&gt; report.to_json(\"output.json\")\n\n    Saving in a pretty format.\n\n    &gt;&gt;&gt; report.to_json(\"output.json\", indent=4)\n    \"\"\"\n    path = process_path(path, \".json\", overwrite=overwrite)\n    data = self.resource.data\n\n    with open(path, \"w\") as f:\n        json.dump(data, f, **kwargs)\n\n    _log.info(f\"Saved report as JSON to {path.resolve()}\")\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_pandas","title":"to_pandas","text":"<pre><code>to_pandas(*, skip_date_conversion: bool = False) -&gt; pd.DataFrame\n</code></pre> <p>Return this report as a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>skip_date_conversion</code> <code>bool</code> <p>Whether or not to skip the conversion of \"day\" and \"month\" columns into a datetime format. If you choose to skip this, these columns will be left as strings.</p> <code>False</code> <p>Returns:</p> Type Description <code>pandas DataFrame</code> <p>A pandas DataFrame.</p> <p>Raises:</p> Type Description <code>MissingOptionalComponents</code> <p>pandas is not installed.</p> <code>DataFrameConversionError</code> <p>There is no data from which to create a DataFrame.</p> Notes <p>This requires <code>pandas</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = report.to_pandas()\n&gt;&gt;&gt; df.head(5)\n         day  views  likes  comments  grossRevenue\n0 2022-06-20    778      8         0         2.249\n1 2022-06-21   1062     32         8         3.558\n2 2022-06-22    946     38         6         2.910\n3 2022-06-23   5107    199        15        24.428\n4 2022-06-24   2137     61         2         6.691\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_pandas(self, *, skip_date_conversion: bool = False) -&gt; \"pd.DataFrame\":\n    \"\"\"Return this report as a pandas DataFrame.\n\n    Parameters\n    ----------\n    skip_date_conversion\n        Whether or not to skip the conversion of \"day\" and \"month\"\n        columns into a datetime format. If you choose to skip this,\n        these columns will be left as strings.\n\n    Returns\n    -------\n    pandas DataFrame\n        A pandas DataFrame.\n\n    Raises\n    ------\n    MissingOptionalComponents\n        pandas is not installed.\n    DataFrameConversionError\n        There is no data from which to create a DataFrame.\n\n    Notes\n    -----\n    This requires `pandas` to be installed to use, which is an\n    optional dependency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = report.to_pandas()\n    &gt;&gt;&gt; df.head(5)\n             day  views  likes  comments  grossRevenue\n    0 2022-06-20    778      8         0         2.249\n    1 2022-06-21   1062     32         8         3.558\n    2 2022-06-22    946     38         6         2.910\n    3 2022-06-23   5107    199        15        24.428\n    4 2022-06-24   2137     61         2         6.691\n    \"\"\"\n    # sourcery skip: class-extract-method\n    if not utils.can_use(\"pandas\"):\n        raise MissingOptionalComponents(\"pandas\")\n\n    if not self._shape[0]:\n        raise DataFrameConversionError(\n            \"cannot convert to DataFrame as the returned data has no rows\",\n        )\n\n    import pandas as pd\n\n    df = pd.DataFrame(self.resource.rows, columns=self.columns)\n\n    if not skip_date_conversion and len(s := {\"day\", \"month\"} &amp; set(df.columns)):\n        col = next(iter(s))\n        fmt = {\"day\": \"%Y-%m-%d\", \"month\": \"%Y-%m\"}[col]\n        df[col] = pd.to_datetime(df[col], format=fmt)\n        _log.debug(f\"Converted {col!r} column to datetime format\")\n\n    return df\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_parquet","title":"to_parquet","text":"<pre><code>to_parquet(path: PathLike, *, skip_date_conversion: bool = False, overwrite: bool = False, **kwargs: Any) -&gt; None\n</code></pre> <p>Save this report as an Apache Parquet file.</p> Changed in version 5.0 <ul> <li>This will no longer overwrite existing files by default</li> <li>You can now pass additional keyword arguments to be passed   to the <code>pq.write_table</code> function</li> <li>This no longer returns a PyArrow table</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>The path to save the file to.</p> required <code>skip_date_conversion</code> <code>bool</code> <p>Whether or not to skip the conversion of \"day\" and \"month\" columns into a datetime format. If you choose to skip this, these columns will be left as strings.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing file.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>This method doesn't return anything.</p> <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to <code>pq.write_table</code>.</p> Notes <p>This requires <code>pyarrow</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; report.to_parquet(\"output.parquet\")\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_parquet(\n    self,\n    path: \"PathLike\",\n    *,\n    skip_date_conversion: bool = False,\n    overwrite: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Save this report as an Apache Parquet file.\n\n    ???+ note \"Changed in version 5.0\"\n        * This will no longer overwrite existing files by default\n        * You can now pass additional keyword arguments to be passed\n          to the `pq.write_table` function\n        * This no longer returns a PyArrow table\n\n    Parameters\n    ----------\n    path\n        The path to save the file to.\n    skip_date_conversion\n        Whether or not to skip the conversion of \"day\" and \"month\"\n        columns into a datetime format. If you choose to skip this,\n        these columns will be left as strings.\n    overwrite\n        Whether to overwrite an existing file.\n\n    Returns\n    -------\n    None\n        This method doesn't return anything.\n\n    Other Parameters\n    ----------------\n    **kwargs\n        Additional arguments to pass to `pq.write_table`.\n\n    Notes\n    -----\n    This requires `pyarrow` to be installed to use, which is an\n    optional dependency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; report.to_parquet(\"output.parquet\")\n    \"\"\"\n\n    if not utils.can_use(\"pyarrow\"):\n        raise MissingOptionalComponents(\"pyarrow\")\n\n    import pyarrow.parquet as pq\n\n    path = process_path(path, \".parquet\", overwrite=overwrite)\n    pq.write_table(\n        self.to_arrow(skip_date_conversion=skip_date_conversion),\n        path,\n        **kwargs,\n    )\n\n    _log.info(f\"Saved report as Apache Parquet file to {path.resolve()}\")\n</code></pre>"},{"location":"reference/reports/interfaces/#analytix.reports.interfaces.Report.to_polars","title":"to_polars","text":"<pre><code>to_polars(*, skip_date_conversion: bool = False) -&gt; pl.DataFrame\n</code></pre> <p>Return the data as a Polars DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>skip_date_conversion</code> <code>bool</code> <p>Whether or not to skip the conversion of \"day\" and \"month\" columns into a date format. If you choose to skip this, these columns will be left as strings.</p> <code>False</code> <p>Returns:</p> Type Description <code>Polars DataFrame</code> <p>A Polars DataFrame.</p> <p>Raises:</p> Type Description <code>MissingOptionalComponents</code> <p>Polars is not installed.</p> <code>DataFrameConversionError</code> <p>There is no data from which to create a DataFrame.</p> Notes <p>This requires <code>polars</code> to be installed to use, which is an optional dependency.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = report.to_polars()\n&gt;&gt;&gt; df.head(5)\nshape: (5, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 day        \u2506 views \u2506 likes \u2506 comments \u2506 grossRevenue \u2502\n\u2502 ---        \u2506 ---   \u2506 ---   \u2506 ---      \u2506 ---          \u2502\n\u2502 date       \u2506 i64   \u2506 i64   \u2506 i64      \u2506 f64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2022-06-20 \u2506 778   \u2506 8     \u2506 0        \u2506 2.249        \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2022-06-21 \u2506 1062  \u2506 32    \u2506 8        \u2506 3.558        \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2022-06-22 \u2506 946   \u2506 38    \u2506 6        \u2506 2.91         \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2022-06-23 \u2506 5107  \u2506 199   \u2506 15       \u2506 24.428       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2022-06-24 \u2506 2137  \u2506 61    \u2506 2        \u2506 6.691        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>analytix/reports/interfaces.py</code> <pre><code>def to_polars(self, *, skip_date_conversion: bool = False) -&gt; \"pl.DataFrame\":\n    \"\"\"Return the data as a Polars DataFrame.\n\n    Parameters\n    ----------\n    skip_date_conversion\n        Whether or not to skip the conversion of \"day\" and \"month\"\n        columns into a date format. If you choose to skip this,\n        these columns will be left as strings.\n\n    Returns\n    -------\n    Polars DataFrame\n        A Polars DataFrame.\n\n    Raises\n    ------\n    MissingOptionalComponents\n        Polars is not installed.\n    DataFrameConversionError\n        There is no data from which to create a DataFrame.\n\n    Notes\n    -----\n    This requires `polars` to be installed to use, which is an\n    optional dependency.\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = report.to_polars()\n    &gt;&gt;&gt; df.head(5)\n    shape: (5, 5)\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 day        \u2506 views \u2506 likes \u2506 comments \u2506 grossRevenue \u2502\n    \u2502 ---        \u2506 ---   \u2506 ---   \u2506 ---      \u2506 ---          \u2502\n    \u2502 date       \u2506 i64   \u2506 i64   \u2506 i64      \u2506 f64          \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 2022-06-20 \u2506 778   \u2506 8     \u2506 0        \u2506 2.249        \u2502\n    \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n    \u2502 2022-06-21 \u2506 1062  \u2506 32    \u2506 8        \u2506 3.558        \u2502\n    \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n    \u2502 2022-06-22 \u2506 946   \u2506 38    \u2506 6        \u2506 2.91         \u2502\n    \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n    \u2502 2022-06-23 \u2506 5107  \u2506 199   \u2506 15       \u2506 24.428       \u2502\n    \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n    \u2502 2022-06-24 \u2506 2137  \u2506 61    \u2506 2        \u2506 6.691        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n    if not utils.can_use(\"polars\"):\n        raise MissingOptionalComponents(\"polars\")\n\n    if not self._shape[0]:\n        raise DataFrameConversionError(\n            \"cannot convert to DataFrame as the returned data has no rows\",\n        )\n\n    import polars as pl\n\n    df = pl.DataFrame(self.resource.rows, schema=self.columns)\n\n    if not skip_date_conversion and len(s := {\"day\", \"month\"} &amp; set(df.columns)):\n        col = next(iter(s))\n        fmt = {\"day\": \"%Y-%m-%d\", \"month\": \"%Y-%m\"}[col]\n        df = df.with_columns(pl.col(col).str.strptime(pl.Date, fmt))\n        _log.debug(f\"Converted {col!r} column to date format\")\n\n    return df\n</code></pre>"},{"location":"reference/reports/resources/","title":"resources","text":"<p>Report resources.</p> <p>These mirror YouTube Analytics API resources, but lack quality-of-life features that the analytix interfaces provide.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.ColumnHeader","title":"ColumnHeader  <code>dataclass</code>","text":"<p>A column header.</p> <p>Column headers contain various information about the columns in the report. You will never need to create one of these yourself.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The column name.</p> required <code>data_type</code> <code>DataType</code> <p>The data type of the column.</p> required <code>column_type</code> <code>ColumnType</code> <p>The column type.</p> required Source code in <code>analytix/reports/resources.py</code> <pre><code>@dataclass(frozen=True)\nclass ColumnHeader:\n    \"\"\"A column header.\n\n    Column headers contain various information about the columns in the\n    report. You will never need to create one of these yourself.\n\n    Parameters\n    ----------\n    name\n        The column name.\n    data_type\n        The data type of the column.\n    column_type\n        The column type.\n    \"\"\"\n\n    __slots__ = (\"name\", \"data_type\", \"column_type\")\n\n    name: str\n    data_type: \"DataType\"\n    column_type: \"ColumnType\"\n\n    @property\n    def data(self) -&gt; Dict[str, Any]:\n        \"\"\"The raw data for this column header in JSON format.\n\n        Returns\n        -------\n        Dict[str, Any]\n            The response data.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"dataType\": self.data_type.value,\n            \"columnType\": self.column_type.value,\n        }\n</code></pre>"},{"location":"reference/reports/resources/#analytix.reports.resources.ColumnHeader.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The raw data for this column header in JSON format.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The response data.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.ColumnType","title":"ColumnType","text":"<p>               Bases: <code>Enum</code></p> <p>An enum of column types. Can be <code>DIMENSION</code> or <code>METRIC</code>.</p> Source code in <code>analytix/reports/resources.py</code> <pre><code>class ColumnType(Enum):\n    \"\"\"An enum of column types. Can be `DIMENSION` or `METRIC`.\"\"\"\n\n    DIMENSION = \"DIMENSION\"\n    \"\"\"Of type dimension.\"\"\"\n\n    METRIC = \"METRIC\"\n    \"\"\"Of type metric.\"\"\"\n</code></pre>"},{"location":"reference/reports/resources/#analytix.reports.resources.ColumnType.DIMENSION","title":"DIMENSION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DIMENSION = 'DIMENSION'\n</code></pre> <p>Of type dimension.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.ColumnType.METRIC","title":"METRIC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>METRIC = 'METRIC'\n</code></pre> <p>Of type metric.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.DataType","title":"DataType","text":"<p>               Bases: <code>Enum</code></p> <p>An enum of data types. Can be <code>STRING</code>, <code>INTEGER</code>, or <code>FLOAT</code>.</p> Source code in <code>analytix/reports/resources.py</code> <pre><code>class DataType(Enum):\n    \"\"\"An enum of data types. Can be `STRING`, `INTEGER`, or `FLOAT`.\"\"\"\n\n    STRING = \"STRING\"\n    \"\"\"A string type.\"\"\"\n\n    INTEGER = \"INTEGER\"\n    \"\"\"An integer type.\"\"\"\n\n    FLOAT = \"FLOAT\"\n    \"\"\"A float type.\"\"\"\n</code></pre>"},{"location":"reference/reports/resources/#analytix.reports.resources.DataType.FLOAT","title":"FLOAT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FLOAT = 'FLOAT'\n</code></pre> <p>A float type.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.DataType.INTEGER","title":"INTEGER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTEGER = 'INTEGER'\n</code></pre> <p>An integer type.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.DataType.STRING","title":"STRING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STRING = 'STRING'\n</code></pre> <p>A string type.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.ResultTable","title":"ResultTable  <code>dataclass</code>","text":"<p>A result table.</p> <p>This is the resource type that gets sent from the YouTube Analytics API.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>Literal['youtubeAnalytics#resultTable']</code> <p>The kind of resource this is. This will always be \"youtubeAnalytics#resultTable\".</p> required <code>column_headers</code> <code>List[ColumnHeader]</code> <p>Information about the columns in the report, such as the name and the column type.</p> required <code>rows</code> <code>List[List[Union[str, int, float]]]</code> <p>The rows in the report. This will be a list of lists.</p> required See Also <p>Instances of this class are presented as part of <code>Report</code> instances.</p> Source code in <code>analytix/reports/resources.py</code> <pre><code>@dataclass(frozen=True)\nclass ResultTable:\n    \"\"\"A result table.\n\n    This is the resource type that gets sent from the YouTube Analytics\n    API.\n\n    Parameters\n    ----------\n    kind\n        The kind of resource this is. This will always be\n        \"youtubeAnalytics#resultTable\".\n    column_headers\n        Information about the columns in the report, such as the name\n        and the column type.\n    rows\n        The rows in the report. This will be a list of lists.\n\n    See Also\n    --------\n    Instances of this class are presented as part of `Report` instances.\n    \"\"\"\n\n    kind: Literal[\"youtubeAnalytics#resultTable\"]\n    column_headers: List[\"ColumnHeader\"]\n    rows: List[List[Union[str, int, float]]]\n\n    @classmethod\n    def from_json(cls, data: Dict[str, Any]) -&gt; \"ResultTable\":\n        \"\"\"Create a new `ResultTable` instance from JSON data.\n\n        Parameters\n        ----------\n        data\n            The raw JSON data from the API.\n\n        Returns\n        -------\n        ResultTable\n            The newly created instance.\n        \"\"\"\n        return cls(\n            data[\"kind\"],\n            [\n                ColumnHeader(\n                    header[\"name\"],\n                    DataType(header[\"dataType\"]),\n                    ColumnType(header[\"columnType\"]),\n                )\n                for header in data[\"columnHeaders\"]\n            ],\n            data[\"rows\"],\n        )\n\n    @property\n    def data(self) -&gt; Dict[str, Any]:\n        \"\"\"The raw data for this result table in JSON format.\n\n        Returns\n        -------\n        Dict[str, Any]\n            The response data.\n        \"\"\"\n        return {\n            \"kind\": self.kind,\n            \"columnHeaders\": [header.data for header in self.column_headers],\n            \"rows\": self.rows,\n        }\n</code></pre>"},{"location":"reference/reports/resources/#analytix.reports.resources.ResultTable.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The raw data for this result table in JSON format.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The response data.</p>"},{"location":"reference/reports/resources/#analytix.reports.resources.ResultTable.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data: Dict[str, Any]) -&gt; ResultTable\n</code></pre> <p>Create a new <code>ResultTable</code> instance from JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The raw JSON data from the API.</p> required <p>Returns:</p> Type Description <code>ResultTable</code> <p>The newly created instance.</p> Source code in <code>analytix/reports/resources.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Dict[str, Any]) -&gt; \"ResultTable\":\n    \"\"\"Create a new `ResultTable` instance from JSON data.\n\n    Parameters\n    ----------\n    data\n        The raw JSON data from the API.\n\n    Returns\n    -------\n    ResultTable\n        The newly created instance.\n    \"\"\"\n    return cls(\n        data[\"kind\"],\n        [\n            ColumnHeader(\n                header[\"name\"],\n                DataType(header[\"dataType\"]),\n                ColumnType(header[\"columnType\"]),\n            )\n            for header in data[\"columnHeaders\"]\n        ],\n        data[\"rows\"],\n    )\n</code></pre>"},{"location":"starting/firstapp/","title":"Creating your first analytix program","text":""},{"location":"starting/firstapp/#creating-a-client","title":"Creating a client","text":"<p>In order to make requests to the YouTube Analytics API, you need a client. analytix provides a few different clients you can use \u2014 to find out the differences between them, see the client documentation. For this guide, we'll just use the standard <code>Client</code>.</p> <p>You can create a client like so:</p> <pre><code>from analytix import Client\n\nclient = Client(\"secrets.json\")\n</code></pre> <p>Here, we're telling the client we want to use the secrets file we downloaded when we created our Google Developers application.</p> <p>You can also create a client using a context manager:</p> <pre><code>with Client(\"secrets.json\") as client:\n    ...\n</code></pre> <p>Functionally this makes no difference -- it's just a matter of personal preference!</p>"},{"location":"starting/firstapp/#authorisation","title":"Authorisation","text":"<p>While your client will authorise itself where necessary, it's worth knowing how it goes about doing so.</p> <p>When your client first authorises itself, it will prompt you to follow an OAuth 2 flow in order to get the necessary access token for the API. This just involves signing into Google and giving your Google Developers application permission to access your analytics data. Your client will then store your access and refresh tokens, and attempt to use them in future requests. If your access token cannot be used or refreshed, you will need to reauthorise from scratch.</p> <p>Your Google Developers application is probably in \"Testing\" mode (if you're not sure, it definitely is), which means your refresh token will expire after seven days. To extend this time, you will need to publish your application, though this is never necessary when using analytix for your own personal projects.</p> <p>Note</p> <p>You can manually authorise your client using the <code>client.authorise()</code> method if you wish.</p>"},{"location":"starting/firstapp/#retrieving-analytics-data","title":"Retrieving analytics data","text":"<p>Now the real fun begins!</p> <p>Retrieving an analyrics report is simple:</p> <pre><code>report = client.fetch_report()\n</code></pre> <p>Unfortunately, deciding what data you want in the report given the constraints imposed by the API is more complicated. Let's run over some examples:</p> <pre><code>from datetime import date\n\nreport = client.fetch_report(\n    dimensions=(\"day\",),\n    start_date=date(2022, 1, 1),\n    end_date=date(2022, 12, 31),\n)\n</code></pre> <p>The above example gets your day-by-day analytics for the 2022 calendar year \u2014 each row in the resultant report will be for a different day.</p> <p>Now let's spice it up a bit:</p> <pre><code>report = client.fetch_report(\n    dimensions=(\"video\",),\n    filters={\"country\": \"US\"},\n    sort_options=(\"-views\"),\n    start_date=date(2022, 1, 1),\n    end_date=date(2022, 12, 31),\n    max_results=10,\n)\n</code></pre> <p>This more complex example gets the ten best performing videos (by views) in the 2022 calendar year in the US.</p> <p>There's a lot more to creating reports than this though, which is why there is some helpful guides you can use to learn more about it.</p>"},{"location":"starting/firstapp/#processing-and-saving-analytics-data","title":"Processing and saving analytics data","text":"<p>Once you have your reports, you can either process them using a data manipulation library such as pandas or save them to disk.</p> <p>pandas, PyArrow, and Polars are all supported natively:</p> pandasPyArrowPolars <pre><code>df = report.to_pandas()\n</code></pre> <pre><code>table = report.to_arrow()\n</code></pre> <pre><code>df = report.to_polars()\n</code></pre> <p>If you want to save your reports to disk, you can do so in a few ways:</p> CSVJSONExcelApache FeatherApache Parquet <pre><code>report.to_csv(\"output.csv\")\n</code></pre> <pre><code>report.to_json(\"output.json\")\n</code></pre> <pre><code>report.to_excel(\"output.xlsx\")\n</code></pre> <pre><code>report.to_feather(\"output.feather\")\n</code></pre> <pre><code>report.to_parquet(\"output.parquet\")\n</code></pre>"},{"location":"starting/firstapp/#what-next","title":"What next?","text":"<p>Now you've got some analytix experience under your belt, you can move onto bigger and better things. Here's some good places to go next:</p> <ul> <li>The <code>Client</code> reference</li> <li>The guides (especially the one about report types)</li> <li>The example store</li> </ul> <p>If you ever get stuck, feel free to start a discussion!</p>"},{"location":"starting/googleapp/","title":"Creating a Google Developers application","text":"<p>This guide will run you through the process of configuring a project for analytix to use.</p> <p>By the end of this guide, you will know:</p> <ol> <li>how to set up an application on the Google Developers Console</li> <li>how to enable the YouTube Analytics API in your application</li> <li>how to make analytix aware of your application</li> </ol>"},{"location":"starting/googleapp/#creating-a-project","title":"Creating a project","text":"<p>To create a project:</p> <ol> <li>sign into your Google account. This does not need to be the same account as the one you are retrieving data from.</li> <li>on the navbar, click on the dropdown that says \"Select a project\".</li> <li>click \"NEW PROJECT\".</li> <li>enter your project name, then click \"CREATE\". You do not need to set an organisation.</li> </ol> <p>After this, you'll be redirected back to the dashboard. It may take some time to create the project.</p>"},{"location":"starting/googleapp/#setting-up-the-youtube-analytics-api","title":"Setting up the YouTube Analytics API","text":""},{"location":"starting/googleapp/#enabling-the-youtube-analytics-api","title":"Enabling the YouTube Analytics API","text":"<ol> <li>Click on \"ENABLE APIS AND SERVICES\".</li> <li>Search for \"youtube\", then click \"YouTube Analytics API\".</li> <li>Click \"ENABLE\".</li> </ol>"},{"location":"starting/googleapp/#configuring-the-consent-screen","title":"Configuring the consent screen","text":"<p>Click \"CREATE CREDENTIALS\" in the top-right corner, then proceed with the following steps.</p> <ol> <li>Credential type<ul> <li>Under \"What data will you be accessing?\", select \"User data\"</li> <li>Click \"NEXT\".</li> </ul> </li> <li>OAuth consent screen<ul> <li>Enter the following information:<ul> <li>App name: the name of your application; this does not need to be the same as your project's name</li> <li>User support email: this is required even though your project will remain private to you</li> <li>App logo: an optional logo for your application</li> <li>Developer contact information: same as User support email</li> </ul> </li> <li>Click \"SAVE AND CONTINUE\".</li> </ul> </li> <li>Scopes<ul> <li>Click \"ADD OR REMOVE SCOPES\".</li> <li>Select the <code>.../auth/yt-analytics.readonly</code> and <code>.../auth/yt-analytics-monetary.readonly</code> scopes; these should be the last two in the list.</li> <li>Click \"UPDATE\".</li> <li>Click \"SAVE AND CONTINUE\".</li> </ul> </li> <li>OAuth Client ID<ul> <li>Select your application type. If you're not sure which option to select, choose \"Desktop app\".</li> <li>Enter a name for your OAuth 2 client. This does not need to be the same as your project name.</li> </ul> </li> <li>Your credentials<ul> <li>Click \"DOWNLOAD\".</li> <li>Save your secrets file in the root directory (or subdirectory thereof) of your project. It is recommended you give it an easy name to remember, such as \"secrets.json\".</li> <li>Click \"DONE\".</li> </ul> </li> </ol> <p>Warning</p> <p>You should never share your secrets file with anyone.</p>"},{"location":"starting/googleapp/#setting-yourself-as-a-test-user","title":"Setting yourself as a test user","text":"<p>In order to use your application, you need to add yourself as a test user. To do so:</p> <ol> <li>click \"OAuth consent screen\"</li> <li>under the \"Test users\" heading, click \"+ ADD USERS\"</li> <li>type your email address into the box</li> <li>click \"SAVE\"</li> </ol> <p>Success</p> <p>You're all done! You can now start working with analytix.</p>"},{"location":"starting/installation/","title":"Installation","text":""},{"location":"starting/installation/#with-pip","title":"With pip","text":"<p>You can install analytix using the pip package manager using the following command:</p> <pre><code>pip install analytix\n</code></pre> <p>You may need to prefix these commands with a call to the Python interpreter depending on your OS and Python configuration:</p> <p>You can also install the latest development version if you wish:</p> PrereleasesFrom GitHub <pre><code>pip install analytix --pre\n</code></pre> <pre><code>pip install git+https://github.com/parafoxia/analytix\n</code></pre>"},{"location":"starting/installation/#with-git","title":"With git","text":"<p>if you don't want to use pip for whatever reason, you can install directly from GitHub instead:</p> <pre><code>git clone https://github.com/parafoxia/analytix\npython setup.py install\n</code></pre>"},{"location":"starting/installation/#with-the-intention-to-contribute","title":"With the intention to contribute","text":"<p>If you wish to contribute to analytix, you also need to install the development dependencies:</p> <pre><code>git clone https://github.com/&lt;username&gt;/analytix\ncd analytix\npip install -r requirements/dev.txt\n</code></pre> <p>where <code>&lt;username&gt;</code> is your GitHub username.</p>"}]}